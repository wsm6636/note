---
created: 2023-11-17-21:00:00
updated: 2024-05-07T22:28
tags:
  - ç¬”è®°
  - ç¬”è®°/paper
  - ç¬”è®°/æ°¸ä¹…ç¬”è®°
---

# é—®é¢˜
**è¦ç ”ç©¶çš„é—®é¢˜**
è‡ªåŠ¨é©¾é©¶ä¸­ç”±äºåº”ç”¨çš„å¤æ‚æ€§å’Œç‰©ç†ä¸Šåˆ†å¸ƒæ€§é‡‡ç”¨åˆ†å¸ƒå¼ç³»ç»Ÿï¼Œç”±å¤šä¸ªECUæ„æˆã€‚å¯ä»¥é€šè¿‡CANæ€»çº¿æˆ–è€…TSNç­‰å…¶ä»–ä¼ è¾“æ–¹å¼è¿æ¥ã€‚è‡ªåŠ¨é©¾é©¶å¯¹äºâ€œæŒ‰é’®åˆ°åŠ¨ä½œâ€çš„å»¶æ—¶éå¸¸å…³æ³¨ï¼Œååº”æ—¶é—´çš„å¢åŠ å¯¹æ§åˆ¶è´¨é‡æœ‰å½±å“ï¼Œéœ€è¦åŠæ—©é™åˆ¶ã€‚

ç”±äºç³»ç»Ÿå¤æ‚çš„è¡Œä¸ºï¼Œä½¿å¾—ä»»åŠ¡é—´å…·æœ‰å› æœå…³è”çš„å…³ç³»ï¼Œä¸€ä¸ªä»»åŠ¡çš„è¾“å…¥å–å†³äºä¹‹å‰ä»»åŠ¡çš„è¾“å‡ºï¼Œè¿™ä¸­å› æœé“¾å½¢å¼çš„ä»»åŠ¡ä½¿å¾—ç«¯åˆ°ç«¯å»¶æ—¶æ›´éš¾ä»¥é¢„æµ‹ã€‚

TSNèƒ½å¤Ÿæ»¡è¶³CANæ€»çº¿æ— æ³•æ»¡è¶³çš„å¤§é‡æ•°æ®çš„åœºæ™¯ã€‚ä½†TSNç½‘ç»œä¼ è¾“å› æœé“¾çš„ç«¯åˆ°ç«¯åˆ†æï¼Œç½‘ç»œéƒ¨åˆ†è¿˜æ²¡æœ‰è¢«å¹¿æ³›ç ”ç©¶ã€‚


**ååº”æ—¶é—´çš„åˆ†æå’Œç«¯åˆ°ç«¯å»¶è¿Ÿçš„åˆ†æçš„åŒºåˆ«** 
å®æ—¶ç³»ç»Ÿé€šå¸¸å¤„ç†å¤–éƒ¨äº‹ä»¶å¹¶å¯¹å…¶åšå‡ºååº”ã€‚åœ¨è®¸å¤šå¤æ‚çš„å®æ—¶ç³»ç»Ÿä¸­ï¼Œå¤–éƒ¨äº‹ä»¶çš„å¤„ç†ç”±ç”±å¤šä¸ªä»»åŠ¡ç»„æˆçš„å¤„ç†é“¾æ¥æ‰§è¡Œï¼Œæ‰€è¿°å¤šä¸ªä»»åŠ¡å¯ä»¥åœ¨åŒä¸€å¤„ç†å™¨ä¸ŠåŒæ—¶æ‰§è¡Œæˆ–è€…åˆ†å¸ƒåˆ°å¤šä¸ªå¤„ç†å•å…ƒã€‚è¿™ç±»ç³»ç»Ÿçš„å…³é”®å®æ—¶æ€§èƒ½æŒ‡æ ‡æ˜¯æœ€å¤§ååº”æ—¶é—´ï¼Œå®ƒæè¿°äº†ä»äº‹ä»¶å‘ç”Ÿåˆ°äº§ç”Ÿä¸è¯¥å¤–éƒ¨äº‹ä»¶å¯¹åº”çš„æœ€ç»ˆè¾“å‡ºæ‰€éœ€çš„æ—¶é—´ã€‚å…·æœ‰æœ€å¤§ååº”æ—¶é—´çº¦æŸçš„åŠ å·¥é“¾åœ¨æ±½è½¦ç”µå­ã€å·¥ä¸šæ§åˆ¶å’Œæœºå™¨äººç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚

åµŒå…¥å¼å®æ—¶ç³»ç»Ÿé€šå¸¸ç”¨ä»»åŠ¡é“¾å’Œæ¶ˆæ¯é“¾æ¥å»ºæ¨¡ã€‚ä¸ºäº†éªŒè¯è¿™äº›é“¾çš„è®¡æ—¶è¡Œä¸ºï¼Œä¸ä»…éœ€è¦è®¡ç®—å®ƒä»¬çš„ç«¯åˆ°ç«¯å“åº”æ—¶é—´å¹¶ä¸ç›¸åº”çš„æˆªæ­¢æ—¥æœŸè¿›è¡Œæ¯”è¾ƒï¼Œè¿˜éœ€è¦è®¡ç®—ç«¯åˆ°ç«¯çš„æ•°æ®ä¼ æ’­å»¶è¿Ÿ(æ•°æ®å¹´é¾„å’Œååº”æ—¶é—´)å¹¶ä¸ç›¸åº”çš„æ•°æ®å¹´é¾„å’Œååº”æ—¶é—´çº¦æŸè¿›è¡Œæ¯”è¾ƒã€‚
å¤„ç†é“¾çš„ç›®æ ‡æ˜¯å¤„ç†æºå¸¦å¤–éƒ¨äº‹ä»¶ä¿¡æ¯çš„æ•°æ®å¸§å¹¶å¯¹å…¶åšå‡ºååº”ã€‚å½“åœ¨æ—¶é—´tå‘ç”Ÿå¤–éƒ¨äº‹ä»¶æ—¶ï¼Œåœ¨æ—¶é—´tæˆ–ä¹‹åé‡Šæ”¾çš„é‡‡æ ·ä»»åŠ¡Ï„0çš„ä½œä¸šå°†äº§ç”Ÿæºå¸¦è¯¥å¤–éƒ¨äº‹ä»¶çš„ä¿¡æ¯çš„è¾“å‡ºæ•°æ®å¸§ã€‚è¯¥æ•°æ®å¸§å°†ç”±å…¶åç»­ä»»åŠ¡Ï„1çš„æŸä¸ªä½œä¸šè¯»å–å’Œå¤„ç†ï¼Œå…¶äº§ç”Ÿä¹Ÿæºå¸¦è¯¥å¤–éƒ¨äº‹ä»¶çš„ä¿¡æ¯çš„å…¶è¾“å‡ºæ•°æ®å¸§ï¼Œå¹¶ä¸”è¿™åœ¨æ•´ä¸ªå¤„ç†é“¾ä¸­é‡å¤ï¼Œç›´åˆ°æœ€åä¸€ä¸ªå¤„ç†ä»»åŠ¡Ï„nçš„æŸä¸ªä½œä¸šåœ¨æŸä¸ªæ—¶é—´ç‚¹tâ€˜äº§ç”Ÿå…³äºè¯¥å¤–éƒ¨äº‹ä»¶çš„æœ€ç»ˆè¾“å‡ºæ•°æ®å¸§ï¼Œåˆ™tâ€™-tæ˜¯å…³äºè¯¥å¤–éƒ¨äº‹ä»¶çš„å¤„ç†é“¾çš„ååº”æ—¶é—´ã€‚


<span style="color:black;background:#40a9ff !important;">å¯¹äºETå¤„ç†é“¾ï¼Œåˆ†æååº”æ—¶é—´æœ¬è´¨ä¸Šç­‰åŒäºåˆ†æé“¾ä¸­æ¯ä¸ªä»»åŠ¡æ‰§è¡Œä¸€æ¬¡ã€ç›¸ç»§è§¦å‘çš„ç«¯åˆ°ç«¯å»¶è¿Ÿï¼Œå¯¹æ­¤å·²æœ‰æˆç†Ÿçš„æŠ€æœ¯[1]ã€[2]</span>
**CANçš„é—®é¢˜**
åˆ†å¸ƒå¼ç³»ç»Ÿä¸­TSNç½‘ç»œä¼ è¾“å› æœé“¾çš„ç«¯åˆ°ç«¯åˆ†æï¼Œæœ€å¤§ååº”æ—¶é—´åˆ†æ

è‡ªåŠ¨é©¾é©¶ä¸­ç”±äºåº”ç”¨çš„å¤æ‚æ€§å’Œç‰©ç†ä¸Šåˆ†å¸ƒæ€§é‡‡ç”¨åˆ†å¸ƒå¼ç³»ç»Ÿï¼Œç”±å¤šä¸ªECUæ„æˆã€‚å¯ä»¥é€šè¿‡CANæ€»çº¿æˆ–è€…TSNç­‰å…¶ä»–ä¼ è¾“æ–¹å¼è¿æ¥ã€‚è‡ªåŠ¨é©¾é©¶å¯¹äºâ€œæŒ‰é’®åˆ°åŠ¨ä½œâ€çš„å»¶æ—¶éå¸¸å…³æ³¨ï¼Œååº”æ—¶é—´çš„å¢åŠ å¯¹æ§åˆ¶è´¨é‡æœ‰å½±å“ï¼Œéœ€è¦åŠæ—©é™åˆ¶ã€‚

ç”±äºç³»ç»Ÿå¤æ‚çš„è¡Œä¸ºï¼Œä½¿å¾—ä»»åŠ¡é—´å…·æœ‰å› æœå…³è”çš„å…³ç³»ï¼Œä¸€ä¸ªä»»åŠ¡çš„è¾“å…¥å–å†³äºä¹‹å‰ä»»åŠ¡çš„è¾“å‡ºï¼Œè¿™ä¸­å› æœé“¾å½¢å¼çš„ä»»åŠ¡ä½¿å¾—ç«¯åˆ°ç«¯å»¶æ—¶æ›´éš¾ä»¥é¢„æµ‹ã€‚

TSNçš„ç¡®å®šæ€§ä¼ è¾“æé«˜äº†å®æ—¶æ€§ï¼Œä½†TSNç½‘ç»œä¼ è¾“å› æœé“¾çš„ç«¯åˆ°ç«¯åˆ†æï¼Œç½‘ç»œéƒ¨åˆ†è¿˜æ²¡æœ‰è¢«å¹¿æ³›ç ”ç©¶ã€‚

**QBVçš„é—®é¢˜**
è™½ç„¶TASåœ¨æ–½åŠ ä¸šåŠ¡ç¡®å®šæ€§æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†ä¸¥æ ¼çš„å®šæ—¶è¦æ±‚ï¼Œå°¤å…¶æ˜¯è·¨TSNåŸŸçš„å®šæ—¶åŒæ­¥çš„é«˜æ‰€éœ€ç²¾åº¦æ°´å¹³ï¼Œå¦‚æœå‘ç”Ÿä»»ä½•å®šæ—¶æœªå¯¹å‡†ï¼Œåˆ™å¢åŠ äº†å¤æ‚æ€§å¹¶å¨èƒåˆ°TSNç½‘ç»œåŸŸçš„å¯é æ€§ã€‚æ­¤å¤–ï¼Œå‡ ä¸ªåŒæ­¥æŒ‘æˆ˜ï¼Œä¾‹å¦‚å®šæ—¶ä¿¡å·å¸§ä¸­çš„åå·®æˆ–æ¼‚ç§»ã€æ—¶é’Ÿä¸å‡†ç¡®å’Œä¸¢å¤±çš„å®šæ—¶å¸§ï¼Œå¯èƒ½å¯¼è‡´TSNåŸŸä¸­çš„åŒæ­¥ä¸»æ—¶é’Ÿä¸‹æ¸¸çš„ä¸å‡†ç¡®ã€‚éšç€ç½‘ç»œè§„æ¨¡çš„å¢å¤§ï¼ŒåŒæ­¥çš„å¤æ‚åº¦ä¹Ÿéšä¹‹å¢åŠ ã€‚

**å°†ATSçœ‹æˆé“¾åˆ†æ**
éœ€è¦è¯»å–ç¼“å†²åŒºæ•°æ®ï¼Œæ‰èƒ½è§¦å‘ä¼ è¾“å’Œä»¤ç‰Œæ¡¶ç®—æ³•çš„è®¡ç®—ã€‚
ç”±äºATSæ•´å½¢åœ¨ä¸åŒé“¾è·¯ä¸Šéƒ½å…·æœ‰ä¸åŒçš„æƒ…å†µï¼Œä¼˜å…ˆçº§ç­‰ï¼Œä¼šå¯¼è‡´åˆ†é…åˆ°ä¸åŒçš„ä»¤ç‰Œæ¡¶ä¸­
ä»¤ç‰Œæ¡¶ä¸­ä¹Ÿå…·æœ‰ä¸åŒçš„å®¹é‡å’Œé€Ÿç‡ï¼Œæ‰€ä»¥è®¤ä¸ºæ¯ä¸€è·³éƒ½æ˜¯ä¸€ä¸ªæ–°çš„ä»»åŠ¡ï¼Œä¸ä»…ä»…åªæ˜¯ä¸€ä¸ªæ•°æ®å¸§çš„ä¼ è¾“ã€‚è€Œæ˜¯ç±»æ¯”æˆä»»åŠ¡é“¾ä¸­çš„å¤šä¸ªå‰åè”ç³»çš„ä»»åŠ¡ï¼Œåªä¸è¿‡ä»–ä»¬ä¸å…·æœ‰æ›´æ–°è®¡ç®—çš„åŠŸèƒ½ï¼Œç›¸å½“äºé€šè¿‡è®¡ç®—ä¹‹åä»ç„¶å¾—åˆ°ä¸å˜çš„ç»“æœã€‚


# æ–¹æ³•
èµ„æºæ¨¡å‹

# æ¨¡å‹

## å‡è®¾
1. éšå¼é€šä¿¡ã€‚ä»»åŠ¡å¼€å§‹æ—¶è¯»ï¼Œç»“æŸæ—¶å†™
2. ä»»åŠ¡ä¹‹é—´å­˜åœ¨ç¼“å†²åŒºã€‚å‰ä¸€ä¸ªä»»åŠ¡å†™å…¥ç¼“å†²åŒºå$w_{i-1}$ï¼Œåä¸€ä¸ªä»»åŠ¡æ‰èƒ½è¯»å–$r_i$
3. ET
4. å‘¨æœŸæ€§ä»»åŠ¡é‡‡æ ·
5. ATSä»»åŠ¡ï¼Œä¸è€ƒè™‘çªå‘
6. éæŠ¢å 
7. ä¸¤ä¸ªä»»åŠ¡ä¹‹é—´æœ‰ç¼“å†²åŒºï¼Œ
8. ä¸¤ä¸ªäº¤æ¢æœºä¹‹é—´å‡è®¾ä¼ è¾“å­˜åœ¨ç±»ä¼¼çš„ç¼“å†²åŒºè¿›è¡Œè¯»å†™ï¼Œå°†ä¼ è¾“æ—¶é—´çº³å…¥åˆ°è¾¾æ—¶é—´ï¼Œä½¿å¾—ç½‘ç»œä»»åŠ¡å’Œä»»åŠ¡ä¸€æ ·ã€‚
9. æœ¬æ–‡ç ”ç©¶çš„æ±½è½¦ç³»ç»Ÿç”±Nä¸ªç‹¬ç«‹çš„å‘¨æœŸæ€§å®æ—¶ä»»åŠ¡ç»„æˆï¼Œç”±Î“={Ï„1ï¼Œ...ï¼ŒÏ„N}æ ‡è¯†ï¼Œå®ƒä»¬åœ¨å…·æœ‰mä¸ªç”µå­æ§åˆ¶å•å…ƒ(ECU)çš„å…¨å±€å¼‚æ­¥å±€éƒ¨åŒæ­¥(GALS)åˆ†å¸ƒå¼ä½“ç³»ç»“æ„ä¸Šæ‰§è¡Œã€‚æ¯ä¸ªä»»åŠ¡è¢«é™æ€åœ°åˆ†é…ç»™ä¸€ä¸ªä¸“ç”¨çš„ECUï¼Œæ¯ä¸ªECUä¸Šçš„ä»»åŠ¡æŒ‰ç…§å›ºå®šä¼˜å…ˆçº§çš„æŠ¢å è°ƒåº¦ç­–ç•¥è¿›è¡Œè°ƒåº¦ã€‚æ¯ä¸ªâˆˆÏ„iÎ“ç”±ä¸€ä¸ªå…ƒç»„Ï„i=(Ciï¼ŒTiï¼ŒDi)æ¥è¡¨å¾ï¼Œå…¶ä¸­

æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹å‡è®¾å¯¹è¿™ç§é€šä¿¡è¿›è¡Œäº†æŠ½è±¡ï¼š1 ) Ï„ cè¢«å¶å‘åœ°æˆ–å‘¨æœŸæ€§åœ°é‡Šæ”¾ï¼Œå¹¶ä¼ è¾“æ‰€éœ€çš„æ•°æ®å’Œå¯èƒ½çš„ä¸€äº›é™„åŠ ä¿¡æ¯ï¼Œä¾‹å¦‚ï¼Œä¸€ä¸ªæ¶ˆæ¯ä¸­å¯èƒ½ä¼ è¾“å¤šä¸ªå€¼ç»™ä¸€ç»„ä»»åŠ¡ï¼›==2 )å½“Ï„ 1çš„ä¸€ä¸ªä½œä¸šå®Œæˆåï¼Œå®ƒå°†æ‰€éœ€çš„å€¼å†™å…¥ä¸€ä¸ªç±»ä¼¼äºä¸€ä¸ªæ ¸å¿ƒä¸­é€šä¿¡çš„ç¼“å†²åŒºä¸­ï¼Œå¹¶ä¸”æ¯ä¸ªÏ„ cçš„ä½œä¸šåœ¨åˆå§‹åŒ–æ—¶è¯»å–å½“å‰å€¼ï¼›==3 )å½“Ï„ cçš„ä¸€ä¸ªä½œä¸šå®Œæˆåï¼ŒÏ„ 2å¯ä»¥ç›´æ¥è¯»å–æ›´æ–°åçš„å€¼ï¼Œå°±åƒè¯»å–ä¸€ä¸ªä»»åŠ¡åœ¨åŒä¸€å¤„ç†å™¨ä¸Šäº§ç”Ÿçš„å€¼ä¸€æ ·ã€‚

## ä»»åŠ¡
**ç»ˆç«¯ä»»åŠ¡**ï¼š
$\tau$ 

iï¼šç¬¬iä¸ªä»»åŠ¡
jï¼šç¬¬iä¸ªä»»åŠ¡çš„ç¬¬jä¸ªä½œä¸š
kï¼šç¬¬kä¸ªç»ˆç«¯ç«™

$a^{ik}_j$ï¼šåˆ°è¾¾æ—¶é—´
$f^{ik}_j$ï¼šç»“æŸæ—¶é—´
$R^{ik}_j$ï¼šæœ€å·®æ‰§è¡Œæ—¶é—´
$T^{ik}_j$ï¼šå‘¨æœŸ




**ATSä»»åŠ¡**ï¼š
$m$

kï¼šç¬¬kä¸ªç»ˆç«¯
iï¼šæ¥è‡ªå“ªä¸ªæµ
jï¼šç¬¬iä¸ªæµä¸­çš„ç¬¬jä¸ªå¸§

$l^{ik}_j$ï¼šå¸§çš„é•¿åº¦ï¼Œsize
$p^{ik}_j$ï¼šä¼˜å…ˆçº§ï¼ˆç»§æ‰¿é˜Ÿåˆ—çš„ï¼‰
$a^{ik}_j$ï¼šåˆ°è¾¾æ—¶é—´
$d^{ik}_j$ï¼šæ•´ä¸ªå¸§ç»“æŸçš„æ—¶é—´ï¼ˆè½¬å‘å‡ºå»çš„æ—¶åˆ»ï¼‰ã€‚å¸§è·å¾—èµ„æ ¼æ—¶é—´ä¹‹åï¼Œå†ç»è¿‡ä¼ è¾“ç®—æ³•æ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©ï¼Œæœ€åä¼ å‡ºçš„æ—¶é—´ã€‚ï¼ˆet+Bï¼‰
$et^{ik}_j$ï¼šå¸§è·å¾—çš„èµ„æ ¼æ—¶é—´ï¼ˆé€šè¿‡ATSç®—æ³•è®¡ç®—ï¼‰ã€‚


$MRT^{ik}_j$ï¼šæœ€å¤§é©»ç•™æ—¶é—´ã€‚çº³ç§’ã€‚å¸§ä»…åœ¨æœ€å¤§é©»ç•™æ—¶é—´å†…æœ‰æ•ˆã€‚
$B^{ik}_j$ï¼šé˜»å¡æ—¶é—´ï¼Œåœ¨åˆ°è¾¾èµ„æ ¼æ—¶é—´ä¹‹åè¢«æ›´é«˜ä¼˜å…ˆçº§æ•°æ®å¸§é˜»å¡


## ç³»ç»Ÿ
Nï¼šNä¸ªæµï¼ŒNä¸ªä»¤ç‰Œæ¡¶ï¼ŒNä¸ªç»ˆç«¯ç«™
é˜Ÿåˆ—Qï¼Œå…·æœ‰å›ºå®šä¼˜å…ˆçº§ï¼ŒFIFO
$r_n$ï¼šç¬¬nä¸ªä»¤ç‰Œæ¡¶çš„é€Ÿç‡
$b_n$ï¼šç¬¬nä¸ªä»¤ç‰Œæ¡¶çš„å¤§å°ï¼ˆæœ€å¤§ä»¤ç‰Œæ•°é‡ï¼‰

> ä¼ è¾“é€‰æ‹©ç®—æ³•ï¼ˆè½®è¯¢æ¯ä¸ªé˜Ÿåˆ—çš„é˜Ÿå¤´ï¼‰ï¼Œè½®è¯¢çš„æ˜¯ï¼Œæ•´å½¢é˜Ÿåˆ—çš„headerï¼Œé€‰æ‹©ä¸€ä¸ªä¼˜å…ˆçº§æœ€é«˜çš„å¸§ä¼ è¾“



## ä»»åŠ¡é“¾
ä¸¤ä¸ªç»ˆç«¯ç«™ï¼Œ
1. ï¼ˆé‡‡æ ·+ï¼‰è®¡ç®—ä»»åŠ¡ + ä¼ è¾“ä»»åŠ¡ï¼ˆå‘é€æ•°æ®å¸§ï¼‰
2. ç½‘ç»œä»»åŠ¡ATSï¼š==æœ€å¤šå‡ è·³ï¼Ÿ==
3. æ¥æ”¶ä»»åŠ¡ï¼ˆæ¥æ”¶æ•°æ®å¸§ï¼‰+ è®¡ç®—ä»»åŠ¡ï¼ˆ+æ¿€åŠ±ï¼‰
4. æ¶ˆæ¯æ•°é‡é™åˆ¶ä¸ºæ¯ä¸ªäº‹åŠ¡ä¸€æ¡
5. åœ¨æ¯ä¸ªäº‹åŠ¡ä¸­ï¼Œæˆ‘ä»¬å‡è®¾ä¸€ä¸ªä»»åŠ¡çš„ä¼˜å…ˆçº§é«˜äºå…¶åœ¨åŒä¸€ç»ˆç«¯ç«™å†…çš„åç»­ä»»åŠ¡çš„ä¼˜å…ˆçº§ã€‚
6. ç½‘é€Ÿè®¾ç½®ä¸º1 Gbps
7. æ¯ä¸ªä»»åŠ¡çš„æœ€åæƒ…å†µæ‰§è¡Œæ—¶é—´**(WCET)è¢«è®¤ä¸ºæ˜¯0.5ms
8. æ ¹æ®æ¶ˆæ¯çš„å¤§å°å’Œç½‘ç»œé€Ÿåº¦è®¡ç®—æ¶ˆæ¯çš„ä¼ è¾“æ—¶é—´(ç§’)((ğ‘†ğ‘–ğ‘§ğ‘’ğ‘—ğ‘˜ + ğ‘‚ğ») âˆ— 8)âˆ•(ğ‘ ).Ohæ˜¯TSNå¸§çš„å¼€é”€ï¼Œä»¥å­—èŠ‚ä¸ºå•ä½ã€‚
9. ä¼ è¾“æ—¶é—´(0.0126æ¯«ç§’)
10. æ ¹æ®TSN[31ï¼Œ33ï¼Œ34]çš„æœ€åæƒ…å†µå“åº”æ—¶é—´åˆ†æï¼Œæ¶ˆæ¯çš„å“åº”æ—¶é—´(æ¥æ”¶ç«¯ç«™æ¥æ”¶æ¶ˆæ¯çš„æ—¶é—´)ä¸º1.025æ¯«ç§’ã€‚

![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202311082247587.png)


### ååº”æ—¶é—´
æœ€åä¸€ä¸ªä»»åŠ¡$\tau$ çš„$a^{last-k}_j$  +  å®ƒçš„æœ€å·®ç›¸åº”æ—¶é—´$R^{last-k}_j$   -  ç¬¬ä¸€ä¸ªä»»åŠ¡çš„$a^{first-k}_j$
**ä¸¤ä¸ªä»»åŠ¡ä¹‹é—´çš„å·®**
ATSä»»åŠ¡ï¼Œä»¥åˆ°èµ„æ ¼æ—¶é—´è®¡ç®—
==è¦è€ƒè™‘ä¼˜å…ˆçº§å’Œèµ„æ ¼æ—¶é—´çš„é—®é¢˜å˜›==



### æœ€å¤§ååº”æ—¶é—´

![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202311112042385.png)



## ç®—æ³•
ATSï¼Œæ ‡å‡†ä¸­çš„ä»¤ç‰Œæ¡¶
ç”±äºè¯¥æ ‡å‡†åªè€ƒè™‘ä»¤ç‰Œæ¡¶
lï¼šå¸§çš„é•¿åº¦ï¼ˆlength frameï¼‰ã€‚å•ä½bitã€‚ä»æ¡¶ä¸­ç§»é™¤çš„ä»¤ç‰Œæ•°é‡ã€‚
rï¼šæ‰¿è¯ºä¿¡æ¯é€Ÿç‡ï¼ˆcommitted information rateï¼‰ã€‚bit/ç§’ã€‚å‘æ¡¶ä¸­å¡«å……ä»¤ç‰Œçš„é€Ÿåº¦ã€‚
bï¼šæ‰¿è¯ºçªå‘å¤§å°ï¼ˆcommitted burst sizeï¼‰ã€‚å•ä½bitã€‚ä»¤ç‰Œæ¡¶æœ€å¤§çš„ä»¤ç‰Œé‡ã€‚
aï¼šè¾¾åˆ°æ—¶é—´ï¼ˆarrival timeï¼‰
dï¼šç»“æŸæ—¶é—´ï¼Œæ•´ä¸ªå¸§æ¥æ”¶
betï¼šæ¡¶ç©ºæ—¶é—´ï¼ˆBucket Empty Timeï¼‰
bftï¼šæ¡¶æ»¡æ—¶é—´ï¼ˆbucket Full Timeï¼‰ã€‚æ¡¶ä¸­ä»¤ç‰Œæ•°é‡ = bã€‚
etï¼šèµ„æ ¼æ—¶é—´ï¼ˆeligibility Timeï¼‰ã€‚

etdï¼šä»ç©ºåˆ°æ»¡çš„æ—¶é—´ï¼ˆempty To Full Durationï¼‰ã€‚ä»¥ré€Ÿç‡å‘æ¡¶ä¸­å¡«ä»¤ç‰Œç›´åˆ°b
getï¼šç»„èµ„æ ¼æ—¶é—´ï¼ˆGroup Eligibility Timeï¼‰ã€‚åŒä¸€ç±»æ•´å½¢å™¨å¤„ç†å‰ä¸€ä¸ªæ•°æ®å¸§çš„æœ€è¿‘çš„èµ„æ ¼æ—¶é—´ã€‚
> ä¸Šä¸€ä¸ªå¸§çš„èµ„æ ¼æ—¶é—´

lrdï¼šé•¿åº¦æ¢å¤æŒç»­æ—¶é—´ï¼ˆlengthRecoveryDurationï¼‰ã€‚ä»¥rç´¯ç§¯åˆ°å¸§é•¿åº¦çš„ä»¤ç‰Œæ•°é‡lï¼Œæ‰€éœ€è¦çš„æ—¶é—´ã€‚l/rã€‚
mrtï¼šæœ€å¤§é©»ç•™æ—¶é—´ï¼ˆMaxResidenceTimeï¼‰ã€‚çº³ç§’ã€‚å¸§ä»…åœ¨æœ€å¤§é©»ç•™æ—¶é—´å†…æœ‰æ•ˆã€‚
setï¼šè°ƒåº¦æ—¶é—´(schedulerEligibilityTime)ã€‚ä»¤ç‰Œæ•°é‡æ»¡è¶³å¸§é•¿åº¦lçš„æ—¶é—´ã€‚

![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202311090911895.png)



# title


åŸºäºTSNçš„åˆ†å¸ƒå¼å®æ—¶ç³»ç»Ÿä»»åŠ¡é“¾çš„ååº”æ—¶é—´åˆ†æ
Reaction Time Analysis of Task Chains for TSN-based Distributed Real-time Systems
# æ‘˜è¦

**åˆ†å¸ƒå¼å®æ—¶ç³»ç»Ÿé€šå¸¸ç”±å¤šä¸ªç”µå­æ§åˆ¶å•å…ƒæ„æˆï¼Œæ§åˆ¶ä»»åŠ¡ä¹‹é—´é€šå¸¸å…·æœ‰å› æœå…³ç³»ã€‚è¿™ç§ç³»ç»Ÿä¸ä»…éœ€è¦æ»¡è¶³æ—¶åºçº¦æŸï¼Œå¯¹æœ€å¤§ååº”æ—¶é—´ä¹Ÿéœ€è¦é™åˆ¶ä»¥å…å¯¹ç»“æœäº§ç”Ÿå½±å“ã€‚ç°æœ‰çš„åˆ†å¸ƒå¼å®æ—¶ç³»ç»Ÿä»»åŠ¡é“¾æœ€å¤§ååº”æ—¶é—´åˆ†æé€šå¸¸é‡‡ç”¨CANæ€»çº¿ä½œä¸ºECUä¹‹é—´çš„é“¾æ¥ï¼Œä½†éšç€æ•°æ®é‡å¢åŠ æ—¶é—´æ•æ„Ÿç½‘ç»œå·²æˆä¸ºä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆã€‚æœ¬æ–‡ç ”ç©¶äº†åŸºäºIEEE 802.1 QCRæ ‡å‡†è½¦è½½åˆ†å¸ƒå¼ç³»ç»Ÿä»»åŠ¡é“¾ç«¯åˆ°ç«¯æ—¶åºåˆ†æã€å»ºç«‹äº†åŸºäºTSNç½‘ç»œä¼ è¾“ä»»åŠ¡é“¾çš„æ¨¡å‹ã€å¹¶å¯¹æœ€å¤§ååº”æ—¶é—´åˆ†æã€‚ç»“åˆè¯•éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•æé«˜äº†æ€§èƒ½ã€‚**
Distributed real-time systems usually consist of multiple electronic control units (ECUs), often with causal relationships between control tasks. Such systems not only need to satisfy timing constraints, but also need to limit the maximum reaction time so as not to affect the results. Existing distributed real-time system task chain maximum reaction time analysis usually uses CAN bus as the link between ECUs, but with the increase of data volume Time-sensitive Networking  (TSN) have become a new solution. In this paper, we investigate the end-to-end timing analysis of task chain of distributed system based on IEEE 802.1 QCR standard for vehicle, model the transmission of task chain based on TSN network, and analyse the maximum reaction time. Combined with experiments, we show that our proposed method improves the performance.


#  Introduction
> å¼‚æ­¥

**åœ¨ç°ä»£åµŒå…¥å¼å®æ—¶ç³»ç»Ÿä¸­ï¼Œé€šå¸¸åœ¨å¤šä¸ªç”µå­æ§åˆ¶å•å…ƒä¸Šï¼Œé€šè¿‡ä¸€ç³»åˆ—ä»»åŠ¡å®Œæˆä¸€äº›åŠŸèƒ½æˆ–å¯¹å¤–éƒ¨äº‹ä»¶åšå‡ºååº”ï¼Œè¿™äº›ä»»åŠ¡å…·æœ‰å› æœå…³ç³»ï¼Œå³ä¸€ä¸ªä»»åŠ¡çš„è¾“å‡ºå†³å®šäº†å¦ä¸€ä¸ªä»»åŠ¡çš„è¾“å…¥ã€‚è¿™æ ·çš„ä»»åŠ¡é“¾ä¸ä»…éœ€è¦æ»¡è¶³æˆªæ­¢æ—¶é—´çº¦æŸï¼Œè¿˜éœ€è¦è€ƒè™‘æœ€å¤§ååº”æ—¶é—´çº¦æŸä»¥æ»¡è¶³åŠŸèƒ½çš„æ­£ç¡®æ€§ä»¥åŠç³»ç»Ÿçš„å®‰å…¨æ€§ã€‚ä¾‹å¦‚è½¦è¾†è‡ªåŠ¨å·¡èˆªæ—¶ï¼Œæ§åˆ¶æ‰§è¡Œå•å…ƒå»¶è¿Ÿè¶…è¿‡50msï¼Œè™½ç„¶ä»å¯èƒ½æ»¡è¶³åœ¨æˆªæ­¢æœŸå‰å®Œæˆå‡é€Ÿæ§åˆ¶ï¼Œä½†å¯èƒ½ä¼šç”±äºæ§åˆ¶ä¿¡å·å»¶è¿Ÿå¯¼è‡´è½¦è¾†æ€¥å‰§å‡é€Ÿå¤±å»ç¨³å®šã€‚ååº”æ—¶é—´çº¦æŸç”±AUTOSAR[AUTOSAR]å®šä¹‰ï¼Œè¡¨ç¤ºå¤–éƒ¨é‡‡æ ·æ›´æ–°æ•°æ®ç›´åˆ°ç³»ç»Ÿæ¯ä¸ªç›¸å…³ä»»åŠ¡å¤„ç†è¿™ä¸ªæ›´æ–°çš„æœ€æ—©æ—¶é—´é—´éš”é•¿åº¦ã€‚**
In modern embedded real-time systems, it is common for multiple electronic control units to perform various functionalities or respond to external events through a series of tasks. These tasks have causal relationships, meaning that the output of one task determines the input of another task. Such task chains not only need to satisfy deadline constraints but also consider maximum reaction time constraints to ensure functional correctness and system safety. For example, when a vehicle is in automatic cruise control, if the execution unit of the control system has a delay of more than 50ms, even though it might still meet the deadline for deceleration control, the vehicle may experience abrupt deceleration and lose stability due to the delay in control signals. The reaction time constraint is defined by AUTOSAR [AUTOSAR], representing the length of the earliest time interval at which each relevant task in the system processes an externally sampled/updated data.

**å¯¹äºååº”æ—¶é—´çš„åˆ†æï¼Œå•ä¸ªECUä¸Šå·²æœ‰å¤šç§ç»“è®ºï¼Œã€tangReactionTimeAnalysis2023ã€‘ä¸­é‡‡ç”¨èµ„æºæœåŠ¡æ›²çº¿æ¨¡å‹å–å¾—äº‹ä»¶è§¦å‘å’Œæ•°æ®åˆ·æ–°æ¨¡å¼ä¸‹çš„æœ€å¤§ååº”æ—¶é—´åˆ†æï¼Œåœ¨[durr2019end]ä¸­æå‡ºå¯ä»¥é€šè¿‡å³æ—¶å‘å‰ï¼ˆå‘åï¼‰ä½œä¸šé“¾é•¿åº¦è®¡ç®—æœ€å¤§å“åº”æ—¶é—´ä¸æœ€å¤§æ•°æ®å¹´é¾„ä¸Šç•Œã€‚[gunzel2021timing]ä¸­å¯¹å³æ—¶å‘å‰ï¼ˆå‘åï¼‰ä½œä¸šé“¾é•¿åº¦ä»é‡‡æ ·åˆ°æ•°æ®å¤„ç†æ‰©å±•åˆ°å¤–éƒ¨æ´»åŠ¨è§¦å‘åˆ°é©±åŠ¨äº‹ä»¶ã€‚è¿™ç§åˆ†ææ–¹æ³•ä¹ŸåŒæ ·è¢«åº”ç”¨äºå…¶ä»–é¢†åŸŸä¾‹å¦‚ros2[teper2022end]ã€‚**
Regarding the analysis of reaction time, there have been various conclusions for individual ECUs. In [tangReactionTimeAnalysis2023], a resource service curve model is used to achieve maximum reaction time analysis for event-triggered and data-refresh patterns. In [durr2019end], it is proposed that the maximum reaction time and maximum data age upper bound can be calculated by considering the length of the immediate forward (backward) job chain. [gunzel2021timing] extends the analysis of immediate forward (backward) job chain length from sampling to data processing to external activity triggering to drive events. This analysis method has also been applied in other domains, such as ros2 [teper2022end].

**å¤æ‚çš„æ•°æ®ä¾èµ–å…³ç³»ä½¿å¾—ç«¯åˆ°ç«¯å»¶è¿Ÿåˆ†æå˜å¾—éš¾ä»¥å¤„ç†ï¼Œè€Œä¸”ä¸ä»…ä»…é’ˆå¯¹å•ä¸ªECUå†…éƒ¨ä¹‹é—´å› æœé“¾çš„æ—¶å»¶ï¼Œå¤šä¸ªECUä¹‹é—´ç”±äºç½‘ç»œé€šä¿¡çš„å­˜åœ¨ä¹Ÿä½¿å¾—åˆ†å¸ƒå¼å› æœé“¾çš„ç«¯åˆ°ç«¯åˆ†æå˜å¾—æ›´åŠ å¤æ‚[arestova2022itans]ã€‚**
The complex data dependency relationships make it difficult to handle end-to-end latency analysis, not only for the causality delays between individual ECUs internally, but also for the distributed end-to-end analysis of causality chains between multiple ECUs due to the existence of network communication [arestova2022itans].

**ä»¥å‰å…³äºå¤šECUè”åˆçš„ç«¯åˆ°ç«¯æ—¶åºåˆ†æé€šå¸¸è€ƒè™‘CANæ€»çº¿ä¸ºé€šä¿¡æ–¹å¼ï¼Œä¾‹å¦‚[gunzel2021timing]ï¼Œä½†ç›®å‰åµŒå…¥å¼å®æ—¶ç³»ç»Ÿè¢«æ¥å…¥æ›´å¤šçš„ä¼ æ„Ÿå™¨å·²é‡‡é›†å¤§é‡ä¿¡æ¯ï¼ŒåŒæ—¶ä¹Ÿé€ æˆæ•°æ®ä¼ è¾“é‡æ¿€å¢ï¼ŒCANæ€»çº¿ä¸èƒ½æ›´å¥½çš„æ»¡è¶³åµŒå…¥å¼å®æ—¶ç³»ç»ŸæŸäº›é«˜å¸¦å®½ä½æ—¶å»¶çš„è¦æ±‚ã€‚æ—¶é—´æ•æ„Ÿç½‘ç»œè¢«è€ƒè™‘ä¸ºåµŒå…¥å¼å®æ—¶ç³»ç»Ÿä»¥åŠæ§åˆ¶é¢†åŸŸçš„é€šä¿¡æ–¹å¼ä¹‹ä¸€ã€‚**
Previously, end-to-end timing analysis for multi-ECU collaboration typically considered the CAN bus as the communication method, for example [gunzel2021timing]. However, with the increasing integration of more sensors in embedded real-time systems, a large amount of information is being collected, leading to a surge in data transfer volume. The CAN bus is unable to meet the requirements of certain high-bandwidth, low-latency demands in embedded real-time systems. Time-sensitive networking is considered as one of the communication methods for embedded real-time systems and control domains.

**æ—¶é—´æ•æ„Ÿç½‘ç»œæ˜¯IEEE802.1Qåè®®çš„å¢å¼ºï¼Œæ—¨åœ¨é€šè¿‡æä¾›æ—¶é—´æ•æ„Ÿæ€§å’Œä½å»¶è¿Ÿçš„é€šä¿¡ä»¥æ”¯æŒå®æ—¶æ§åˆ¶ä¸æ•°æ®ä¼ è¾“ã€‚
å…¶ä¸­IEEE 802.1Qcr[IEEEStandardLocal2020]å¼‚æ­¥æµé‡æ•´å½¢ (ATS) æ ‡å‡†æ—¨åœ¨é€šè¿‡æ’¤é”€åŒæ­¥å¹¶å…è®¸æ¯ä¸ªç½‘ç»œèŠ‚ç‚¹æŒ‰è‡ªå·±çš„æ—¶é—´å‘é€æµé‡æ¥ç»•è¿‡åŒæ­¥çš„å¤æ‚æ€§ã€‚**
Time-sensitive networking is an enhancement of the IEEE 802.1Q protocol aimed at providing time-sensitive and low-latency communication to support real-time control and data transfer. Among them, the IEEE 802.1Qcr [IEEEStandardLocal2020] standard for asynchronous traffic shaping (ATS) aims to bypass the complexity of synchronization by revoking synchronization and allowing each network node to send traffic at its own time.

**åœ¨æˆä¸ºIEEEæ ‡å‡†å‰ï¼ŒSpechtç­‰äººæå‡ºäº†Urgency-Based Schedulerï¼ˆUBSï¼‰ï¼Œå¹¶ä½¿ç”¨äº†Length-Rate Quotient (LRQ) and Token Bucket Emulation (TBE)ä¸¤ç§ç®—æ³•ã€‚æœ€ååœ¨IEEE 802.1 Qcråè®®ä¸­ä½¿ç”¨åŸºäºä»¤ç‰Œæ¡¶çš„ATSç®—æ³•ï¼Œå¦‚å›¾æ‰€ç¤ºï¼Œåœ¨TSNäº¤æ¢æœºä¸­æ•°æ®æµå°†é€šè¿‡ä»¤ç‰Œæ¡¶çš„æ–¹å¼æ•´å½¢é˜Ÿåˆ—åˆ†é…ç»™æ•°æ®å¸§èµ„æ ¼æ—¶é—´ï¼Œåˆ°è¾¾é˜Ÿåˆ—å¤´çš„æ•°æ®å¸§é€šè¿‡åˆ¤æ–­èµ„æ ¼æ—¶é—´ä»¥åŠç»è¿‡ä¼˜å…ˆçº§é€‰æ‹©ï¼Œæœ€ç»ˆå’Œå…¶ä»–æœªæ•´å½¢æ•°æ®æµä¸€èµ·è¾“å‡ºã€‚**
Before becoming an IEEE standard, Specht et al. proposed the Urgency-Based Scheduler (UBS) and used two algorithms, Length-Rate Quotient (LRQ) and Token Bucket Emulation (TBE). Finally, the Token Bucket-based ATS algorithm was used in the IEEE 802.1 Qcr protocol as shown in the diagram. In TSN switches, data flows are shaped and queues are allocated to data frames based on token bucket. Data frames reaching the head of the queue are output together with other non-shaped data flows after evaluating their eligibility time and priority selection.


**TSNäº¤æ¢æœºçš„ATSè¾“å‡ºç«¯å£**
Output ports of TSN switches with ATS


**ç›®å‰å·²æœ‰ç ”ç©¶å°†TSNä¸ä»»åŠ¡é“¾ç›¸ç»“åˆï¼Œã€houtanSupportingEndtoendData2023ã€‘é€šè¿‡å®é™…æ±½è½¦æ¡ˆä¾‹å»ºæ¨¡ä»»åŠ¡é“¾å¹¶é€šè¿‡IEEE 802.1 Qbvåè®®ä½œä¸ºç½‘ç»œä¼ è¾“çš„æ¡¥æ¢ã€‚è™½ç„¶TASåœ¨æ–½åŠ ä¸šåŠ¡ç¡®å®šæ€§æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†ä¸¥æ ¼çš„åŒæ­¥è¦æ±‚ï¼Œåˆ™å¢åŠ äº†å¤æ‚æ€§å¹¶å¨èƒåˆ°TSNç½‘ç»œåŸŸçš„å¯é æ€§ã€‚é’ˆå¯¹ä¸€èˆ¬çš„åµŒå…¥å¼å®æ—¶ç³»ç»Ÿåœºæ™¯ï¼Œå¼‚æ­¥ç³»ç»Ÿä»ç„¶è¢«å¹¿æ³›åº”ç”¨ä»¥å‡å°‘å¤æ‚æ€§ä¾‹å¦‚ä½¿ç”¨CANæ€»çº¿ä½œä¸ºç½‘ç»œä¼ è¾“ã€‚æ‰€ä»¥åœ¨æœ¬æ–‡ä¸­æˆ‘ä»¬é€‰æ‹©å¼‚æ­¥çš„IEEE 802.1Qcrä½œä¸ºç½‘ç»œä»»åŠ¡æ ‡å‡†ï¼ŒATSç®—æ³•ä½œä¸ºé˜Ÿåˆ—æ•´å½¢ç®—æ³•ã€‚**
Currently, there have been studies combining TSN with task chains. [houtanSupportingEndtoendData2023] Modeling task chains using real-world automotive cases and using the IEEE 802.1Qbv protocol as a bridge for network transmission. Although TAS performs well in enforcing business determinism, strict synchronization requirements increase complexity and pose a threat to the reliability of TSN network domains. For general embedded real-time system scenarios, asynchronous systems are still widely used to reduce complexity, for example, using the CAN bus as network transmission. Therefore, in this paper, we choose the asynchronous IEEE 802.1Qcr as the network task standard and the ATS algorithm as the queue shaping algorithm.


**è´¡çŒ®ï¼šæˆ‘ä»¬ç ”ç©¶äº†åˆ†å¸ƒå¼å®æ—¶ç³»ç»Ÿä¸ŠåŸºäºTSNç½‘ç»œçš„ä»»åŠ¡é“¾æœ€å¤§ååº”æ—¶é—´ï¼Œæˆ‘ä»¬çš„è´¡çŒ®æ˜¯ï¼š**

**- åœ¨ç¬¬äºŒèŠ‚ä¸­ï¼Œæˆ‘ä»¬ç»™å‡ºäº†åŸºäºTSNç½‘ç»œçš„åˆ†å¸ƒå¼å®æ—¶ç³»ç»Ÿä»»åŠ¡é“¾æ¨¡å‹ï¼ŒåŒ…æ‹¬å•ä¸ªECUä¸Šçš„ä»»åŠ¡æ¨¡å‹å’Œå¤šä¸ªECUé“¾æ¥çš„ç½‘ç»œä»»åŠ¡æ¨¡å‹ã€‚å…¶ä¸­å¤šECUé€šè¿‡TSNç›¸äº’è¿æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„TSNæ ‡å‡†ä¸ºIEEE 802.1Qcrã€‚**
**- åœ¨ç¬¬ä¸‰èŠ‚ä¸­ï¼Œæˆ‘ä»¬å¯¹å¤šECUåœºæ™¯ä¸‹æœ€å¤§ååº”æ—¶é—´è¿›è¡Œåˆ†æï¼Œä¸ºé‡‡ç”¨IEEE 802.1Qcræ ‡å‡†çš„ç½‘ç»œä¼ è¾“ä»»åŠ¡é“¾æä¾›äº†æœ€å¤§ååº”æ—¶é—´ä¸Šç•Œã€‚**
- **åœ¨ç¬¬å››èŠ‚ä¸­ï¼Œæˆ‘ä»¬è¿›è¡Œäº†è¯„ä¼°å¹¶è¯æ˜æå‡ºçš„æ–¹æ³•æé«˜äº†æ€§èƒ½.****
Contribution: We have studied the maximum reaction time of task chains based on TSN networks in distributed real-time systems. Our contributions are:
In Section 2, we present the task chain models for distributed real-time systems based on TSN networks, including the task model for a single ECU and the network task model for multiple ECUs connected through TSN. The TSN standard we use is IEEE 802.1Qcr.
In Section 3, we analyze the maximum reaction time in a multi-ECU scenario, providing upper bounds on the maximum reaction time for network transmission task chains adopting the IEEE 802.1Qcr standard.
In Section 4,  we evaluate and demonstrate that the proposed method improves the performance.

# System Model
**æˆ‘ä»¬å‡è®¾ä¸€ç»„ç”µå­æ§åˆ¶å•å…ƒé€šè¿‡é‡‡ç”¨IEEE 802.1 QCRæ ‡å‡†çš„TSNç½‘ç»œè¿æ¥ã€‚æ¯ä¸ªä»»åŠ¡è¢«é™æ€çš„åˆ†é…ç»™ä¸€ä¸ªECUï¼Œè¯¥ä»»åŠ¡é‡Šæ”¾çš„æ‰€æœ‰ä½œä¸šéƒ½åœ¨åŒä¸€ä¸ªECUä¸Šä»¥å›ºå®šä¼˜å…ˆçº§éæŠ¢å æ¨¡å¼æ‰§è¡Œï¼Œä¸”åœ¨åŒä¸€ä¸ªECUä¸Šä¸å­˜åœ¨å¦ä¸€ä¸ªå¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡ã€‚æ¯ä¸¤ä¸ªECUä¹‹é—´é€šè¿‡ç½‘ç»œè¿æ¥ï¼Œè¿™æ ·ç»„æˆäº†ä¸€æ¡ç®€å•çš„åŸºäºTSNç½‘ç»œçš„è½¦è½½åˆ†å¸ƒå¼ç³»ç»Ÿä»»åŠ¡é“¾ã€‚**
We assume a group of ECUs connected through TSN network using the IEEE 802.1 QCR standard. Each task is statically assigned to one ECU, and all the jobs released by this task are executed on the same ECU in a fixed priority non-preemptive mode. There are no other parallel executing tasks on the same ECU. Each pair of ECUs is connected through the network, forming a simple vehicle distributed system task chain based on TSN network.
## Task Module

**ä¸åŒçš„é€šä¿¡è¯­ä¹‰ä¼šäº§ç”Ÿä¸åŒçš„æ—¶é—´åˆ†æç»“æœã€‚åœ¨è½¦è½½åˆ†å¸ƒå¼ç³»ç»Ÿä¸­é€šå¸¸é‡‡ç”¨ä¸¤ç§é€šä¿¡è¯­ä¹‰ï¼š**
The use of different communication semantics produces varying results in timing analysis, with two communication semantics conventionally employed in vehicular distributed systems:

**éšå¼é€šä¿¡ç”±AUTOSARå®šä¹‰[1]ä¸ºäº†ä¿è¯æ•°æ®ä¸€è‡´æ€§ã€‚éšå¼é€šä¿¡è¯­ä¹‰ä¸­åœ¨ä½œä¸šå¼€å§‹çš„æ—¶å€™è¯»å–æ•°æ®ï¼Œåœ¨ä½œä¸šå®Œæˆçš„æ—¶å€™å†™å…¥æ•°æ®ã€‚**
Implicit communication is defined by AUTOSAR [AUTOSAR] to ensure data consistency. In the implicit communication semantics, data is read at the starting of the task and written at its completion. 


**é€»è¾‘æ‰§è¡Œæ—¶é—´æ˜¯ç”±GIOTTOæ¡†æ¶å¼•å…¥çš„[biondi2018achieving]ï¼Œç›®çš„æ˜¯ä¸ºäº†å‡å°‘æŠ–åŠ¨å¸¦æ¥çš„ä¸ç¡®å®šæ€§ã€‚LETè¯­ä¹‰ä¸­ä»»åŠ¡åœ¨åˆ°è¾¾æ—¶è¯»å–æ•°æ®åœ¨ä¸‹ä¸€å‘¨æœŸåˆ°æ¥å‰å†™å…¥æ•°æ®ã€‚**
Logical Execution Time (LET) was introduced by the GIOTTO framework [biondi2018achieving] with the aim of reducing the uncertainty caused by jitter. In LET semantics, tasks read data upon arrival and write data before the next cycle arrives.


**å›¾1å±•ç°äº†é€šä¿¡è¯­ä¹‰å¯¹äºç«¯åˆ°ç«¯å»¶è¿Ÿåˆ†æçš„å½±å“ã€‚â€œç›´æ¥çš„â€è¡¨ç¤ºæ•°æ®åœ¨æ‰§è¡Œçš„ä»»æ„æ—¶åˆ»è¢«è¯»æˆ–å†™ã€‚LETæ¨¡å‹ä¼šå¯¼è‡´å› æœé“¾å‡ºç°æ›´é•¿çš„ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚æ‰€ä»¥åœ¨æœ¬æ–‡ä¸­æˆ‘ä»¬è€ƒè™‘éšå¼é€šä¿¡ã€‚**
Figure 1 illustrates the impact of communication semantics on end-to-end delay analysis. "Direct" means that data is read or written at any point during execution. The LET model results in longer end-to-end delays due to the causal chain. Therefore, in this paper, we consider implicit communication.

**æˆ‘ä»¬è€ƒè™‘å•ä¸ªECUä¸Šçš„è°ƒåº¦ä»»åŠ¡Ï„ï¼ŒEiæè¿°äº†è°ƒåº¦ä»»åŠ¡Ï„içš„æœ€å·®æ‰§è¡Œæ—¶é—´ï¼ˆWCETï¼‰ã€‚Riæè¿°äº†è°ƒåº¦ä»»åŠ¡Ï„içš„æœ€å·®å“åº”æ—¶é—´ï¼Œå³æ‰€æœ‰è°ƒåº¦ä»»åŠ¡å®ä¾‹ä»åˆ°è¾¾åˆ°å®Œæˆçš„æœ€å¤§æ—¶é—´é—´éš”ã€‚$J^{j}_i$æ˜¯Ï„ié‡Šæ”¾çš„ç¬¬jä¸ªä½œä¸šã€‚å¯¹äºæ‰€æœ‰Ï„ié‡Šæ”¾çš„ä½œä¸šéƒ½ä¸ä»»åŠ¡Ï„iå…·æœ‰ç›¸åŒçš„å±æ€§ã€‚$a^{j}_i$è¡¨ç¤ºä½œä¸šçš„åˆ°è¾¾æ—¶é—´ä»¥åŠ$f^{j}_i$è¡¨ç¤ºç»“æŸæ—¶é—´ã€‚**
We consider the scheduling task Ï„ on a single ECU. Ei describes the worst-case execution time (WCET) of the scheduling task Ï„i. Ri describes the worst-case reaction time of the scheduling task Ï„i, i.e., the maximum time interval from arrival to completion of all scheduling task instances.Â $J^{j}_i$Â is the jth job released by Ï„i. All jobs released by Ï„i have the same attributes as the task Ï„i.Â $a(J^{j}_i)$Â represents the arrival time of the job, and $f(J^{j}_i)$Â Â represents the finish time.


**Biè¡¨ç¤ºè°ƒåº¦ä»»åŠ¡Ï„içš„å›ºå®šå¤§å°ï¼ˆä¸º|Bi|ï¼‰çš„è¾“å…¥ç¼“å†²åŒºã€‚æ¯ä¸ªè°ƒåº¦ä»»åŠ¡Ï„iä»å®ƒçš„è¾“å…¥ç¼“å†²åŒºBiä¸­è¯»å–ç”±å‰é©±ä½œä¸šÏ„i-1äº§ç”Ÿçš„æ•°æ®ï¼Œå¹¶å°†è‡ªå·±äº§ç”Ÿçš„æ•°æ®å†™å…¥å…¶åç»§ä»»åŠ¡Ï„i+1çš„è¾“å…¥ç¼“å†²åŒºBi+1ã€‚
å•ä¸ªECUä¸Šçš„è°ƒåº¦ä»»åŠ¡é‡‡ç”¨äº‹ä»¶è§¦å‘ï¼ˆETï¼‰çš„æ–¹å¼ï¼Œå³å½“å‰ä¸€ä¸ªä½œä¸š$J^{j-1}_i$æ‰§è¡Œå®Œæˆï¼ˆ$f(J^{j-1}_i)$æ—¶åˆ»ï¼‰å†™å…¥ç¼“å†²åŒºåï¼Œåä¸€ä¸ªä»»åŠ¡$J^{j}_i$åœ¨$a(J^{j}_i)$ æ—¶åˆ»è§¦å‘ã€‚åä¸€ä¸ªä½œä¸šçš„è¯»å–æ“ä½œæ—¶åˆ»ä¸ä¼šæ—©äºå‰ä¸€ä¸ªä½œä¸šçš„å†™å…¥æ“ä½œæ—¶åˆ»ã€‚**
$B_i$ represents the fixed size (is $|B_i|$) input buffer of scheduling task $\tau_i$. Each scheduling task $\tau_i$ reads data generated by the predecessor job $\tau_{i-1}$ from its input buffer $B_i$, and writes its own generated data into the input buffer $B_{i+1}$ of the successor task $\tau_{i+1}$. On a single ECU, scheduling tasks are triggered by events (ET), which means that when the previous jobÂ $J^{j-1}_i$Â completes execution (at timeÂ $f(J^{j-1}_i)$), the next jobÂ $J^{j}_i$Â is triggered at timeÂ $a(J^{j}_i)$. The read operation of a subsequent task will not occur earlier than the write operation of the previous task.

## Network Module

**ä¸ºäº†åŒºåˆ«ECUä¸Šæ‰§è¡Œçš„ä»»åŠ¡ï¼Œæˆ‘ä»¬å°†TSNç½‘ç»œä¸­çš„ä»»åŠ¡ç§°ä¸ºç½‘ç»œä»»åŠ¡å¹¶ç”¨m={lï¼Œd}è¡¨ç¤ºï¼Œè€ŒECUä¸Šçš„ä»»åŠ¡æˆ‘ä»¬ä»ç„¶æˆä¸ºä»»åŠ¡ã€‚æˆ‘ä»¬ä½¿ç”¨æ•°æ®å¸§ä½œä¸ºç«¯åˆ°ç«¯åˆ†æçš„ä¸€ä¸ªåŸºæœ¬å•å…ƒã€‚æ‰€ä»¥ç½‘ç»œä»»åŠ¡$m^{i}_j$ä»£è¡¨æºå¸¦ä»»åŠ¡é“¾ä¿¡æ¯çš„æ•°æ®å¸§ï¼Œiä»£è¡¨äº†æ•°æ®å¸§æ‰€åœ¨çš„æµï¼Œå¹¶ä¸”å®ƒæ˜¯æ•°æ®æµiä¸­çš„ç¬¬jä¸ªæ•°æ®å¸§ï¼Œåœ¨æœ¬æ–‡åç»­çš„å†…å®¹ä¸­ã€‚$l(m^{i}_j)$ä»£è¡¨äº†æ•°æ®å¸§çš„é•¿åº¦ã€‚$d(m^{i}_j$)ä»£è¡¨æ•´ä¸ªæ•°æ®å¸§ç»“æŸçš„æ—¶é—´ï¼Œå³æ•°æ®å¸§é€šè¿‡ATSç®—æ³•è·å¾—èµ„æ ¼æ—¶é—´$et(m^{i}_j)$ä¹‹åï¼Œé€šè¿‡ä¼ è¾“ç®—æ³•æ ¹æ®ä¼˜å…ˆçº§ç­‰é€‰æ‹©ï¼Œæœ€åç¦»å¼€çš„æ—¶åˆ»ã€‚åœ¨æ•°æ®å¸§è¿ç»­çš„ä¼ è¾“è¿‡ç¨‹ä¸­ï¼Œèƒ½å¤Ÿç¡®ä¿ä»ä¸€ä¸ªäº¤æ¢æœºæµå‡ºä¹‹åæ‰ä¼šç»è¿‡ç½‘ç»œä¼ è¾“å¹¶æµå…¥åˆ°ä¸‹ä¸€ä¸ªäº¤æ¢æœºä¸­ï¼Œè¿™ç±»ä¼¼äºECUä¸Šä»»åŠ¡å¯¹äºè¯»å†™é¡ºåºçš„çº¦æŸã€‚**
In order to distinguish the scheduling tasks performed on the ECU, we refer to the tasks in the TSN network as network tasks and represent them as m={l, d}, and the tasks on the ECU, we still refer to them as scheduling tasks. We use data frames as the basic unit for end-to-end analysis. Therefore, the network taskÂ $m^{i}_j$Â represents a data frame carrying task chain information, where i indicates the stream the data frame belongs to, and it is the jth data frame in data stream i in the following content.Â $l(m^{i}_j)$Â represents the length of the data frame.Â $d(m^{i}_j)$Â represents the end time of the entire data frame, which is the moment the data frame leaves after obtaining eligibility timeÂ $et(m^{i}_j)$Â through the ATS algorithm and selecting the transmission algorithm based on priority, among other things. During the continuous transmission process of data frames, it ensures that they will only be transmitted through the network and enter the next switch after flowing out from one switch. This is similar to the constraint on the read-write order of tasks on an ECU.

**ATSç®—æ³•æ ¹æ®é˜Ÿåˆ—åˆ†é…è§„åˆ™å†³å®šæ•°æ®å¸§çš„æµå‘ï¼Œå¹¶é€šè¿‡æ‰¿è¯ºä¿¡æ¯é€Ÿç‡ï¼ˆcommitted information rateï¼‰ä»¥åŠæ‰¿è¯ºçš„çªå‘å¤§å°ï¼ˆcommitted burst sizeï¼‰ç¡®å®šæ•°æ®å¸§çš„èµ„æ ¼æ—¶é—´ã€‚
å…¶ä¸­ï¼Œæ•´å½¢é˜Ÿåˆ—éœ€è¦éµå¾ªé˜Ÿåˆ—åˆ†é…çš„è§„åˆ™ï¼Œä»¥ä¸‹æƒ…å†µçš„æ•°æ®å¸§ä¸èƒ½è¢«åˆ†é…åˆ°åŒä¸€ä¸ªæ•´å½¢é˜Ÿåˆ—ï¼š
P1ï¼Œæ¥è‡ªä¸åŒå‘å°„æœº
P2ï¼Œæ¥è‡ªç›¸åŒå‘å°„æœºä½†æ˜¯ä¼˜å…ˆçº§ä¸åŒ
P3ï¼Œåœ¨åŒä¸€ä¸ªå‘å°„æœºä¸­å…·æœ‰ç›¸åŒä¼˜å…ˆçº§ï¼Œä½†æ˜¯æ¥æ”¶å™¨ä¼˜å…ˆçº§ä¸ä¸€æ ·ã€‚**

The ATS algorithm determines the flow direction of data frames based on queue allocation rules, and determines the eligibility time of data frames through committed information rate and committed burst size. 
The shaping queues need to adhere to the rules of queue allocation. The frames in the following situations should not be allocated to the same shaping queue:
P1: Frames from different transmitters. 
P2: Frames from the same transmitter but with different priorities. 
P3: Frames within the same transmitter with the same priority, but different receiver priorities.


**åœ¨æœ¬æ–‡çš„ç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘æœ‰Nä¸ªECUï¼Œæœ€å¤šäº§ç”ŸNä¸ªæµè¿™äº›æ•°æ®æµé€šè¿‡Nä¸ªä»¤ç‰Œæ¡¶æ•´å½¢é˜Ÿåˆ—ã€‚æ¯ä¸ªé˜Ÿåˆ—Qéƒ½å…·æœ‰å›ºå®šä¼˜å…ˆçº§å¹¶ä»¥å…ˆè¿›å…ˆå‡ºçš„æ¨¡å¼ä¼ è¾“æ•°æ®ã€‚$r_n$ä»£è¡¨ç¬¬nä¸ªä»¤ç‰Œæ¡¶çš„é€Ÿç‡ï¼Œä»¥åŠ$b_n$ä»£è¡¨ç¬¬nä¸ªä»¤ç‰Œæ¡¶çš„å¤§å°ï¼ˆå³æœ€å¤§ä»¤ç‰Œæ•°é‡ï¼‰ã€‚
å¯¹äºç½‘ç»œä»»åŠ¡ï¼Œå½“æœŸè¢«åˆ†é…è‡³ä¸€ä¸ªä»¤ç‰Œæ¡¶åï¼Œå®ƒä¹Ÿä¼šè·å¾—çš„æ€§è´¨ï¼Œå³$r_i$ä»£è¡¨äº†ç½‘ç»œä»»åŠ¡$m_i$æ‰€åœ¨é˜Ÿåˆ—çš„é€Ÿç‡ï¼ŒåŒç†$b_i$ä»£è¡¨äº†ç½‘ç»œä»»åŠ¡$m_i$æ‰€åœ¨é˜Ÿåˆ—çš„ä»¤ç‰Œæ¡¶å¤§å°ï¼Œå¹¶æœ‰$l_i\le b_i$ã€‚
å½“ä¸€ä¸ªæ•°æ®å¸§é€šè¿‡æ•´å½¢é˜Ÿåˆ—å¹¶è·å¾—èµ„æ ¼æ—¶é—´åï¼Œä¼ è¾“é€‰æ‹©ç®—æ³•å°†è½®è¯¢é˜Ÿåˆ—å¤´é€‰æ‹©æ•°æ®å¸§ä¼ è¾“ï¼Œåœ¨æœ¬æ–‡çš„ç ”ç©¶ä¸­æˆ‘ä»¬è®¤ä¸ºæ­¤æ—¶åªæ ¹æ®é˜Ÿåˆ—çš„ä¼˜å…ˆçº§é€‰æ‹©æœ€é«˜ä¼˜å…ˆçº§çš„æ•°æ®å¸§è¿›è¡Œä¸‹ä¸€æ­¥ä¼ è¾“ï¼Œè€Œä¸è€ƒè™‘å…¶ä»–å¯èƒ½å­˜åœ¨çš„å¹²æ‰°æƒ…å†µã€‚**
In the system described in this article, we considered there are a total of $N$ ECU. At most, $N$ flows are generated, and these data flows pass through $N$ token bucket shaping queues. Each queue $Q$ has a fixed priority and transfers data in a first-in, first-out mode.Â Committed information rate $r_n$Â represents the rate of the nth token bucket, andÂ committed burst size $b_n$Â represents the size of the nth token bucket (i.e., the maximum number of tokens) with $l_i\le b_i$. 
For network tasks, when assigned to a token bucket, they also acquire properties denoted byÂ $r_i$, representing the rate of the network taskÂ $m_i$Â in the queue, and similarly,Â $b_i$Â represents the token bucket size of the network taskÂ $m_i$Â in the queue.
When a data frame passes through the shaping queue and qualifies for transmission time, the transmission selection algorithm will poll the head of the queue to select the data frame for transmission. In our research, we consider that at this point, only the data frame with the highest priority in the queue is selected for the next transmission step, without considering other possible interference situations.

**åŒæ ·ç±»æ¯”äºå•ä¸ªECUä¸Šçš„ä»»åŠ¡ï¼Œæˆ‘ä»¬è®¤ä¸ºç½‘ç»œä»»åŠ¡ä¹Ÿå…·æœ‰ç±»ä¼¼çš„è¾“å…¥ç¼“å†²åŒºï¼Œå½“æ•°æ®éœ€è¦ä»ä¸€ä¸ªECUä¼ å‘å¦ä¸€ä¸ªECUæ—¶ï¼š
ï¼ˆ1ï¼‰å‰ä¸€ä¸ªECUä¸­æœ€åä¸€ä¸ªå¤„ç†æ•°æ®çš„ä»»åŠ¡ï¼Œå°†å…¶å¤„ç†ä¹‹åçš„æ•°æ®å†™å…¥åˆ°ç¬¬ä¸€ä¸ªç½‘ç»œä»»åŠ¡çš„è¾“å…¥ç¼“å†²åŒºï¼Œå¹¶è§¦å‘æ•°æ®å¸§çš„ä¼ è¾“ä»¥åŠå¼€å§‹é€šè¿‡ATSç®—æ³•è®¡ç®—èµ„æ ¼æ—¶é—´ç­‰ã€‚
ï¼ˆ2ï¼‰ç”±äºATSæ•´å½¢åœ¨ä¸åŒé“¾è·¯ä¸Šéƒ½å…·æœ‰ä¸åŒçš„æƒ…å†µï¼Œä¾‹å¦‚ä¼˜å…ˆçº§ç­‰ï¼Œä¼šå¯¼è‡´æ•°æ®å¸§åˆ†é…åˆ°ä¸åŒçš„ä»¤ç‰Œæ¡¶ä¸­ã€‚ä»¤ç‰Œæ¡¶ä¹Ÿå…·æœ‰ä¸åŒçš„å®¹é‡å’Œé€Ÿç‡ï¼Œæ‰€ä»¥åœ¨æœ¬æ–‡ä¸­æˆ‘ä»¬è®¤ä¸ºæ¯ä¸€è·³éƒ½æ˜¯ä¸€ä¸ªæ–°çš„ç½‘ç»œä»»åŠ¡ã€‚ä¸ä»…ä»…åªæ˜¯ä¸€ä¸ªæ•°æ®å¸§çš„ä¼ è¾“ï¼Œè€Œæ˜¯ç±»æ¯”æˆä»»åŠ¡é“¾ä¸­çš„å¤šä¸ªå‰åè”ç³»çš„ä»»åŠ¡ï¼Œåªä¸è¿‡ä»–ä»¬ä¸å…·æœ‰è®¡ç®—å¹¶æ›´æ–°æ•°æ®çš„åŠŸèƒ½ï¼Œç›¸å½“äºé€šè¿‡è®¡ç®—ä¹‹åä»ç„¶å¾—åˆ°ä¸å˜çš„ç»“æœã€‚
ï¼ˆ3ï¼‰ç»è¿‡å¤šä¸ªç½‘ç»œä»»åŠ¡ä¹‹åï¼Œåœ¨æœ€åä¸€è·³æ•°æ®å¸§å°†é€šè¿‡ä¼ è¾“åå†™å…¥åä¸€ä¸ªECUçš„è¾“å…¥ç¼“å†²åŒºï¼Œä»¥å®Œæˆæ•°æ®åœ¨ä¸¤ä¸ªECUä¹‹é—´çš„ä¼ è¾“ã€‚**
Similar to tasks on a single ECU, we believe that network tasks also have similar input buffers when data needs to be transmitted from one ECU to another: 
(1) The last task that processes data in the previous ECU writes its processed data into the input buffer of the first network task, triggering the transmission of data frames and initiating the calculation of qualification time using ATS algorithm, and so on.
(2) Due to different situations, such as priority, in ATS shaping on different links, data frames may be allocated to different token buckets. Token buckets also have different capacities and rates. Therefore, in this paper, we consider each hop as a new network task. It is not just the transmission of a data frame, but rather analogous to multiple interconnected tasks in a task chain, except that they do not have the function of computing and updating data and instead produce unchanged results through computation. 
(3) After going through multiple network tasks, the data frame in the last hop will be written into the input buffer of the next ECU after transmission, completing the data transfer between the two ECUs.

## Task Chains
**æˆ‘ä»¬è€ƒè™‘ç”±ä¸€ç³»åˆ—äº‹ä»¶cç»„æˆçš„ä»»åŠ¡é“¾C={z, c0ï¼Œc1ï¼Œc2ï¼Œ...ï¼Œcn}ã€‚æ‰€æœ‰äº‹ä»¶cæŒ‰åºå¤„ç†åœ¨tæ—¶åˆ»å¤–éƒ¨äº‹ä»¶zäº§ç”Ÿçš„åˆå§‹æ•°æ®ï¼Œå¹¶åœ¨æ—¶åˆ»t'ç”±æœ€åä¸€ä¸ªäº‹ä»¶cnäº§ç”Ÿå…³äºè¯¥æ•°æ®çš„æœ€ç»ˆç»“æœã€‚**

We consider a task chain C consisting of a series of events $C=\{z, c_0, c_1, c_2, ..., c_n\}$. All events in c process the initial data generated by external event $z$ at time $t$ sequentially and produce the final result regarding that data at time $t'$ by the last event $c_n$.

**å®šä¹‰1ï¼ˆä»»åŠ¡é“¾ï¼‰ï¼šä»»åŠ¡é“¾C={z, c0ï¼Œc1ï¼Œc2ï¼Œ...ï¼Œcn}æ»¡è¶³ï¼š
- ä»»åŠ¡é“¾Cä¸­çš„äº‹ä»¶c0å’Œcnåªèƒ½æ˜¯è°ƒåº¦ä»»åŠ¡ $\tau_0$ and $\tau_n$,ï¼Œå³c0å’Œcnåªèƒ½å­˜åœ¨äºECUä¸Šã€‚
- c0æ˜¯ä¸€ä¸ªECUä¸Šçš„å‘¨æœŸæ€§è°ƒåº¦ä»»åŠ¡$\tau_0$ï¼Œä¸”å‘¨æœŸä¸ºTï¼Œç”¨æ¥å®šæœŸæ•æ‰å¤–éƒ¨äº‹ä»¶z
- å¯¹äºå¤–éƒ¨äº‹ä»¶zï¼Œå½“ä¸”ä»…å½“å…¶å‘ç”Ÿåœ¨CPUç©ºé—²æ—¶æ‰æœ‰æ•ˆã€‚
- å¯¹äºä»»æ„äº‹ä»¶ci ï¼ˆ1<i<n-1ï¼‰ï¼Œå¯ä»¥æ˜¯è°ƒåº¦ä»»åŠ¡ä¹Ÿå¯ä»¥æ˜¯ç½‘ç»œä»»åŠ¡ã€‚
- ä¸å­˜åœ¨ä¸¤ä¸ªè¿ç»­çš„äº‹ä»¶ciå’Œci-1ï¼ˆ1<i<n-1ï¼‰ä¸ºåˆ†åˆ«åœ¨ä¸åŒECUä¸Šæ‰§è¡Œçš„è°ƒåº¦ä»»åŠ¡æƒ…å†µã€‚åœ¨ä»»åŠ¡é“¾ä¸Šï¼Œä¸åŒECUä¸Šæ‰§è¡Œçš„ä¸¤ä¸ªè°ƒåº¦ä»»åŠ¡ä¸­é—´è‡³å°‘æœ‰ä¸€ä¸ªç½‘ç»œä»»åŠ¡ä½œä¸ºè¿æ¥ã€‚ä¾‹å¦‚ï¼Œci-1å’Œ ci+1ä¸ºä¸åŒECUä¸Šçš„è°ƒåº¦ä»»åŠ¡ï¼Œåˆ™ciä¸ºä¸€ä¸ªç½‘ç»œä»»åŠ¡ã€‚**
Definition 1 (Task Chain): a task chain C = {z, c0, c1, c2, ... , cn} are satisfied:
- The events c0 and cn in the task chain C can only be scheduling tasks $\tau_0$ and $\tau_n$, i.e., c0 and cn can only exist on the ECU.
-  c0 is a periodic scheduling task $\tau_0$ on an ECU with period T that is used to periodically capture external events z.
- For external event z, it is valid when and only when it occurs when the CPU is idle.
- For any event ci (1<i<n-1), it can be either a scheduling task or a network task.
- There is no case where two consecutive events ci and ci-1 (1<i<n-1) are scheduling tasks executed on separate ECUs. In the task chain, there is at least one network task as a connection between two scheduling tasks executed on different ECUs. For example, if ci-1 and ci+1 are scheduling tasks on different ECUs, then ci is a network task.
> åº”åœ¨è¿™é‡Œè¡¥ä¸€å¥å‡è®¾ï¼Œå¤–éƒ¨äº‹ä»¶zåœ¨é‡‡æ ·ä»»åŠ¡ï¼Œé‡Šæ”¾çš„ä½œä¸šç»“æŸåï¼Œè§¦å‘æ‰æœ‰æ•ˆ


**å®šä¹‰2ï¼ˆååº”æ—¶é—´ï¼‰ï¼šä»»åŠ¡é“¾çš„ååº”æ—¶é—´è¡¨ç¤ºä¸ºR(c)**
Rï¼ˆcï¼‰= t'-t =  f(cn) - t(z)
Definition 2 (reaction time): the reaction time of a task chain is expressed as R(c)

**å®šä¹‰3 ï¼ˆæœ€å¤§ååº”æ—¶é—´ï¼‰ï¼šä»»åŠ¡é“¾çš„æœ€å¤§ååº”æ—¶é—´RT(c)æ˜¯ä»»åŠ¡é“¾cæ‰€æœ‰å¯èƒ½è·¯å¾„çš„æœ€å¤§å€¼**
RT(c) = max{R(c)}
Definition 3 (Maximum reaction time): the maximum reaction time RT(c) of a task chain is the maximum of all possible paths of the task chain c
## An Illustrative Example

**åœ¨å›¾ä¸­ï¼Œä»»åŠ¡é“¾ç”±å¤–éƒ¨äº‹ä»¶zã€ä¸‰ä¸ªè°ƒåº¦ä»»åŠ¡å’Œä¸¤ä¸ªç½‘ç»œä»»åŠ¡ç»„æˆ$C = \{z, \tau_0, \tau_1, m_1, m_2, \tau_2\}$ã€‚è°ƒåº¦ä»»åŠ¡$\tau_0, \tau_1$å’Œ$\tau_2$è¢«é™æ€çš„åˆ†é…ç»™äº†ä¸åŒçš„ä¸¤ä¸ªECUï¼Œä»–ä»¬é€šè¿‡ä¸¤ä¸ªäº¤æ¢æœºæ­å»ºé€šä¿¡ç½‘ç»œã€‚å…¶ä¸­ä»»åŠ¡$\tau_0$, $\tau_1$å’Œ$\tau_2$çš„æœ€å·®æ‰§è¡Œæ—¶é—´åˆ†åˆ«ä¸º$E_0=3$ã€$E_1=3$ã€$E_2=3$ã€‚ä»»åŠ¡$\tau_0$çš„å‘¨æœŸ$T=6$ã€‚æ ¹æ®ä»»åŠ¡é‡Šæ”¾ä½œä¸šçš„æƒ…å†µæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥å°†ä»»åŠ¡é“¾Cè¡¨ç¤ºä¸º$C = \{z, J_0^2, J_1^1, m_1^2, m_2^2, J_2^3\}$ã€‚**
In the figure, the task chain consists of external event z, three scheduling tasks, and two network tasks, denoted asÂ $C = \{z, \tau_0, \tau_1, m_1, m_2, \tau_2\}$. The scheduling tasksÂ $\tau_0, \tau_1$, andÂ $\tau_2$Â are statically allocated to two different ECUs, and they are connected through two switches to establish a communication network. The worst-case execution times for tasksÂ $\tau_0, \tau_1$, andÂ $\tau_2$Â areÂ $E_0=3$,Â $E_1=3$, andÂ $E_2=3$Â respectively. The period of taskÂ $\tau_0$Â isÂ $T=6$. Based on the task release order, the task chain C can be further represented asÂ $C = \{z, J_0^2, J_1^1, m_1^2, m_2^2, J_2^3\}$.

**åœ¨$t=4$çš„æ—¶åˆ»ç³»ç»Ÿäº§ç”Ÿäº†å¤–éƒ¨äº‹ä»¶å¹¶å†™å…¥ç›¸å…³çš„åˆå§‹æ•°æ®åˆ°ä»»åŠ¡$J_0^2$çš„è¾“å…¥ç¼“å†²åŒº$B_0$ã€‚æ­¤æ—¶CPUç©ºé—²ï¼Œå¤–éƒ¨äº‹ä»¶zæœ‰æ•ˆã€‚åœ¨$t=10$æ—¶åˆ»ECU1ä¸Šçš„è°ƒåº¦ä»»åŠ¡$J_0^2$ç»“æŸå¹¶å°†æ›´æ–°åçš„æ•°æ®å†™å…¥ä»»åŠ¡$J_1^1$çš„è¾“å…¥ç¼“å†²åŒº$B_1$ã€‚å½“ä»»åŠ¡$J_1^1$ç»“æŸåï¼Œäº§ç”Ÿçš„è¾“å‡ºå°†å¼€å§‹é€šè¿‡ç½‘ç»œä¼ è¾“åˆ°ECU2ï¼Œå¹¶åœ¨$t=17$æ—¶åˆ»å…¥é˜Ÿï¼Œé€šè¿‡ATSæ•´å½¢ç®—æ³•ï¼Œå¹¶åœ¨$t=21$æ—¶åˆ»æ•´ä¸ªæ•°æ®å¸§åœ¨äº¤æ¢æœº1ç»“æŸã€‚ç±»ä¼¼çš„åœ¨$t=32$æ—¶åˆ»ï¼Œæ•°æ®å¸§ç”±äº¤æ¢æœº2ä¼ è¾“åˆ°ECU2ã€‚æœ€ååœ¨$t=36$æ—¶åˆ»äº§ç”Ÿå…³äºå¤–éƒ¨äº‹ä»¶zçš„æœ€ç»ˆæ•°æ®ç»“æœã€‚å¦‚å›¾æ‰€ç¤ºï¼Œå¤„ç†å¤–éƒ¨äº‹ä»¶zçš„ä»»åŠ¡é“¾çš„ååº”æ—¶é—´ä¸º$R(C)=36-4=32$**
At timeÂ $t=4$, an external event occurs and relevant initial data is written into the input bufferÂ $B_0$Â of taskÂ $J_0^2$. At this time the CPU is idle and the external event z is valid. At timeÂ $t=10$, scheduling taskÂ $J_0^2$Â on ECU1 finishes and updates the data, which is then written into the input bufferÂ $B_1$Â of taskÂ $J_1^1$. After taskÂ $J_1^1$Â completes, the generated output starts to be transmitted through the network to ECU2. At timeÂ $t=17$, the output is enqueued and goes through the ATS shaping algorithm, and the entire data frame is finished at switch 1 atÂ $t=21$. Similarly, at timeÂ $t=32$, the data frame is transmitted from switch 2 to ECU2. Finally, at timeÂ $t=36$, the final data result regarding external event z is produced. As shown in the figure, the reaction time of the task chain handling external event z isÂ $R(C) = 36-4 = 32$.
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202312252207793.png)
# maximum reaction time analysis
> èµ„æºæœåŠ¡æ›²çº¿
è€ƒè™‘ä»»åŠ¡è¢«è·³è¿‡ï¼ˆç¼“å†²åŒºæ»¡æº¢å‡ºï¼‰

**åœ¨æœ¬èŠ‚ä¸­æˆ‘ä»¬å°†è®¨è®ºæœ€å¤§ååº”æ—¶é—´çš„ä¸Šç•Œï¼Œå‚è€ƒã€ã€‘æˆ‘ä»¬å‡è®¾è°ƒåº¦ä»»åŠ¡çš„ç¼“å†²åŒºæ˜¯å›ºå®šå¤§å°çš„ï¼Œè€Œä¸”å­˜åœ¨ç¼“å†²åŒºæ»¡æ•°æ®å¸§æº¢å‡ºçš„æƒ…å†µã€‚ä½†å¯¹äºåŸºäºATSç®—æ³•ç½‘ç»œä»»åŠ¡ç°æœ‰çš„åˆ†æå¤§éƒ¨åˆ†åŸºäºLRQæˆ–æ˜¯TBEï¼Œå¹¶ä¸”åªè€ƒè™‘TSNç½‘ç»œæœ¬èº«ï¼Œå¹¶ä¸é€‚ç”¨äºä»»åŠ¡é“¾çš„åˆ†æã€‚æ‰€ä»¥æˆ‘ä»¬å°†åŸºäºATSç®—æ³•ç½‘ç»œä»»åŠ¡éƒ¨åˆ†åˆ†æä¸ç°æœ‰ECUè°ƒåº¦ä»»åŠ¡é“¾åˆ†ææ•´åˆï¼Œæ‰©å±•åˆ°é€šè¿‡TSNç½‘ç»œäº’è”çš„å¤šä¸ªECUä¹‹é—´çš„ä»»åŠ¡é“¾æœ€å¤§ååº”æ—¶é—´ä¸Šç•Œåˆ†æã€‚**
In this section, we will discuss the upper bound of the maximum reaction time. Referring to [], we assume that the buffer for scheduling tasks is of a fixed size, and there is a possibility of buffer overflow. However, most of the existing analysis for network tasks based on the ATS algorithm is based on LRQ or TBE, and only considers the TSN network itself, which is not suitable for analyzing task chains. Therefore, we will integrate the partial analysis of network tasks based on the ATS algorithm with the existing analysis of ECU scheduling task chains, and extend it to analyze the upper bound of the maximum reaction time for task chains between multiple ECUs interconnected through the TSN network.

**å®šä¹‰4 ï¼ˆç»“æŸæ—¶é—´ï¼‰ï¼šå¯¹äºä»»åŠ¡é“¾$C = \{z, c_0, c_1, c_2, ... , c_n\}$ä¸­çš„æ¯ä¸€ä¸ªäº‹ä»¶ï¼Œ$t(\cdot )$ä¸ºäº‹ä»¶çš„ç»“æŸæ—¶é—´ï¼š
**- å¯¹äºå¤–éƒ¨äº‹ä»¶zï¼Œ$t(z)$ä¸ºå¤–éƒ¨äº‹ä»¶å‘ç”Ÿçš„æ—¶é—´ã€‚**
**- å¯¹äºECUä¸Šçš„è°ƒåº¦ä»»åŠ¡$\tau_i$æ¥è¯´$t(c_i)$ä¸ºè°ƒåº¦ä»»åŠ¡$\tau_i$çš„ç»“æŸæ—¶é—´$f(c_i)$ã€‚**
**- å¯¹äºç½‘ç»œä»»åŠ¡$m_i$æ¥è¯´$t(c_i)$ä¸ºç»“æŸæ—¶é—´$d(c_i)$ã€‚****
Definition 4 (End Time): For each event in a task chainÂ $C = \{z, c_0, c_1, c_2, ..., c_n\}$,Â $t(\cdot)$Â represents the end time of the event: 
- For an external event z,Â $t(z)$Â is the time at which the external event occurs. 
- For a scheduling taskÂ $\tau_i$Â on the ECU,Â $t(c_i)$Â is the end timeÂ $f(c_i)$Â of the scheduling taskÂ $\tau_i$. 
- For a network taskÂ $m_i$,Â $t(c_i)$Â is the end timeÂ $d(c_i)$.

$$t(\cdot)=
\begin{array}{l} 
  \left\{\begin{matrix} 
  t(z)  & \text{if an external event}\\
t(c_i)=f(c_i) & \text{if a scheduling task}\quad\tau_i\\
d(c_i) & \text{if a network task}\quad m_i\\
\end{matrix}\right.    
\end{array} $$ 

**åŸºäºå…¬å¼ï¼ˆï¼‰ï¼Œå¯¹äºååº”æ—¶é—´æˆ‘ä»¬å¯ä»¥å°†å…¶è¡¨ç¤ºä¸ºï¼š**
Based on formula (), For reaction time, we can express it as:
$$\begin{equation}
\begin{aligned}
R(C) & = t'-t\\
     & = t(c_n) - t(z)\\
     & = t(c_0) - t(z) + \sum_{i=1}^{n}(t(c_i) - t(c_{i-1}))\\
     & = t(c_0) - r(c_0) + r(c_0) - t(z) + \sum_{i=1}^{n}(t(c_i) - t(c_{i-1}))\\
     & = f(c_0) - t(z) + \sum_{i=1}^{n}(t(c_i) - t(c_{i-1}))\\
\end{aligned}
\end{equation}$$

**åˆ™æœ€å¤§ååº”æ—¶é—´æ ¹æ®å…¬å¼ï¼ˆï¼‰ä¸ºmax{f(c_0) - t(z) + \sum_{i=1}^{n}(t(c_i) - t(c_{i-1}))}**
The maximum reaction time is determined according to formula () is $\max\{f(c_0) - t(z) + \sum_{i=1}^{n}(t(c_i) - t(c_{i-1}))\}$

**æ ¹æ®å…¬å¼ï¼ˆ4ï¼‰æˆ‘ä»¬å¯ä»¥å¯¹ä»»åŠ¡é“¾Cçš„çš„æœ€å¤§ååº”æ—¶é—´åˆ†æ®µæ±‚å–ä¸Šç•Œã€‚æˆ‘ä»¬å°†ä»»åŠ¡é“¾Cçš„æœ€å¤§ååº”æ—¶é—´åˆ†ä¸ºä¸¤éƒ¨åˆ†**
Based on formula (4), we can obtain upper bounds for the maximum reaction time of task chain C in segments. We divide the maximum reaction time of task chain C into two parts.

**Part one. $f(c_0)-t(z)$çš„ä¸Šç•Œ**
Part \uppercase\expandafter{\romannumeral1}. The upper bound ofÂ $f(c_0)-t(z)$.


**å¼•ç†1ï¼ŒThe upper bound of $f(c_0)-t(z)$ is $f(c_0)-t(z) \le T$**
Lemma 1,Â $f(c_0)-t(z) \le T$.


**è¯æ˜ï¼Œæ ¹æ®å®šä¹‰ï¼ˆ1ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—äº‹ä»¶$c_0$çš„å®šä¹‰ï¼Œå³äº‹ä»¶$c_0$å¿…ç„¶æ˜¯ä¸€ä¸ªè°ƒåº¦ä»»åŠ¡ä¸º$\tau_0$ï¼Œæ‰€ä»¥æ ¹æ®å®šä¹‰ï¼ˆ4ï¼‰è°ƒåº¦ä»»åŠ¡$\tau_0$çš„ç»“æŸæ—¶é—´ä¸º$f(\tau_0)=f(c_0)$ã€‚ç»§ç»­ä½¿ç”¨å®šä¹‰ï¼ˆ1ï¼‰ï¼Œäº‹ä»¶$c_0$ï¼ˆè°ƒåº¦ä»»åŠ¡$\tau_0$ï¼‰ä»¥Tä¸ºå‘¨æœŸæ•æ‰å¤–éƒ¨äº‹ä»¶zï¼Œæ‰€ä»¥å½“å¤–éƒ¨äº‹ä»¶åœ¨t(z)å¼€å§‹è§¦å‘ä¹‹åæœ€æ™šåœ¨ä¸€ä¸ªå‘¨æœŸTä¹‹å†…ï¼Œå®ƒå°†è¢«è°ƒåº¦ä»»åŠ¡$\tau_0$æ•æ‰ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å¾—åˆ°$f(c_0)-t(z)$çš„ä¸Šç•Œä¸ºTã€‚**
Proof: According to definition (1), we can obtain the definition of eventÂ $c_0$, which states that eventÂ $c_0$Â must necessarily be scheduled as taskÂ $\tau_0$. Thus, based on definition (4), the completion time of taskÂ $\tau_0$Â isÂ $f(\tau_0)=f(c_0)$.Continuing with definition (1), eventÂ $c_0$Â (taskÂ $\tau_0$) captures external eventÂ $z$Â with a period ofÂ $T$. Therefore, when the external event is triggered atÂ $t(z)$Â or later, it will be captured by taskÂ $\tau_0$Â within a maximum period ofÂ $T$. Hence, we can conclude that the upper bound ofÂ $f(c_0)-t(z)$Â isÂ $T$.

> å‡è®¾å¤–éƒ¨äº‹ä»¶zï¼Œåªåœ¨é‡‡æ ·ä»»åŠ¡Ï„0é‡Šæ”¾çš„ä½œä¸šï¼Œå®Œæˆä¹‹åæ‰èƒ½æœ‰æ•ˆè§¦å‘
> ä¹Ÿå°±æ˜¯è¯´ f(J01) < t(z) < r(J02)
> å› ä¸ºå¦‚æœå¤–éƒ¨äº‹ä»¶zåœ¨ä½œä¸šJ01ç»“æŸå‰è§¦å‘ï¼Œé‚£ä¹ˆå®ƒå°†ç”±ä½œä¸š0æ•æ‰ï¼Œä½†ä¸ä¸€å®šèƒ½å¤„ç†å®Œæˆä¼ é€’æ•°æ®ï¼Œæ‰€ä»¥å‡è®¾å®Œæˆä¹‹åæ‰èƒ½æœ‰æ•ˆçš„è§¦å‘
> é‡‡æ ·ä»»åŠ¡å…·æœ‰ç›¸åŒçš„WCET
> é‚£ä¹ˆï¼Œç›¸é‚»ä¸¤ä¸ªä½œä¸šçš„ç»“æŸæ—¶é—´ä¹‹å·®ï¼Œä¸Šç•Œä¸ºT
>æ‰€ä»¥ f(c0)-t(z)ä¸Šç•Œä¸ºT

**Part two. $t(c_i)-t(c_{i-1})$çš„ä¸Šç•Œ**
PartÂ two. The upper bound ofÂ $t(c_i)-t(c_{i-1})$.

**å®šä¹‰5ï¼Œäº‹ä»¶çŠ¶æ€ã€‚ä¸ºäº†ç®€åŒ–è¡¨è¾¾ä¾¿äºåˆ†æï¼Œæˆ‘ä»¬ä½¿ç”¨$s(\cdot)$è¡¨ç¤ºä»»åŠ¡é“¾$C = \{z, c_0, c_1, c_2, ... , c_n\}$ä¸­æ¯ä¸ªäº‹ä»¶çš„çŠ¶æ€ï¼Œå³å¯¹äºä»»æ„ä¸€ä¸ªäº‹ä»¶$c_i$å®ƒä»£è¡¨çš„ä»»åŠ¡ç±»å‹ã€‚
**- å¦‚æœæ˜¯è°ƒåº¦ä»»åŠ¡ï¼Œåˆ™$s(c_i)=\tau$,**
**- å¦‚æœæ˜¯ç½‘ç»œä»»åŠ¡ï¼Œåˆ™$s(c_i)=m$,****
 Definition 5, Event Status. In order to simplify the expression for ease of analysis, we useÂ $s(\cdot)$Â to represent the status of each event in the task chainÂ $C = \{z, c_0, c_1, c_2, ..., c_n\}$, i.e., for any eventÂ $c_i$, it represents the type of task it stands for.
- If it is a scheduling task, thenÂ $s(c_i) = \tau$,
- If it is a network task, thenÂ $s(c_i) = m$.
- $$s(c_i)=
\begin{array}{l} 
  \left\{\begin{matrix} 
\tau  & \text{if a scheduling task}\\
m  & \text{if a network task}\\
\end{matrix}\right.    
\end{array} $$


**å¼•ç†2ï¼Œ$t(c_i)-t(c_{i-1}) \le D$ 
å…¶ä¸­ï¼Œ**
Lemma 2,Â $t(c_i)-t(c_{i-1}) \le D$,
where

$$D=\begin{array}{l} 
\left\{\begin{matrix} 
\alpha  & s(c_i)=\tau, s(c_{i-1})=\tau\\
\theta +t   & s(c_i)=m\\
\alpha  +t  & s(c_i)=\tau, s(c_{i-1})=m\\
\end{matrix}\right.    
\end{array}$$


**å¯¹äºP2éƒ¨åˆ†æˆ‘ä»¬åˆ†ä¸ºä¸‰ç§æƒ…å†µè®¨è®ºä»–ä»¬çš„ä¸Šç•Œã€‚**
For the P2 part, we divide it into three cases to discuss their upper bounds.

**case1ï¼š$s(c_i)=\tau, s(c_{i-1})=\tau$ã€‚å³å‰åç›¸é‚»çš„ä¸¤ä¸ªäº‹ä»¶ä¸­ï¼Œå‰ä¸€ä¸ªäº‹ä»¶$c_{i-1}$ä¸ºè°ƒåº¦ä»»åŠ¡$\tau_{i-1}$ ï¼Œåä¸€ä¸ªä»»åŠ¡$c_i$ä¹Ÿæ˜¯è°ƒåº¦ä»»åŠ¡$\tau_i$ ã€‚**
Case 1:Â $s(c_i) = \tau, s(c_{i-1}) = \tau$. In other words, in the adjacent events, the previous eventÂ $c_{i-1}$Â is a scheduling taskÂ $\tau_{i-1}$, and the subsequent taskÂ $c_i$Â is also a scheduling taskÂ $\tau_i$.

**è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å‚è€ƒã€ã€‘ä¸­å¯¹äºå›ºå®šå¤§å°ç¼“å†²åŒºäº‹ä»¶è§¦å‘é“¾çš„æ—¶é—´ä¸Šé™ã€‚
ä»¤$\alpha=\max\{\overline{\beta_i^l}((|B_i| + 1)\cdot E_i), DLY_i(|B_i|)\}$**
In this case, we refer to the time upper bound for fixed-size buffer event-triggered chains discussed in [reference]. Let $\alpha=\max\{\overline{\beta_i^l}((|B_i| + 1)\cdot E_i), DLY_i(|B_i|)\}$

**å…¶ä¸­$\overline{\beta(\cdot)}$ä¸ºèµ„æºæ›²çº¿å‡½æ•°$\beta(\Delta )$çš„ä¼ªé€†å‡½æ•°ï¼Œè¡¨ç¤ºç³»ç»Ÿå¤„ç†ä¸€å®šå·¥ä½œè´Ÿè½½æ‰€éœ€è¦çš„æ—¶é—´ã€‚è€Œ$DLY_i(|B_i|)$æ˜¯ä½œä¸šçš„æœ€å¤§å»¶è¿Ÿã€‚**
In this equation,Â $\overline{\beta(\cdot)}$Â represents the pseudo-inverse function of the resource curve functionÂ $\beta(\Delta)$, which indicates the time required for the system to process a certain workload.Â $DLY_i(|B_i|)$Â represents the maximum delay of the job

**æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å¾—åˆ°å½“$s(c_i)=\tau, s(c_{i-1})=\tau$æ—¶ï¼Œ$D=\alpha= \max\{\overline{\beta_i^l}((|B_i| + 1)\cdot E_i), DLY_i(|B_i|)\}$**
Therefore, we can obtain that whenÂ $s(c_i)=\tau$Â andÂ $s(c_{i-1})=\tau$,Â $D=\alpha= \max\{\overline{\beta_i^l}((|B_i| + 1)\cdot E_i), DLY_i(|B_i|)\}$.


**case2ï¼š$s(c_i)=m$ã€‚å³å‰åç›¸é‚»çš„ä¸¤ä¸ªäº‹ä»¶ä¸­ï¼Œåä¸€ä¸ªä»»åŠ¡$c_i$æ˜¯è°ƒåº¦ä»»åŠ¡$m_i$ ï¼Œè€Œå‰ä¸€ä¸ªäº‹ä»¶ä¸å—é™åˆ¶ $c_{i-1}=\tau_{i-1}$ or $m_{i-1}$**
Case 2:Â $s(c_i)=m$. In other words, in the two consecutive events, the subsequent taskÂ $c_i$Â is scheduled as a taskÂ $m_i$, while the preceding event is not restricted,Â $c_{i-1}=\tau_{i-1}$Â orÂ $m_{i-1}$.

**å¦‚å›¾1æ‰€ç¤ºï¼Œæˆ‘ä»¬è€ƒè™‘æ•°æ®ï¼ˆ1ï¼‰åœ¨ä¸€ä¸ªECUä¸Šä¼ å…¥ç½‘ç»œï¼›(2)ç½‘ç»œä¸­ä¸åŒäº¤æ¢æœºä¹‹é—´ä¼ è¾“ï¼›(3)ç½‘ç»œä¸­æœ€åä¸€è·³ä¼ è¾“åˆ°å¦ä¸€ä¸ªECUã€‚è¿™ä¸‰ç§æƒ…å†µä¸‹ï¼Œæ ¹æ®ç½‘ç»œå¸¦å®½ä»¥åŠæ•°æ®å¤§å°ï¼Œåœ¨ä¸€æ¡ä»»åŠ¡é“¾çš„åˆ†æä¸­ï¼Œæ•°æ®ä¼ è¾“å…·æœ‰ç›¸åŒçš„å»¶è¿Ÿä¸ºtï¼ˆæ•°æ®å¤§å°/å¸¦å®½ï¼‰ã€‚**
As shown in Figure 1, we consider the following scenarios in the analysis of a task chain: (1) Data input from an ECU into the network, (2) Transmission between different switches in the network, and (3) Final hop transmission to another ECU in the network. In these three scenarios, based on the network bandwidth and data size, data transmission has the same delay of t (data size/bandwidth) in the analysis of a task chain.

**å¯¹äºç½‘ç»œä»»åŠ¡ï¼Œæ ¹æ®ä»¤ç‰Œæ¡¶ç®—æ³•æˆ‘ä»¬çŸ¥é“æ•°æ®å¸§çš„å»¶è¿Ÿä¼šå—åˆ°(1)é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—çš„æµï¼›(2)ä½ä¼˜å…ˆçº§é˜Ÿåˆ—çš„æµï¼›(3)åŒç­‰ä¼˜å…ˆçº§ç«äº‰çš„æµï¼›(4)æ•°æ®æµæœ¬èº«çš„æ€§è´¨ï¼›(5)å½“å‰ä»¤ç‰Œæ¡¶æ€§è´¨çš„å½±å“ã€‚æ‰€ä»¥æ ¹æ®Spechtç­‰äººåœ¨ã€ã€‘æ‰€æ±‚çš„ä¸Šç•Œï¼Œä»¥åŠã€TimeSensitiveNetworking2021ã€‘å¯å¾—åˆ°
$(\frac{b_H+b_j+l_L}{r-r_H} + \frac{l_i}{r})$ï¼Œå…¶ä¸­$H$ï¼Œ$L$ï¼Œ$j$åˆ†åˆ«è¡¨ç¤ºäº†é«˜ä¼˜å…ˆçº§ã€ä½ä¼˜å…ˆçº§ä¸ç«äº‰æµçš„ç´¢å¼•ã€‚å¹¶ä¸”å–å¾—é«˜ä¼˜å…ˆçº§æµÂ committed burst sizeçš„é›†åˆ$b_H$ï¼Œç«äº‰çš„åˆé›†$b_j$ï¼Œä»¥åŠä½ä¼˜å…ˆçº§ä¸­æœ€å¤§å¸§é•¿åº¦$l_L$ï¼Œ** å…¶ä¸­ $r>\sum_{k\in H\cup j\cup i }r_k$
> $(\frac{b_H+b_j+b_i-l_i+l_L}{r-r_H} + \frac{l_i}{r})$


For network tasks, according to the token bucket algorithm, we know that the delay of data frames is influenced by (1) flows in the high priority queue, (2) flows in the low priority queue, (3) flows competing with equal priority, (4) the nature of the data flow itself, and (5) the current nature of the token bucket.
Therefore, based on the upper bound obtained by Specht et al. in ã€ã€‘and ã€TimeSensitiveNetworking2021ã€‘, we can obtainÂ $(\frac{b_H+b_j+l_L}{r-r_H} + \frac{l_i}{r})$, whereÂ $H$,Â $L$, andÂ $j$Â respectively represent the indices of the high-priority, low-priority, and competing flows.  And obtain a collection of high priority flows with committed burst sizeÂ $b_H$, a set of competing burst sizesÂ $b_j$, and the maximum frame lengthÂ $l_L$Â in low priority.
Where $r>\sum_{k\in H\cup j\cup i }r_k$
![image.png](https://cdn.jsdelivr.net/gh/wsm6636/pic/202311171713154.png)


**æ‰€ä»¥å¯¹äº$r_H + r_j + r_i \le r$æˆ‘ä»¬å¯ä»¥å¾—åˆ°å½“$s(c_i)=m$æ—¶ï¼Œ$D=\theta+t=(\frac{b_H+b_j+l_L}{r-r_H} + \frac{l_i}{r})+t$**
So we can obtain , for $r_H + r_j + r_i \le r$, that whenÂ $s(c_i)=m$,$D=\theta+t=(\frac{b_H+b_j+l_L}{r-r_H} + \frac{l_i}{r})+t$.


**case3ï¼š$s(c_i)=\tau, s(c_{i-1})=m$ã€‚å³å‰åç›¸é‚»çš„ä¸¤ä¸ªäº‹ä»¶ä¸­ï¼Œå‰ä¸€ä¸ªäº‹ä»¶$c_{i-1}$ä¸ºç½‘ç»œä»»åŠ¡$m_{i-1}$ ï¼Œåä¸€ä¸ªä»»åŠ¡$c_i$æ˜¯è°ƒåº¦ä»»åŠ¡$\tau_i$ ã€‚**
Case 3:Â $s(c_i)=\tau, s(c_{i-1})=m$. That is, in the sequence of two consecutive events, the first eventÂ $c_{i-1}$Â is a network taskÂ $m_{i-1}$, and the second taskÂ $c_i$Â is a scheduling taskÂ $\tau_i$.

**åœ¨è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬éœ€è¦å°†ç½‘ç»œä¼ è¾“åˆ°å¦ä¸€ä¸ªECUçš„æƒ…å†µè€ƒè™‘è¿›å»ï¼Œå°±åƒcase2ä¸€æ ·ã€‚æ‰€ä»¥å¯ä»¥è·å¾—åŒæ ·çš„ä¼ è¾“æ—¶é—´tã€‚å¹¶ä¸”åœ¨tæ—¶é—´æ®µç»“æŸåæ•°æ®è¢«å†™å…¥è°ƒåº¦ä»»åŠ¡$\tau_i$çš„è¾“å…¥ç¼“å†²åŒºï¼Œåœ¨$a_i$æ—¶åˆ»æˆ‘ä»¬å¯ä»¥ç±»æ¯”ä¸ºcase1ä¸­å‰ä¸€ä¸ªè°ƒåº¦ä»»åŠ¡çš„ç»“æŸæ—¶åˆ»$f_{i-1}$ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è·å¾—åŒæ ·çš„æ—¶é—´ç»“æœä¸º$\alpha$ã€‚**
In this case, we need to consider the situation where the network transmission needs to be done to another ECU, similar to case 2. So, we can obtain the same transmission time, t. And after the t time period, the data is written into the input buffer of the scheduling taskÂ $\tau_i$. At timeÂ $a_i$, we can analogize it to the end time of the previous scheduling task,Â $f_{i-1}$, in case 1. Therefore, we can obtain the same time result is $\alpha$.

**æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å¾—åˆ°å½“$s(c_i)=\tau, s(c_{i-1})=m$æ—¶ï¼Œ**$D=\alpha + t=\max\{\overline{\beta_i^l}((|B_i| + 1)\cdot E_i), DLY_i(|B_i|)\}+t$
So we can obtain that whenÂ $s(c_i)=\tau, s(c_{i-1})=m$,Â $D=\alpha + t=\max\{\overline{\beta_i^l}((|B_i| + 1)\cdot E_i), DLY_i(|B_i|)\}+t$.

**ç»¼åˆpart 1å’Œpart 2æˆ‘ä»¬å¯ä»¥å¾—åˆ°ä»¥ä¸‹å®šç†ã€‚**
By combining part 1 and part 2, we can derive the following theorem.
å®šç†1ï¼Œä»»åŠ¡é“¾$C = \{z, c_0, c_1, c_2, ... , c_n\}$çš„æœ€å¤§ååº”æ—¶é—´ä¸Šç•Œä¸ºï¼š
å…¶ä¸­ï¼Œ$D$ç”±å¼•ç†2ç»™å‡ºã€‚
Theorem 1, the maximum reaction time upper bound of task chainÂ $C = \{z, c_0, c_1, c_2, ... , c_n\}$Â is:
$$\begin{equation}
\begin{aligned}
RT(C)
& =\max{R(C)}\\
& = f(c_0) - t(z) + \sum_{i=1}^{n}(t(c_i) - t(c_{i-1}))\\
& = T + D
\end{aligned}
\end{equation}$$
WhereÂ $D$Â is given by Lemma 2.

# Evaluation
åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬è¯„ä¼°äº†åŸºäºTSNç½‘ç»œä¼ è¾“çš„ä»»åŠ¡é“¾æ¨¡å‹æœ€å¤§ååº”æ—¶é—´çš„ä¸Šç•Œã€‚
æˆ‘ä»¬è®¾ç½®æ¯æ¡ä»»åŠ¡é“¾é™¤äº†å¤–éƒ¨äº‹ä»¶ï¼Œå…¶ä½™éƒ¨åˆ†ç”±ä¸‰ä¸ªè°ƒåº¦ä»»åŠ¡ä»¥åŠä¸¤ä¸ªç½‘ç»œä»»åŠ¡ç»„æˆï¼Œç±»ä¼¼äºæ–‡çŒ®ã€houtanSupportingEndtoendData2023ã€‘ä¸­çš„è½¦è¾†åº”ç”¨æ¡ˆä¾‹ã€‚è¿™äº›ä»»åŠ¡é“¾è¢«è®¾å®šä¸ºä¸¤ä¸ªECUä¹‹é—´ä¼ è¾“çš„æƒ…å†µï¼Œå‰ä¸¤ä¸ªè°ƒåº¦ä»»åŠ¡æ˜¯ç”±å¤–éƒ¨äº‹ä»¶åœ¨ç¬¬ä¸€ä¸ªECUä¸Šè§¦å‘çš„éƒ¨åˆ†ï¼Œé€šè¿‡ç½‘ç»œä»»åŠ¡çš„ä¼ è¾“ï¼Œæœ€ç»ˆç”±æœ€åä¸€ä¸ªè°ƒåº¦ä»»åŠ¡åœ¨å¦ä¸€ä¸ªECUä¸Šå®Œæˆå¤–éƒ¨äº‹ä»¶çš„å¤„ç†ã€‚å¯¹äºæ‰€æœ‰è°ƒåº¦ä»»åŠ¡ï¼Œåœ¨[1,60]ï¼Œä¹‹é—´é€‰æ‹©å…¶çš„WCETï¼Œå¹¶åœ¨[1,100]ä¸­éšæœºé€‰æ‹©$T$ã€‚æŒ‰ç…§æ—¶åˆ†å¤šå€æ¨¡å‹å¾—åˆ°ï¼š
$\beta (\bigtriangleup ) = (\left \lfloor \bigtriangleup'/x_i  \right \rfloor \cdot s_i+\min (\bigtriangleup'/x_i \mod{ x_i,s_i} ))\cdot b_i$
In this chapter, we evaluated the upper bound of the maximum reaction time for the task chain model based on TSN network transmission. We set up each task chain to consist of three scheduling tasks and two network tasks, except for external events, similar to the vehicle application case in the literature [HOUTAN2023102911]. These task chains were configured for transmission between two ECUs, where the first two scheduling tasks were triggered by external events on the first ECU. Through the transmission of network tasks, the final external event processing was completed by the last scheduling task on the other ECU. For all scheduling tasks, their WCET (worst-case execution time) was selected between [1,60], andÂ $T$Â was randomly chosen between [1,100]. According to the time-division multiple access model, we obtained:
$\beta (\bigtriangleup ) = (\left \lfloor \bigtriangleup'/x_i \right \rfloor \cdot s_i+\min (\bigtriangleup'\mod{ x_i,s_i} ))\cdot b_i$



å…¶ä¸­$\bigtriangleup'=\max (\bigtriangleup-x_i+s_i,0)$ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œ$x_i$æ˜¯åœ¨[50ï¼Œ120]ä¸­éšæœºé€‰æ‹©çš„ï¼Œ$b_i=1$ï¼Œ$\delta =40$ï¼Œ$s_i=x_iâˆ’\delta$ã€‚å¯¹äºç½‘ç»œä»»åŠ¡ï¼Œæ•´ä¸ªç½‘ç»œçš„å¸¦å®½è¢«è®¾å®šä¸º1Gbit/sã€‚å¯¹äºæ¯æ¡ä»»åŠ¡é“¾ä¸Šçš„ç½‘ç»œä»»åŠ¡ï¼Œæ•°æ®å¸§çš„é•¿åº¦åœ¨[84,1542]Byte ä¸­éšæœºåˆ†é…ã€‚
æˆ‘ä»¬åŒæ—¶ç”Ÿæˆäº†$N$ä¸ªå¹²æ‰°ä»»åŠ¡ï¼ˆåŒ…æ‹¬ç½‘ç»œä»»åŠ¡æœ¬èº«ï¼‰ï¼ŒNåœ¨[5,50]ä¸­éšæœºé€‰æ‹©ï¼Œä»–ä»¬æ ¹æ®åˆ†é…çš„é˜Ÿåˆ—è·å¾—äº†ç›¸åº”çš„ä¼˜å…ˆçº§ä»¥åŠå‚æ•°$r$å’Œ$b$ã€‚
æ¯ä¸ªæ³„æ¼ç‡ $r$æ˜¯éšæœºé€‰æ‹©çš„ï¼Œä¸” $0 < r \le 1$ï¼Œ$b$ä¸$l$èŒƒå›´ç›¸åŒã€‚
Among them,Â $\bigtriangleup'=\max (\bigtriangleup-x_i+s_i,0)$. In our experiment,Â $x_i$Â is randomly selected from [50, 120],Â $b_i=1$,Â $\delta =40$, andÂ $s_i=x_i-\delta$. For network tasks, the total network bandwidth is set to 1Gbit/s. For each network task on the task chain, the length of the data frame is randomly allocated from [84, 1542] bytes. We also generateÂ $N$Â interference tasks (including the network task itself), randomly select N from [5, 50], which obtain corresponding priority and parametersÂ $r$Â andÂ $b$Â based on the assigned queue. Each leakage rateÂ $r$Â is randomly selected, andÂ $0 < r \le 1$,Â $b$Â is within the same range asÂ $l$.

> intel(R) Core(TM) i7-10700 CPU @ 2.90GHz 

æˆ‘ä»¬åœ¨å®éªŒå¹³å°è¿›è¡Œäº†è¯„ä¼°ï¼Œwith intel(R) Core(TM) i7-10700 CPU @ 2.90GHz and 32GB DDR4ã€‚
é¦–å…ˆæˆ‘ä»¬è¯„ä¼°äº†æ•°æ®å¸§é•¿åº¦å¯¹äºæœ€å¤§ååº”æ—¶é—´çš„å½±å“ï¼Œå¦‚å›¾1.1æ‰€ç¤ºï¼Œæˆ‘ä»¬é€‰æ‹©ç½‘ç»œä»»åŠ¡ä¸­40%ä¸ºé«˜ä¼˜å…ˆçº§ï¼Œ30ä¸ºåŒç­‰ä¼˜å…ˆçº§ï¼Œå…¶ä½™ä¸ºä½ä¼˜å…ˆçº§çš„ã€‚ä¸ºäº†æ›´å¥½çš„æ˜¾ç¤ºç»“æœçš„å˜åŒ–ï¼Œæˆ‘ä»¬å¯¹è¿‡é•¿çš„æ•°æ®è¿›è¡Œäº†å½’ä¸€åŒ–å¤„ç†ã€‚å½“æ•°æ®å¸§é•¿åº¦å¢åŠ æ—¶ï¼Œæœ€å¤§ååº”æ—¶é—´ä¹Ÿéšä¹‹å¢åŠ ï¼Œç›´åˆ°è¾¾åˆ°committed burst sizeã€‚
We conducted an evaluation on the experimental platform with intel(R) Core(TM) i7-10700 CPU @ 2.90GHz and 32GB DDR4.
First, we evaluated the impact of data frame length on maximum reaction time, as shown in Figure 1.1. We chose a network task with 40% high priority, 30% equal priority, and the remaining as low priority. In order to better visualize the changes in the results, we applied normalization to the overly long data.
As the data frame length increases, the maximum reaction time also increases, until it reaches the committed burst size.

æ¥ç€æˆ‘ä»¬è§‚å¯Ÿäº†é«˜ä¼˜å…ˆçº§ç½‘ç»œä»»åŠ¡å’ŒåŒç­‰ä¼˜å…ˆçº§ä»»åŠ¡å¯¹äºæœ€å¤§ååº”æ—¶é—´çš„å½±å“ã€‚å¦‚å›¾1.2å’Œ1.3æ‰€ç¤ºï¼Œæˆ‘ä»¬é™å®šN=40, T=50, E=0.5ï¼Œå¹¶å°†é«˜ä¼˜å…ˆçº§ä¸åŒç­‰ä¼˜å…ˆçº§ä»»åŠ¡çš„å æ¯”ä»¥10%çš„æ­¥é•¿å†²10%å¢åŠ åˆ°90%ã€‚åœ¨å›¾1.2ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°å½“é«˜ä¼˜å…ˆçº§ä»»åŠ¡å æ¯”å¢åŠ æœ€å¤§ååº”æ—¶é—´ä¹Ÿéšä¹‹å¢åŠ ï¼Œè€Œåœ¨å›¾1.3ä¸­åŒç­‰ä¼˜å…ˆçº§ä»»åŠ¡å æ¯”å¢åŠ åˆ™æœ€å¤§ååº”æ—¶é—´éšä¹‹å‡å°ã€‚è¿™æ˜¯ç”±äºåœ¨å…¬å¼ã€ã€‘ä¸­ï¼Œé«˜ä¼˜å…ˆçº§ä»»åŠ¡ä¸åŒç­‰ä¼˜å…ˆçº§ä»»åŠ¡å¯¹åˆ†å­åˆ†æ¯çš„å½±å“ä¸åŒã€‚
Next, we observed the impact of high-priority network tasks and tasks with equal priority on the maximum reaction time. As shown in Figures 1.2 and 1.3, we set N=40, T=50, E=0.5 and increased the proportion of high-priority and equal-priority tasks in increments of 10% from 10% to 90%. In Figure 1.2, we can see that as the proportion of high-priority tasks increases, the maximum reaction time also increases. On the other hand, in Figure 1.3, as the proportion of equal-priority tasks increases, the maximum reaction time decreases. This is because the influence of high-priority tasks and equal-priority tasks on the numerator and denominator is different in the formula [].


æ ¹æ®Davareåœ¨ã€davare2007periodã€‘ä¸­æå‡ºçš„å…³äºåŸºäºå¼‚æ­¥CANç½‘ç»œçš„ä»»åŠ¡é“¾æ—¶å»¶åˆ†æï¼Œçš„æœ€å¤§ååº”æ—¶é—´æ˜¯ä»»åŠ¡é“¾ä¸­æ‰€æœ‰å¯¹è±¡çš„å‘¨æœŸä¸æœ€åå“åº”æ—¶é—´ä¹‹å’Œã€‚å³$RT'(C')=\sum_{k\in C}{T_k'+R_k'}$ã€‚
According to the maximum reaction time analysis for task chains based on asynchronous CAN networks proposed by Davare in \cite{davare2007period}, the maximum reaction time is the sum of the period and worst-case response time of all objects in the task chain. In other words, $RT'(C')=\sum_{k\in C}{T_k'+R_k'}$.

ä¸ºäº†ä¾¿äºæ¯”è¾ƒæˆ‘ä»¬è®¾å®š$|B|=1$ï¼Œä¸”ä»»åŠ¡é“¾$C$çš„ä»»åŠ¡è¢«è®¤ä¸ºæ˜¯å¶å‘ä»»åŠ¡ï¼Œ
å¯¹äºè°ƒåº¦ä»»åŠ¡ï¼Œ$T'=D'=\alpha '=\bar{\beta^l_i}*(E_i)$
å¯¹äºç½‘ç»œä»»åŠ¡ï¼Œ$l_i=b_i$ï¼Œ$T'=D'=\theta ' +t=(\frac{b_H+b_j+l_L}{r-r_H} + \frac{b_i}{r})+t$

To facilitate comparison, we setÂ $|B|=1$, and the tasks in task chainÂ $C$Â are considered sporadic tasks.
For scheduling tasks,Â $T'=D'=\alpha '=\bar{\beta^l_i}*(E_i)$.
For network tasks, $l_i=b_i$,Â $T'=D'=\theta ' +t=(\frac{b_H+b_j+l_L}{r-r_H} + \frac{b_i}{r})+t$.
So for a task chain $C = \{z, c_0, c_1, c_2, ... , c_n\}$, $RT'(C)=T+D'$ where

$$D'=\begin{array}{l} 
\left\{\begin{matrix} 
\alpha '  & s(c_i)=\tau, s(c_{i-1})=\tau\\
\theta ' +t   & s(c_i)=m\\
\alpha '  +t  & s(c_i)=\tau, s(c_{i-1})=m\\
\end{matrix}\right.    
\end{array}$$
æœ€åæƒ…å†µä¸‹æœ€åå“åº”æ—¶é—´ä¸å‘¨æœŸç›¸ç­‰ï¼Œ$RT'(C')=\sum_{k\in C}2{T_k}'$ã€‚ä½†å¯¹äºç½‘ç»œä»»åŠ¡ï¼Œåªéœ€è€ƒè™‘ä¸€æ¬¡ä¼ è¾“çš„æ—¶é—´æ‰€ä»¥$RT'(C')=\sum_{k\in C}2{T_k}'-t[p]$
In the worst-case scenario, the worst-case response time is equal to the period,Â $RT'(C')=\sum_{k\in C}2{T_k}'$. However, for network tasks, we only need to consider the time of one transmission, soÂ $RT'(C')=\sum_{k\in C}2{T_k}'-t[p]$.
where [p] is an iverson bracket with:
$$[p]=\begin{array}{l} 
\left\{\begin{matrix} 
0  & s(c_i)=\tau, s(c_{i-1})=\tau\\
1  & otherwise\\
\end{matrix}\right.    
\end{array}$$
æˆ‘ä»¬åœ¨å›¾1.4ä¸­å±•ç¤ºäº†ä¸ã€davare2007periodã€‘çš„æ¯”è¾ƒï¼Œç»“æœæ˜¾ç¤ºåœ¨ä¸å›¾1.2ç›¸åŒçš„é…ç½®ä¸‹ï¼Œé€šè¿‡é€æ­¥å¢åŠ é«˜ä¼˜å…ˆçº§çš„å æ¯”ï¼Œæˆ‘ä»¬çš„æœ€å¤§ååº”æ—¶é—´å§‹ç»ˆä½äºdavareçš„æ–¹æ³•ã€‚
In Figure 1.4, we demonstrate a comparison with [davare2007period]. The results show that, under the same configuration as in Figure 1.2, by gradually increasing the proportion of high-priority tasks, our maximum reaction time is consistently lower than that of davare's method.

# Conclusion

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸€ç§åŸºäºTSNç½‘ç»œä¼ è¾“çš„ä»»åŠ¡é“¾æ¨¡å‹ï¼Œå°†IEEE 802.1 Qcræ ‡å‡†ä½œä¸ºè¿æ¥å¤šä¸ªECUçš„ç½‘ç»œä¼ è¾“ä»»åŠ¡çš„æ ‡å‡†ï¼Œå¹¶å°†å•ä¸ªECUä¸Šçš„äº‹ä»¶è§¦å‘ä»»åŠ¡é“¾ä¸ä¹‹ç»“åˆã€‚æˆ‘ä»¬å¯¹æå‡ºçš„ä»»åŠ¡é“¾è¿›è¡Œäº†æœ€å¤§ååº”æ—¶é—´ä¸Šç•Œçš„åˆ†æã€‚é€šè¿‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•æé«˜äº†æ€§èƒ½ã€‚æˆ‘ä»¬è®¡åˆ’è¿›ä¸€æ­¥æ¢ç´¢TSNç½‘ç»œä¸­Qcræ ‡å‡†ä»¥åŠå…¶ä»–ç±»å‹æµé‡å¯¹äºä»»åŠ¡é“¾æœ€å¤§ååº”æ—¶é—´çš„å½±å“ï¼Œå¹¶å°†å…¶æ‰©å±•è‡³æœ€å¤§æ•°æ®å¹´é¾„çš„åˆ†æã€‚
In this paper, we investigate a task chain model based on TSN network transmission, using the IEEE 802.1 Qcr standard as the standard for connecting multiple ECUs for network transmission tasks, and combining event-triggered task chains on individual ECUs. We analyze the maximum reaction time upper bound of the proposed task chains. Experimental results show that our method improves performance. We plan to further explore the impact of the Qcr standard in TSN networks and other types of traffic on the maximum reaction time of task chains, and extend it to the analysis of maximum data age.

# APPENDIX



----


å‡è®¾
ç ”ç©¶çš„é—®é¢˜

ATSè°ƒåº¦

åœ¨ä»€ä¹ˆæ¡ä»¶ä¸‹ç ”ç©¶ä»€ä¹ˆ