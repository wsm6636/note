---
created: 2023-09-26T13:10
updated: 2024-02-13T22:40
tags:
  - 笔记
  - 笔记/文献笔记
---

# Reaction Time Analysis of Event-Triggered Processing Chains with Data Refreshing

| Title                 | Reaction Time Analysis of Event-Triggered Processing Chains with Data Refreshing |
| --------------------- | -------------------------------------------------------------------------------- |
| Journal or Conference | 2023 60th ACM/IEEE Design Automation Conference (DAC)                            |
| Authors               | Yue Tang; Nan Guan; Xu Jiang; Zheng Dong; Wang Yi                                |
| Pub. date             | 2023-7-9                                                                         |
| DOI                   | [10.1109/DAC56929.2023.10248012](https://doi.org/10.1109/DAC56929.2023.10248012) |
| Level                 | CCFA                                                                               |


# Reaction Time Analysis of Event-Triggered Processing Chains with Data Refreshing——具有数据刷新的事件触发处理链的反应时间分析

## 摘要
许多实时系统通过一系列任务来处理和响应外部事件，并且对最大反应时间有限制，最大反应时间描述了响应外部事件所需的时间。虽然处理链通常从定期触发的采样任务开始，以采样传感器数据，但链中的其他任务可以通过两种不同的方式触发：事件触发或时间触发，这两种方式各有优缺点。<span style="color:black;background:#ff4d4f !important;">在本文中，我们提出了第三种方法来触发链中的处理任务，即事件触发和数据刷新方法，</span>它结合了事件触发和时间触发的方法的优点。作为主要的技术贡献，我们开发了形式上界其最大反应时间的技术，并将其与现有方法进行了分析比较。使用合成工作负载进行的实验表明，我们提出的技术提高了性能。

## 1 引言

实时系统通常处理外部事件并对其做出反应。在许多复杂的实时系统中，外部事件的处理由由多个任务组成的处理链来执行，所述多个任务可以在同一处理器上同时执行或者分布到多个处理单元。这类系统的关键实时性能指标是最大反应时间，它描述了从事件发生到产生与该外部事件对应的最终输出所需的时间。具有最大反应时间约束的加工链在汽车电子、工业控制和机器人等领域有着广泛的应用。

<span style="color:black;background:#40a9ff !important;">处理链的第一个任务(称为采样任务)</span>是对传感器数据进行采样，这通常会<span style="color:black;background:#40a9ff !important;">以一定的频率定期触发</span>。然而，在现有的研究中，有不同的方式来触发其他任务(称为处理任务)，要么是时间触发(TT)，要么是事件触发(ET)。在TT方式下，每个处理任务按照自己的周期周期性地触发执行，链中两个连续的任务以非阻塞的方式通信，即一个任务简单地将其输出数据写入缓冲区，其后续任务从该缓冲区读取数据，当新的数据帧到达时，缓冲区中的旧数据帧被覆盖，而不管旧的数据帧是否已被使用。<span style="color:black;background:#40a9ff !important;">通过ET方法，任务以阻塞的方式相互通信，处理任务被触发，因此当其前一任务完成并为其生成数据帧时，该任务就有资格执行。一个无限(足够大)的缓冲器被用来以FIFO顺序存储未处理的数据帧，并且每个数据帧迟早都会被处理。</span>

对上述两种触发方式的反应时间分析问题进行了研究。<span style="color:black;background:#40a9ff !important;">对于ET处理链，分析反应时间本质上等同于分析链中每个任务执行一次、相继触发的端到端延迟，对此已有成熟的技术[1]、[2]</span>。对于TT处理链，反应时间不同于端到端延迟，因为一些数据帧可能在没有处理的情况下被重写，因此反应时间可能涉及任务的多次执行，如图1-(B)所示。最近的工作已经开发出了时间触发处理链的最大反应时间上限的技术[3]-[5]。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310122151791.png)


然而，在给定处理链的情况下，如果系统设计人员可以选择通过ET方法或TT方法来实现，那么在优化最大反应时间方面，哪一种方法更好？此外，还有比现有的ET和TT方法更好的方法吗？据我们所知，这些问题仍未解决。注意，尽管在现实的系统设计中，当在ET和TT方法之间进行选择时，通常在其他方面存在限制或考虑因素，例如，在ET方法中同步任务的可行性和开销，但从最大反应时间的角度回答上述问题仍然很重要，这可以为更好地指导系统设计提供有用的见解。这篇论文在回答这些重要但尚待解决的问题方面取得了一些进展。

更具体地说，本文提出<span style="color:black;background:#d3f8b6 !important;">使用标准ET方法的变体</span>，称为<span style="color:black;background:#d3f8b6 !important;">带有数据刷新的事件触发(ETDR)</span>，来触发链中的处理任务。ETDR和标准ET方法之间的唯一区别是，虽然在标准ET方法中，连接两个连续任务的缓冲区被假设为足够大，从而永远不会发生溢出，但<span style="color:black;background:#d3f8b6 !important;">在ETDR方法中，我们让每个缓冲区具有有限的大小，并且当缓冲区溢出发生时，旧数据帧被新到达的数据帧覆盖，就像在TT方法中一样。</span> 事实证明，这种微小的差异使得ETDR方法的反应时间分析不同于标准ET方法，并且比标准ET方法更困难，因为<span style="color:black;background:#fff88f !important;">ETDR的分析需要限制由被重写的数据帧引起的额外延迟</span>。本文的主要技术贡献包括开发了使用ETDR方法来确定加工链最大反应时间上限的技术，并与标准的ET和TT方法进行了分析比较。使用合成工作负载进行的实验表明，使用我们提出的技术可以获得性能提升。

> ET事件触发机制  +  TT时间触发缓冲机制（固定大小缓冲区，新数据覆盖旧数据）

## 2 模型

### 2.1 处理链

我们考虑由一系列任务C={τ0，τ1，τ2，...，τn}组成的处理链C。每个任务τi的特征是最坏情况执行时间(WCET) e(τi)。任务τ0是采样任务，它以周期T0定期调用，以定期采样传感器数据。其他任务τ1、...、τn都是处理任务。每个处理任务$\tau$i读取由其前驱τi-1产生的数据帧，并产生用于其后继τi+1的数据帧(如果有的话)。每个任务τi都有一个<span style="color:black;background:#d3f8b6 !important;">输入缓冲器Bi</span>，它以先进先出(FIFO)的顺序存储由其前驱产生的输出数据帧。我们用|Bi|来表示bi的大小。对于采样任务τ0，其输入缓冲器B0存储定期采样的传感器数据。

任务τi释放(无限多个)作业，每个作业处理其输入数据缓冲区BI中的一个数据帧，并产生输出数据帧并将其放入其后续的输入缓冲区中。<span style="color:black;background:#d3f8b6 !important;">采样任务τ0根据其周期T0周期性地释放作业。</span><span style="color:black;background:#d3f8b6 !important;">当其前身τi−1产生数据帧并将其放入τi的输入缓冲器Bi时，处理任务τi释放作业。</span>我们用$J_i^k$来表示τi发布的第k个作业。为了简单起见，有时我们也用Ji来表示τi发布的作业，而不需要准确地区分它是哪个作业。我们用r(集)、S(集)和f(集)分别表示集的释放时间(集成为可执行的时间)、开始时间(集开始执行时)和结束时间(集完成执行时)。<span style="color:black;background:#d3f8b6 !important;">在时间S(Ji)，Ji读取输入数据帧(并将其从Bi中移除)，并且在时间f(Ji)，产生数据帧并将其放入其后续τi+1的输入缓冲器Bi+1中。</span>

<span style="color:black;background:#fff88f !important;">当某个输入缓冲器Bi溢出时，即τi-1产生新的数据帧但τi的输入缓冲器Bi已满时，该新数据帧将重写该新数据帧中最旧的数据帧</span>。<span style="color:black;background:#d3f8b6 !important;">当BI中的一个数据帧被覆盖时，将跳过该数据帧对应的τi发布的作业(即不执行)，我们称该作业为跳过的作业。不是跳过作业的作业称为非跳过作业。</span>
> 跳过作业
> 被覆盖的作业（缓冲区中最旧的数据最先被覆盖）

### 2.2 资源可用性

我们假设系统由多个处理器组成，并且每个任务被<span style="color:black;background:#d3f8b6 !important;">静态地分配</span>给某个处理器。此外，根据我们的分析，在每个处理器上，可能会有其他工作负载与处理链C的任务竞争计算资源。我们使用通用==资源可用性模型==<span style="color:black;background:#d3f8b6 !important;">服务曲线</span>$⟨β^l_i(∆), β^u_i(∆)⟩$[6]来描述所考虑的处理链中每个任务可用的资源，其中$β^l_i(∆), β^u_i(∆)$是在长度为$∆$的任意时间段内对τi可用的最小和最大处理时间量。使用服务曲线对资源可用性进行建模允许包含与底层平台和资源分配相关的各种不同设置，这已被许多现有的实时系统研究[7]-[9]所采用。

> "service curves" 是指在网络服务质量管理中使用的一种性能度量。它通过描述服务提供商在不同的负载条件下提供服务的能力来衡量网络服务的性能。一般来说，"service curves" 描述了服务质量随着网络负载的变化而变化的关系。
>
> 具体来说，"service curves" 包括两个重要参数："延迟曲线（delay curve）" 和 "带宽曲线（bandwidth curve）"。延迟曲线描述了在不同的网络负载条件下，服务的延迟表现；带宽曲线描述了服务在不同负载条件下可提供的带宽。
> 
> 系统性能随负载变化
 <span style="color:#00b050 !important;">> $β^l_i(∆)$ 在时间间隔内，最大处理时间</span>



### 2.3 最大反应时间

处理链的目标是处理携带外部事件信息的数据帧并对其做出反应。当在时间t发生外部事件时，在时间t或之后释放的采样任务τ0的作业将产生携带该外部事件的信息的输出数据帧。该数据帧将由其后续任务τ1的某个作业读取和处理，其产生也携带该外部事件的信息的其输出数据帧，并且这在整个处理链中重复，直到最后一个处理任务τn的某个作业在某个时间点t‘产生关于该外部事件的最终输出数据帧，则t’-t是关于该外部事件的处理链的反应时间。接下来，我们形式化地定义了加工链的最大反应时间。

在运行时，处理链生成(无限多个)传播链，每个传播链由外部事件和处理携带该事件信息的数据的作业组成。

**定义1(传播链)**：传播链c={z，c0，c1，...，cn}满足：

- Z是任意外部事件，发生在t(Z)处。
- c0是采样任务τ0释放的第一个**非跳过作业**，释放时间不早于t(Z)。
- 对于每个i∈[1，n]，ci是释放时间不早于f(ci−1)的对应任务τi释放的第一个未跳过的作业。

**定义2(反应时间)**：由L(C)表示的传播链c的反应时间为

![image-20230927163716863](https://gcore.jsdelivr.net/gh/wsm6636/pic/202309271637987.png)

**定义3(最大反应时间)**：加工链C的最大反应时间RT(C)是由C产生的任何可能的传播链c的最大L(C)，即，

![image-20230927163815252](https://gcore.jsdelivr.net/gh/wsm6636/pic/202309271638322.png)

### 2.4 说明性的例子

![image.png|762](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310101703940.png)

在图2中，处理链C由三个任务组成C={τ0，τ1，τ2}。其中e(τ0)=2，e(τ1)=2，e(τ2)=3，|B0|=1，|B1|=1，|B2|=2.
τ0是在周期T0=5时调用的采样任务。我们假设这三个任务在三个不同的处理器上执行，并且在灰色块所覆盖的时间间隔内，处理器对相应的任务不可用。在t(z)=3处发生外部事件z，对应的传播链为c={z，$j^3_0$，$j^2_1$，$j^2_2$}，反应时间为21−3=18。对z的反应过程详细如下：$j^2_0$是t(Z)之后释放的第一个作业，当下一个作业$j^3_0$被释放时，它被跳过，因为其对应的输入数据帧在时间10被重写。$j^3_0$是携带外部事件信息的第一个非跳过作业，其在有可用资源的时间10开始执行，并在12结束。在其执行结束时，$j^3_0$产生输出帧并将其放入B1，即τ1的输入缓冲器。然后，$j^2_1$在12被释放，并在15结束，其输出数据帧被存储在B2中。在21，$j^2_2$结束，并且产生关于z的最终输出数据。
> 事件触发ET，任务完成输出时触发下一个任务
> 任务0的输入区B0，大小为1，只能同时存在一个数据帧
> 任务0是采样任务，周期性释放
> 其他任务，当前一个任务完成，写入缓冲区，触发后一个

> 3时刻，外部事件z，
> 5时刻，任务0采样，j02释放，外部事件z的数据写入B0
> 5-10时刻，CPU0上的任务不可用，直到j03释放都不可用。所以数据没有被下一个任务读取移除
> 10时刻，任务0采样，j03释放，B0被重写<span style="color:#ffff00 !important;">（新数据吗，和j02不一样吗）</span>
## 3 最大反应时间分析

在这一部分中，我们介绍了处理链C的最大反应时间的上界的技术。回想一下，对于标准的ET方法，其中每个任务的输入缓冲区足够大，因此没有溢出发生，最大反应时间分析问题被归结为传统的最大端到端延迟分析问题，该问题可以通过现有技术很好地解决[1]，[2]。然而，在我们的ETDR方法中，可能会发生缓冲区溢出，因此可能会跳过一些已释放的作业，反应时间还需要包括由跳过的作业造成的额外时间延迟。因此，现有的标准ET加工链的分析技术不适用于ETDR加工链，我们需要开发新的技术来分析它们的最大反应时间。

### 3.1 最大反应时间分析

我们的分析集中在任意传播链c={z，c0，c1，…，cn}上。
**定义4(合格时间)：** 作业ci在c={z，c0，c1，...，cn}中的合格时间由t(ci)表示，定义为：

![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310101736952.png)

==其中$j^*_0$是z出现后发布的τ0的第一个作业。==
我们的目标是达到L(c)的上限，可以改写为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310111021052.png)

> t(c0)=rj0，在图2中是j02的释放时间5
> t(c1)=f(c0)，j03的完成时间12
> t(c2)=f(c1)，j12的完成时间15
> f(c2)，j22的完成时间21

首先，我们可以用下面的引理来确定t(C0)−t(Z)的上界。
**引理1**：给定一个传播链c={z，c0，c1，…，Cn}，t(C0)−t(Z)上界：

![image.png|252](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310111023276.png)
证明：由于τ0是使用周期T0定期调用的，因此从t(Z)到τ0的第一个作业发布之间的时间以T0为界。
>任务0定期采样，所以一个周期一定会有一个作业被释放（可以是跳过的作业），z时刻后第一个释放作业的时间为t(c0)

接下来，我们对每个i−[0，n]给出f(Ci)∈t(Ci)的上界。为此，我们首先给出了文献[10](Reaction%20Time%20Analysis%20of%20Event-Triggered%20Processing%20Chains%20with%20Data%20Refreshing.md#^7d4976)的一个已知结果。
> Reference
[10] L. Phan, R. Schneider, S. Chakraborty, and I. Lee, “Modeling buffers with data refresh semantics in automotive architectures,” in EMSOFT , 2010.

**引理2([10])**：给定一个传播链c={z，c0，c1，…，cn}，对每个i∈[0，n]，f(Ci)−r(Ci)是上界
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310121705554.png)
其中DLYi(|Bi|)是关于|Bi|的非递减函数，详见附录2
> 2注意，在[10]中开发的界限DLYi(|Bi|)不同于传统事件触发处理链/网络中的延迟界限，在传统的事件触发处理链/网络中，所有缓冲区足够大，因此不会发生缓冲区溢出[1]，因为执行ci−1的延迟可能受其他跳过的作业的影响，尽管ci−1本身是非跳过的作业。

> DLY是什么
 <span style="color:#00B0F0 !important;">> 非跳过作业Ji的最大延迟</span>

基于这一结果，我们可以利用下面的引理来确定f(Ci)−t(Ci)的上界。
**引理3：** 给定一个传播链c={z，c0，c1，…，Cn}，对每个Ci，i∈[0，n]，f(Ci)−t(Ci)上界是
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310122042535.png)
其中 $\bar{\beta^l_i}$ 是$\beta^l_i$的伪逆函数(定义3.1.7，[11])。
> 定义3.1.7(伪逆)。令f是F的一个函数或一个序列。f的伪逆是函数
> ![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310122050213.png)
> ![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310150945560.png)

证明：我们==首先考虑在t(Ci)处放入缓冲器Bi中的数据帧不被重写的简单情况==，即在t(Ci)处释放的作业不被跳过。在这种情况下，t(Ci)=f(ci−1)=r(Ci)。然后通过引理2，我们得到了
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310122058417.png)
接下来，我们考虑更复杂的情况，其中==在t(Ci)处放入缓冲器Bi中的数据帧被重写==，即，在t(Ci)处释放的作业被跳过。根据定义1和定义4，Ci是释放时间不早于t(Ci)的第一个未跳过的作业。我们主张以下命题。

> 注意前提条件，t(Ci)处释放的作业被跳过

**P1。 在$[t(c_i)，r(c_i))$期间不存在有未使用的可用资源但没有任务τi的未完成作业的时刻。**

我们用矛盾的方法证明了P1。假设存在某个t'∈$[t(Ci)，r(Ci))$，在t'处有未使用的可用资源，但没有未完成的τ (ci)作业。则在t'处，缓冲区必须为空。我们用Ji表示τi在t'之前发布的最后一个作业。则对应于Ji的输入数据帧在时间t'之前一定没有被其他数据帧重写，因为在t'之前没有较新的数据帧到达Bi，并且由于在t'处没有τi的未完成作业，所以我们可以断定Ji在时间t'已经被执行和完成，这意味着Ji是未跳过的作业。另一方面，由于在t(Ci)处释放的作业是跳过的，而ci是在t(Ci)之后释放的τi的第一个非跳过作业，因此我们知道Ji一定是跳过的作业，这导致了一个矛盾，于是证明了P1。

**P2。在$[t(Ci)，f(Ci))$期间执行的τi的最大工作量是(|Bi|+1)·e(τi)的上界。**

> 工作量 = 处理数据帧的时间
3

<span style="color:black;background:#d3f8b6 !important;">工作负载包括三个部分</span>：
(1)在t(Ci)处执行的作业所产生的工作负载。
(2)在$[t(Ci)，f(Ci))$期间要执行的、由其对应的数据帧在t(Ci)+ε处的缓冲区Bi中的作业产生的最大工作量，其中t(Ci)+ε是紧接在t(Ci)之后的时刻，当由ci−1产生的数据被写入Bi时。
(3)在(t(Ci)，r(Ci)]期间释放的工作产生的工作量。
> t(Ci)+ε，是ci-1完成将输出写入Bi的时刻

部分(1)的上界是e(τi)。
下一步，我们求部分(2)上界。在t(Ci)+ε处，缓冲器中最多有Bi数据帧，并且最多释放与这些数据帧相对应的Bi任务。由于在t(Ci)处写入Bi的数据帧必须在这些Bi数据帧中，并且在t(Ci)处发布的作业被跳过并且不执行，因此必须排除由在t(Ci)处发布的作业产生的工作量，因此部分(Ii)的上界为(Bi−1)·e(τi)。
下一步，我们求部分(三)上界。由于ci是一个不可跳过的作业，因此ci生成的工作量为e(τi)。
根据定义1，在(t(Ci)，r(Ci))期间释放的所有作业都被跳过，因此不会产生工作负载。因此，在(t(Ci)，r(Ci)]之间释放的作业所产生的工作量的上界是e(τi)。

> e(τi)，任务τi的最差执行时间
> t(Ci)+ε时刻，最多有Bi个任务（数据帧），工作量Bi·e(τi)
> t(Ci)时刻，跳过作业，-1

然后，通过将第(I)、(Ii)和(Iii)部分的工作量相加，得出在$[t(Ci)，f(Ci))$期间要处理的**工作量**的上界为
**(|Bi|+1)·e(τi)** ，即P2。
> e(τi)+[(Bi−1)·e(τi)]+e(τi)

通过P1，将在$[t(Ci)，f(Ci))$期间提供的所有资源用于处理τi产生的工作量，从而所提供的资源量等于在$[t(Ci)，f(Ci))$期间要执行的工作量，以P2为上界。资源等于在$[t(Ci)，f(Ci))$期间要执行的工作量，其上限为P2。

由于$\bar{\beta^l_i}(|Bi|+1)·e(τi))$ 是处理器提供(|Bi|+1)·e(τi)个资源单位的最大时间间隔，因此$f(c_i)−t(c_i)≤\bar{\beta^l_i}(|Bi|+1)·e(τ_i))$ 。然后结合(5)证明了这一引理。
> 为什么⭐️⭐️⭐️⭐️⭐️
>$[t(Ci)，f(Ci))$期间内，系统能提供的最大处理时间（资源），就是$\beta^l_i([t(Ci)，f(Ci)))=(|Bi|+1)·e(τi)$
>通过P1可以知道，期间内所有的资源都被用于处理任务产生的工作量（工作负载）
>所以处理这么多工作负载用的时间就是$\bar{\beta^l_i}(|Bi|+1)·e(τi))$

**定理1：** 加工链C={τ0，τ1，τ2，...，τn}的最大反应时间上界为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310132250813.png)
其中 $\bar{\beta^l_i}$ 是$\beta^l_i$的伪逆函数
证明：结合定义3，(3)和引理1和3，
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310132252726.png)

### 3.2 缓冲区大小的影响
<span style="color:black;background:#ff4d4f !important;">现在我们讨论无限缓冲区的标准ET方法和我们的有限缓冲区的ETDR方法的比较，以及不同缓冲区大小的总体影响。</span>
当缓冲器大小被设置得足够大以便不发生数据帧重写时，到达处理链中的每个任务的输入数据帧的长期比率与采样任务τ0相同，并且每个任务的所有释放的任务最终将不得不完成。在这种情况下，<span style="color:black;background:#fff88f !important;">如果处理链中的某个任务资源利用率较低，则会成为整个处理链的瓶颈。</span>特别地，如果某个任务τi∈C的长期资源可用性小于其长期工作量，即$\lim_{0 \to \infty} (\beta^l_i(x*T_0)-x*e(\tau_i)) < 0$，==则Bi中的积压数据帧的数量随着时间的推移而增加到无穷大，因此最大反应时间是无界的。==
> long-term ratio，长期比率
> 通常用于指代在长时间跨度内的比较或关系。

虽然只要每个任务的输入缓冲区具有有限的大小，就可以解决上述无限反应时间问题，但一般来说，<span style="color:black;background:#fff88f !important;">使用较小的缓冲区有利于反应时间，因为较小的缓冲区减少了积压的工作量，</span>从而使较少的工作量突发从上游任务传播到处理链中的下游任务。使用较小缓冲区的好处也反映在定理1中的反应时间界限RT(C)中，如下面的推论所述。

**推论1：** 当为每个任务τi设置|Bi|=1时，链C的最大反应时间RT(C)最小化。
证明：根据定理1，最大反应时间界RT(C)依赖于C中每个τi的输入缓冲区大小|Bi|。由于$\beta^l_i$是非减函数，即 $\bar{\beta^l_i}$是非减函数，DLYi(|Bi|)也是非减函数，因此我们可以得出<span style="color:black;background:#d3f8b6 !important;">RT(C)关于每个|Bi|是非减的</span>，即当对每个任务τi设置|Bi|=1时，RT(C)是最小化的。
> β和DLY是非减的，Bi是个常数，所以RTC对于Bi来说也是非减的
> 所以当Bi=1的时候，Bi是最小的，RTC也是最小的

## 4 与时间触发链的比较
在上一节中，我们展示了在ETDR中使用有限缓冲区比使用标准ET方法的好处。在本节中，我们将比较ETDR和TT方法。
设C={τ0，τ1，τ2，...，τn}是使用第二节中定义的ETDR的处理链，即，周期性地触发τ0，每个任务τi当输出数据帧到达其输入缓冲器Bi时被触发。我们还考虑了相应的TT处理链$C_t=\{τ^t_0，τ^t_1，τ^t_2，...，τ^t_n\}$，其中每个任务τi(0≤i≤n)具有与其C中的对应任务相同的WCET (由e(τi)表示)，并且以其自己的周期Ti周期性地触发。τi和$τ^t_i$的资源可用性是相同的，都由$β^u_i$和$β^l_i$的服务曲线表征。为了进行公平的比较，我们还假设τ0和$τ^t_0$的释放具有相同的周期T0。
> ETDR任务链，C，周期T0触发τ0，事件触发机制（写入B）
> TT任务链，Ct，采样任务0同上，周期Ti触发其他任务
> 两者最差执行时间一样，资源可用性相同
> 
> 资源可用性是指计算机系统、网络或其他信息技术基础设施的资源在需要时可供使用的状态和程度。这包括硬件资源（如服务器、存储设备、网络设备）和软件资源（如操作系统、应用程序、数据库）。

在具有较小周期的TT处理链中执行任务会导致较小的最大反应时间。然而，<span style="color:black;background:#fff88f !important;">不能为TT处理链中的任务设置任意小的周期，因为现有的时间触发链的反应时间分析是基于这样的假设，即对于每个任务，每个作业必须在下一个作业发布之前完成[3]。</span>因此，为了使用具有最大反应时间的解析保证的TT方法，它要求TT处理链$C^t$中的每个任务$τ^t_i$的周期必须以<span style="color:black;background:#40a9ff !important;">每个作业在下一个作业释放之前能够完成</span>的方式来选择。使用下面的引理可以计算出满足上述约束的D最小周期Ti。

**引理4：** 对于<span style="color:black;background:#d3f8b6 !important;">服务曲线较低</span>的任务$τ^t_i$∈$C^t$，保证每个任务在下一次任务释放前完成的最小周期$T^{min}_i= \bar{\beta^l_i}*(e(τi))$。
证明：提供足够的资源来完成任务$τ^t_i$的一项工作的时间间隔长度的上限为 $\bar{\beta^l_i}*(e(τi))$。为了保证每个作业在下一个作业释放之前完成，周期Ti不能小于$\bar{\beta^l_i}*(e(τi))$。
> 每个任务在下一次任务释放前完成，任务完成需要的最差执行时间e(τi)，并保证资源足够

在下面的比较中，我们将使用引理 4 中所述的 $T^{min}_i$每个任务 $\tau^t_i$ ∈ $C^t$，定理 1 中的反应时间限制 RT (C) 被最小化，如上一节所述。
> |Bi| = 1

根据引理 4，TT 处理链必须满足 $T0  ≥  T^{min}_0= \bar{\beta^l_0}*(e(τ0))$。<span style="color:black;background:#d3f8b6 !important;">我们还应该将此条件应用于 ETDR 处理链的分析，以进行公平的比较，通过该比较，可以将反应时间界限细化如下。</span>

> 注意，以下响应时间分析，是为了和TT比较，所以设置缓冲区大小为1

**引理 5：** 处理链的反应时间 C = {τ0, τ1, τ2, ..., τn}，其中  $T0  ≥ \bar{\beta^l_0}*(e(τ0))$，上限为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310141722631.png)
证明：由(3)，我们有
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142011500.png)
其中 J′ 表示 t(z) 之后释放的 τ0 的第一个作业。
由于$T0  ≥ \bar{\beta^l_0}*(e(τ0))$，τ0 释放的每个作业在下一个作业释放之前完成，因此 J′ 必须是不可跳过的，并且 J′ 恰好是 c0。同时，<span style="color:black;background:#d3f8b6 !important;">在某一时刻，至多有一项未完成的工作</span>，所以
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142015699.png)
因此处理链 C 的反应时间的上限为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142030152.png)
上述推导的最后一步成立，因为 $DLY_i(|B_i|) ≤  \bar{\beta^l_i}*(2e(τ_i))$，==详见附录==。
> 与TT比较，所以τ0的每个作业都在下一个作业释放之前完成
> 那么J'不可跳过，是z之后的第一个作业，也就是C0
> 而且由于每个任务释放时，它之前的任务都已经完成，所以在同一时刻不会有多个未完成的任务

我们将把在上述引理中得到的界限RT'(C)与TT处理链在与我们的论文相同的设置下的反应时间界限进行比较：
**引理6([12])：** 时间触发链Ct的最大反应时上界为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142139217.png)
其中Ri是任务τi的局部最坏情况响应时间界限。
> Period Optimization for Hard Real-time Distributed Automotive Systems
> Davare
> 最老的分析，有关最大反应时间
> 最差响应时间+时间间隔

根据引理4，<span style="color:black;background:#d3f8b6 !important;">在最坏的情况下，每个Ti以任务在下一个作业发布时间之前完成的方式设置</span>，==即Ri=Ti==，因此我们有$RT^t(C^t)$可以被重写为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142144150.png)
**定理2**：对于满足∀i∈[0，n]，$Ti  ≥  \bar{\beta^l_i}*(e(τi))$的ETDR处理链C= {τ0, τ1, τ2, ..., τn}和TT处理链$C_t=\{τ^t_0，τ^t_1，τ^t_2，...，τ^t_n\}$，有RT'(C)≤$RT^t(C^t)$。
证明：$β^l_i$是超加性的，即$\bar{\beta^l_i}$是次加性的，所以我们知道
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142152317.png)

> 超加性：将函数应用于两个变量的和时，函数的值至少等于将函数分别应用于这两个变量后的值的总和。这是一种强于线性性质的性质，因为它要求对于任意 a 和 b，不仅是 f(a + b) ≥ f(a) + f(b)，而且要求对于所有的 a 和 b。
> 次加性：将函数应用于两个变量的和时，函数的值不会超过将函数分别应用于这两个变量后的值的总和。这是一种弱于线性性质的性质，因为它要求对于任意 a 和 b，不仅是 f(a + b) ≤ f(a) + f(b)，而且要求对于所有的 a 和 b。

结合(6)、(9)和(10)证明了这个定理。

> 与ET比较的最大响应时间是RTC
> 与TT比较的是RT‘C

## 5 实验

在这一部分中，我们使用合成工作负载经验地评估了本文开发的ETDR处理链的最大反应时间界限。我们首先介绍了参数设置。每条链由N个任务组成。在[1，60]中随机选择每个任务τi的WCET。<span style="color:black;background:#FFDBBB !important;">按照时分多址模型[13]生成每个任务τi的服务曲线：</span>
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142157379.png)
其中∆‘=max(∆−xi+si，0)。在我们的实验中，xi是在[50，X]中随机选择的，bi=1，si=xi−δ。我们在不同的实验中改变了δ、N和X。
> 
> RTC 是一种数学框架，用于建模和分析实时系统中的任务和资源分配。RTC 工具包提供了一组计算工具，用于分析实时系统的性能、延迟和可靠性。

我们首先评估了<span style="color:black;background:#FFDBBB !important;">不同缓冲区大小的ETDR的反应时间界限</span>。对于每个生成的链，我们将每个任务的缓冲区大小设置为|B|，并设置N=5，X=120，并在[1,100]中随机选择T0。如图3-(A)所示<span style="color:black;background:#FFDBBB !important;">，随着缓冲器大小的增加，反应时间界限显著增加。</span>

接下来，我们比较<span style="color:black;background:#FFDBBB !important;">每个任务缓冲大小为1的ETDR处理链的反应时间界限(即引理6中的RT‘(C))和每个任务的T T链的反应时间界限(即引理6中的RT t(C))</span>，其中$Ti  =  \bar{\beta^l_i}*(e(τi))$。图3-(B)至图3-(C)分别显示了不同δ、X和N的比较结果。在图3-(B)中，X=120，N=5。在图3-(C)中，δ=40，N=5。在图3-(D)中，X=120，δ=40。实验结果表明，<span style="color:black;background:#FFDBBB !important;">在不同的参数设置下，缓冲大小为1的ETDR处理链的反应时间界与TT处理链的反应时间界一致。</span>
> 一样的趋势，但是ERDR比TT小
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142205349.png)

## 6. 相关工作
**TT加工链**。TT处理链的端到端延迟分析考虑了两个语义：反应时间和数据年龄，这是在[14]中首次提出的。[12]计算了周期任务集最大反应时间的上界，提出了通过调整任务周期来优化反应时间的几何规划方法。[3]利用即时前向和后向作业链，计算了由零星任务组成的TT加工链的反应时间和数据年龄的上界。[4]推导了全局同步系统上周期性任务集的最大反应时间。[5]导出了异步化系统因果链的反应时间和数据年龄的上界。[16]开发了将任务集高效地映射到多核实时系统的技术，通过自动系统转换和分析解决了数据年龄界限、同步开销和总体可调度性的挑战。[17]计算了DBP下同步周期任务的反应时间。
> 之前看的论文，端到端延迟的，都是TT


**ET加工链**。对于具有无限缓冲区的ET处理链，反应时间分析问题退化为端到端延迟分析问题，已有成熟的分析技术，包括组成性能分析框架[2]和实时演算框架[1]。[18]计算了具有同步和异步通信的线程序列的响应时间，[19]使用只支付突发一次分析技术优化了穿越多个处理器的触发链的端到端延迟。对于具有有限大小缓冲区的ET处理链，[10]在RTC框架下发展了非跳过的延迟分析，该延迟分析可用于分析处理链的另一重要实时性能度量数据AGE[14]，但不能用于分析本文所研究的反应时间。<span style="color:black;background:#ff4d4f !important;">此外，我们不仅研究了如何分析具有有限大小缓冲区的ET加工链的反应时间，而且还与TT加工链进行了分析比较。</span>


## 7.结论
在本文中，我们研究了一种标准的偶触发方法的变体，通过限制缓冲区大小和允许数据刷新来触发链中的处理任务。作为主要的技术贡献，我们开发了形式上界其最大反应时间的技术，并将其与现有方法进行了分析比较。使用合成工作负载进行的实验表明，我们提出的技术提高了性能。下一步，我们计划通过联合分析多个任务造成的延迟来制定更精确的反应时间界限。

## 附录
我们在文[10]中简要介绍了DLYi(|Bi|)的计算。在[10]中的系统模型和本文中的系统模型之间有一些细微的差别。[10]使用基于事件的系统模型，而本文使用基于工作负载的系统模型(因为我们想与其他有关反应时间分析的工作进行比较，特别是使用TT方法的工作，它们使用基于工作负载的系统模型)。更具体地说，Bi 上数据帧的到达模式由一对到达曲线 $\left \langle \alpha^l_i ,  \alpha^u_i  \right \rangle$ 来表征，它们描述了在长度为 Δ 的任何时间间隔内到达的数据帧的最大/最小数量。资源供应由一对基于事件的服务曲线 $\left \langle \beta ^{*l}_i(\triangle ) ,  \beta ^{*u}_i(\triangle )  \right \rangle$来表征，它描述了在长度为 Δ 的任意时间间隔内可以处理的最大/最小作业数量。本文使用的服务曲线和[10]中基于事件的服务曲线可以通过以下方式相互转换：
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142313957.png)
> 到达曲线，时间间隔内，到达数据帧的数量
> 资源供应，服务曲线，时间间隔内，可以处理的作业数量

此外，在基于事件的系统模型中，一旦有足够的资源，输入数据帧的处理就被认为立即完成，而在我们基于工作负载的系统模型中，任务 τi 需要执行 e(τi)处理输入数据帧，在此期间可能有新的输入数据帧到达。因此，在我们的模型中，当任务 τi 的输入缓冲区已满时，τi 要执行的最大工作负载总量应以 (|Bi| + 1) · e(τi) 为界，而不是 |Bi| · e(τi)，<span style="color:black;background:#d3f8b6 !important;">因为我们还需要包括当前正在处理的数据帧的工作负载，该工作负载可能恰好在所考虑的时刻之前开始。</span>因此，我们需要使用 |Bi| + 1 替换 |Bi|计算 DLYi 以适应我们基于工作负载的系统模型。
因此，[10]中DLYi(|Bi|)的计算可以在本文问题模型的背景下表述如下：
**引理 7**：在 ETDR 处理链 C 中，==非跳过作业 Ji 经历的最大延迟的上限==为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142324662.png)
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142325256.png)
每个任务 τi 的 αl i 和 αu i 递归计算如下：
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142325379.png)
其中 f ◦ = min{f n|n ≥ 0} 是 f 的子加法闭包，其中 f n+1 = f n⊗f （定义 3.1.12，[11]）。由于τ0是周期性发布的任务，因此起始点αl 0 和αu 0 可以计算如下。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310142326682.png)
通过(11)中DLYi(|Bi|)的计算，我们可以观察到DLYi不随|Bi|减少，如引理2所述。此外，我们可以观察到$DLYi(|Bi|) ≤ H( β^{*l}_i , |Bi|+1) = \bar β^{*l}_i (|Bi|+1)$。当|Bi|时= 1, $DLY_i(|B_i|) ≤\bar{\beta^{*l}_i}(2)  =\bar{\beta^l_i}*(2(τ_i))$，用于引理 5 的证明




---
# 笔记

## 1 论文创新在于

## 2 解决了什么问题

## 3 方法

## 4 不足&可继续研究

## 5 可参考

## 6 思考

Referred in [cause-effect chain.md](E:\笔记\因果链\cause-effect chain.md)
