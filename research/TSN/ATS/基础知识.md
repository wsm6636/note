---
created: 2023-10-18T11:26
updated: 2024-03-26T23:33
tags:
  - 笔记
  - 笔记/学习笔记
---

## CAN
车载分布式嵌入式系统通常用任务和消息链建模，这些任务和消息可以分布在通过实时网络连接的两个或多个电子控制单元(ECU)1上[1]。传统上，车载通信是基于低带宽、低延迟的网络，如控制器局域网(CAN)[2]。由于<span style="color:black;background:#40a9ff !important;">CAN是事件触发的通信协议</span>，因此连接到网络的ECU不同步。

在汽车系统中，数据可以通过直接通信(无需一致性检查，即冒着数据不一致的风险)、隐式通信(在作业开始时读取并且在作业结束时写入)或逻辑执行时间模型(在预定义的时间点读取和写入，例如周期性任务发布的作业的发布时间)[14]在作业。

## CAN-FD
CAN-FD代表Controller Area Network Flexible Data Rate，它是一种用于在汽车和其他嵌入式系统中进行数据通信的标准协议。CAN-FD是传统CAN（Controller Area Network）协议的进化版本，它引入了一些新特性，以满足现代汽车和其他嵌入式系统中日益增长的数据通信需求。

CAN-FD与传统CAN之间的主要区别在于数据传输速率和数据帧大小。传统CAN通常以固定速率传输数据，通常为1 Mbps，而CAN-FD允许可变的数据传输速率，最高可达5 Mbps或更高。此外，CAN-FD还支持更大的数据帧，可以传输更多的数据。

CAN-FD的引入使其更适合高带宽应用，例如高分辨率摄像头、雷达系统、自动驾驶系统和其他需要在车辆内部进行大量数据交换的应用。它提供了更大的灵活性，以适应不同应用的需求。

总之，CAN-FD是一种用于嵌入式系统和汽车通信的现代化协议，它允许更高的数据传输速率和更大的数据帧，以满足现代车辆和嵌入式系统的通信需求。

---
## 节点
可以是终端站（通过一个端口连接到一条链路），也可以是交换机（通过多个端口连接到多条链路）。
## 流
流是沿着固定路径从一个特定源终端站发送到一个（单播）或多个（多播）终端站的<span style="color:black;background:#d59e83 !important;">一系列数据包</span>。在应用上下文中，终端站可以是流的发送者（称为发送者），也可以是流的接收者（称为侦听者）。

## "burstiness"（突发性）
在计算机网络和通信领域，"burstiness"（突发性）是指数据流中出现短期高峰的现象。它<span style="color:black;background:#ff4d4f !important;">描述了数据包或数据流在时间上的突发性变化，即数据包或数据流的到达时间间隔不均匀，出现了短期高速传输的情况</span>。

<span style="color:black;background:#40a9ff !important;">通常情况下，数据包或数据流的到达时间间隔是均匀的，即数据包以相等的时间间隔到达</span>。然而，在某些情况下，数据包或数据流的到达时间间隔可能会发生剧烈的变化。这种突发性的到达模式<span style="color:black;background:#fff88f !important;">可能是由于网络拥塞、流量波动、应用程序行为或其他因素引起的</span>。

突发性的存在对网络和通信系统的设计和管理具有重要影响。由于突发性会导致瞬时的大量数据包到达，可能会造成网络拥塞、丢包和延迟增加等问题。因此，网络管理者需要考虑突发性的特点，并采取相应的策略来处理突发性流量，以确保网络的正常运行和性能。

突发性还与流量建模和网络性能评估等领域密切相关。在流量建模中，突发性的存在需要考虑到模型中，以更准确地描述实际网络中的数据流行为。在网络性能评估中，突发性的特点可以影响性能指标的计算和预测，需要综合考虑突发性对网络性能的影响。

总而言之，突发性（burstiness）指的是数据流中出现短期高峰的现象，描述了数据包或数据流在时间上的突发性变化。它对网络和通信系统的设计、管理和性能评估等方面都具有重要的影响。

## "leak rate"（泄漏速率）
在令牌桶算法（Token Bucket Algorithm）中，"leak rate"（泄漏速率）是指<span style="color:black;background:#ff4d4f !important;">桶中的令牌每秒被移除（泄漏）的速率</span>。<span style="color:black;background:#40a9ff !important;">令牌桶算法是一种用于限制访问速率或请求速率的算法</span>，通常在计算机网络中用于流量控制和限制资源的访问。

<span style="color:black;background:#d3f8b6 !important;">令牌桶算法的基本原理是，系统中有一个桶，每秒会往桶中添加一定数量的令牌，这些令牌代表着可用的许可证。如果有请求需要处理，就需要从桶中取出一个或多个令牌来执行请求。如果桶中没有足够的令牌，那么请求就会被限制或延迟处理。</span>

"Leak rate"（泄漏速率）决定了桶中的令牌每秒被移除的速率。<span style="color:black;background:#ff4d4f !important;">如果泄漏速率低，桶中的令牌将会积累，从而允许一段时间内处理更多请求</span>，但在桶中积累的令牌不会无限增长，因为它们会以泄漏速率的速度被移除。如果泄漏速率高，<span style="color:black;background:#ff4d4f !important;">桶中的令牌会更快地被消耗，限制请求的速率。</span>

"Leak rate" 在令牌桶算法中是一个重要的参数，它可以用来控制请求的速率，确保网络或资源的访问在可接受的范围内。

## "interleaved shaping"（交错整形）
在IEEE 802.1 TSN（Time-Sensitive Networking）标准中，"interleaved shaping"（交错整形）是一种流量整形技术，用于确保网络中的时序敏感应用能够按时传输数据，同时维持网络的可预测性和低延迟。

"Interleaved shaping" 是 TSN 中的一个关键特性，<span style="color:black;background:#ff4d4f !important;">它允许不同优先级或类别的数据流以交错的方式发送，以确保高优先级流量不会完全占用网络资源，从而防止低优先级流量受到严重阻塞。</span>这有助于实现网络中的公平性和可预测性。

这种技术的基本思想是，<span style="color:black;background:#ff4d4f !important;">网络中的数据流可以按优先级进行分类，然后通过分别发送每个类别的数据包，而不是一次发送一个类别的所有数据包。</span>通过将不同类别的数据包交错发送，高优先级数据包有机会更快地通过网络，从而降低了低优先级数据包被延迟的风险。

"Interleaved shaping" 的实现依赖于 TSN 标准中的各种机制，如时间感知调度、流量整形和流控制，以协调和控制不同类别的数据流。这有助于确保网络中的时序敏感应用（如工业自动化和音视频传输）能够满足其严格的时序要求，并提供高质量的服务。

## "pseudo queues"伪队列
在IEEE 802.1 TSN（Time-Sensitive Networking）标准中，"pseudo queues" 是一种网络机制，用于模拟不同数据流之间的虚拟队列。这个概念有助于管理和控制网络中的数据流，特别是在实时通信和时序敏感应用中。

"Pseudo queues" 的主要目的是为了满足不同数据流的服务质量要求，使其能够在网络中按照其时序需求进行传输。它通过<span style="color:black;background:#ff4d4f !important;">将数据流分成不同的虚拟队列，每个队列都具有自己的调度和流量整形策略</span>。这使得网络能够为不同优先级、类别或特性的数据流提供不同的服务水平。

"Pseudo queues" <span style="color:black;background:#ff4d4f !important;">不是实际的物理队列，而是一种管理和控制机制，用于定义和区分数据流的传输特性</span>。通过使用这种机制，TSN网络可以更好地满足各种应用的要求，包括音视频传输、工业自动化、机器控制等。

总之，"pseudo queues" 在TSN中允许网络按照虚拟队列的方式对不同数据流进行管理和调度，以确保网络能够提供适当的服务质量，满足时序敏感应用的需求。






---
## ATS

IEEE Std 802.1Q-2018 的修订规定了网桥和终端站在具有恒定位数据速率的全双工链路上执行异步流量整形的程序和管理对象。<span style="color:black;background:#d3f8b6 !important;">异步流量整形可以建模为一层整形的先进先出 (FIFO) 队列，这些队列合并到传输端口中每个流量类别的 FIFO 队列中。</span>所需的整形 FIFO 队列的最小数量是可调整的，并且至少是特定桥接器的接收端口的数量。

网络中每个连接设备的独立时钟，消除了分布式设备必须就同步计时器达成一致时出现的问题。支持异步的队列。每一个都绑定了一个整形器，该整形器为队列中的帧分配合格时间，并且根据该信息，传输选择算法决定何时传输帧。

**ATS 调度程序时钟**是特定于本地系统时钟功能的实现。它用于确定帧的到达时间（8.6.11.3.1）。桥接器组件可以利用一个或多个ATS调度器时钟实例。在多个调度器时钟实例的情况下，与相同接收端口关联的所有ATS调度器实例共享相同的ATS调度器时钟实例（即，从特定接收端口接收到的所有帧的到达时间由相同的ATS调度器时钟实例确定） ）。

该算法可以描述为一种简单的门禁控制，考虑了合格时间。这些初始整形队列是简单的FIFO队列，它们确保高优先级流的处理不受恶意流或其他干扰流的影响。
整形队列需要遵循**队列分配规则**，直接引用自[8]：
<span style="color:black;background:#d3f8b6 !important;">QAR1：不允许将来自不同发射机的帧存储在相同的整形队列中。</span>
<span style="color:black;background:#d3f8b6 !important;">QAR2：来自相同发送器但不属于发送器中相同优先级的帧，不允许被存储在相同的整形队列中。</span>
<span style="color:black;background:#d3f8b6 !important;">QAR3：来自相同发送器的帧在发送器中具有相同的优先级，但在接收器中不属于相同的优先级，不允许将其存储在相同的整形队列中。</span>

> 来自相同发射器，在发射器和接收器中都具有相同的优先级，可以存储在相同的整形队列中。

在整形合格的帧之后，它们被从整形的队列中发送并存储在共享队列中。这些由下面描述的整形器之一管理，该整形器选择它们并将它们转发到网络接口，将它们释放到网络中。

ATS标准提出了两种可用于实现异步整形队列的调度算法，其中最重要的是UBS算法和Paternoster算法。

> UBS
<span style="color:black;background:#ffbbff !important;">UBS方案允许使用两种类型的整形队列：LRQ和TBE，分别基于逐帧漏桶算法和基于令牌的漏桶算法[6]。</span>

LRQ通过将分组的合格时间计算为“先前传输的帧的大小与特定类别的预留链路速率之间的商”来忽略具有稳定的传输/泄漏速率的传入流模式和形状。
> 基于逐帧漏桶算法

TBE允许一定程度的突发流量传输，同时保持平均速率，它使用“桶”中“令牌”的累积时间来计算数据包的合格时间。与 LRQ 相比，它可以在较轻的负载下更好地利用给定带宽。

调度是使用基于漏桶方法的ATS算法实现的。根据帧的合格时间、到达时间、最后一帧的大小以及允许丢弃过期帧的当前系统时钟来处理帧。因此，ATS调度器充当可用带宽的最终整形器。

> Paternoster

Paternoster 排队和调度算法是一种循环方法。它使用四个队列，在每个 epoch 中都会经过先前、当前、下一个和最后四种状态之一，如表 1 所示。在每个 epoch 中，帧都会排队到当前队列中，如果队列已满，则帧会传递到下一个或最后一个队列或被丢弃，并且仅从当前队列中出列。纪元长度会影响延迟，并且必须在网络内保持一致。 [8]
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310192225586.png)
### 端到端延迟建模方法
从 Talker 站点到单个 Listener 站点的路径被细分为包含的 n 跳，其中<span style="color:black;background:#d3f8b6 !important;">第 1 跳是从 Talker 到路径上第一个 Bridge 的跳数，第 n 跳是从路径上最后一个 Bridge 的跳数到侦听器的路径。</span>

感兴趣的流的端到端延迟界限$d_{max}(f)$ 由沿<span style="color:black;background:#d3f8b6 !important;">流 f 的路径的 n 个后续跳的每跳延迟界限</span>$d_{max}(k,f)$ 给出，如公式 (V-1) 所示。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310202031520.png)
$f$: 是流
$k$: 是从 Talker 到 Listener 的路径上的跳数索引
$d_{max}(k,f)$:  是流 f 在第 k 跳处的每跳延迟界限
图V-1说明了流f穿过沿该路径的相关机制和两个后续网桥的接口的路径，以及在以下子条款中描述的相关延迟界限[例如，在V.5中引入]。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310202042632.png)


### 缓冲延迟
缓冲延迟包括流F的帧上的所有延迟，这些延迟是由于它们驻留在沿路径的<span style="color:black;background:#fff88f !important;">传输端口中的相关业务类别的队列中</span>而产生的。对于路径上的传输端口，这些延迟由以下原因引起
A)与流F的业务类别不同的业务类别的队列中的竞争帧。
b)竞争传输的流F的业务类别的队列中的竞争帧。
C)通过ATS调度器状态机(8.6.11)的操作强制实施令牌桶业务包络。
D)在接收端口中存储和转发操作。

在没有后续条款中所述影响的情况下，**单跳缓冲延迟的延迟界**是已知的$d_{BU,max}(k,f)$(参见Speht和Samii[B87])。对于k<n (即，除了到收听者的最后一跳之外的所有跳)，延迟界限$d_{BU,max}(k,f)$由公式(V-2)给出。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310202157906.png)

对于k=n（即到侦听器的最后一跳），该界限由公式 (V-3) 给出。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310202201845.png)

$F_{H}(k,f)$，$F_{H}(k,h)$：表示在第 k 跳的上行传输端口处分别以比流 f 和流 h **更高的流量类别** (8.6.8) 传输的流集合。
$F_{S}(k,f)$，$F_{S}(k,h)$：表示在第k跳的上行传输端口处与流f**相同流量类别**传输的流的集合，分别包括流f和流h
$l_{LP,max}(k,f)$，$l_{LP,max}(k,h)$：表示在第 k 跳的上行传输端口处分别比流 f 和流 h 的类别低的任何数字流量类别的**最大干扰长度**（以比特为单位）
$l_{min}(f)$，$l_{min}(h)$：分别表示流 f 和流 h 的**最小帧长度（以位为单位**），包括所有与媒体相关的开销（8.6.11.3.11、12.4.2.2）
$b_{max}(k,g)$:是与第 k 跳处的流 g 关联的**最大突发大小，以位为单位**
$r_{max}(k,g)$:是第 k 跳上游设备中流 g 的**承诺信息速率，单位为比特/秒**
$R_{(k)}$: 是支持通过第 k 跳的上行传输端口进行传输的底层 MAC 服务提供的传输速率，以比特/秒为单位

### 与媒体相关的延迟
流F的帧在该跳的==上行传输端口和该跳的下行接收端口之间==经历与媒体相关的延迟。此延迟的测量范围为
A)帧的特定八位字节从**上行传输端口通过边界**到网络物理介质的时间，以及
b)该特定八位字节从网络物理介质通过**边界到下行端口**的时间。
第k跳的最大媒体相关延迟被表示为$d_{MD,max}(k)$并且假设为已知以供分析。

媒体相关延迟的变化不会影响V.9中的组合延迟界限。这种变化在相关ATS调度器时钟的到达时间识别和相关ATS调度器实例的处理之前发生。如果令牌桶信封实施需要，则经历比由相同调度器实例处理的较早帧更低的媒体相关延迟的帧将被调度器延迟。

### 内部到达时间识别延迟
对于流的任何帧，第k跳(>1)的**上游网桥中的最大到达时间识别延迟**由相关的ArrivalRecognitionDelayMax参数(8.6.11.3.1，12.31.8.5)给出。为了紧凑表示和符号一致性，ArrivalRecognitionDelayMax随后表示为$d_{AT,max}(k)$。
到达时间识别延迟的变化不会影响V.9中的组合延迟界限，类似于媒体相关延迟(V.4)的变化。

### 内部处理延迟
由关联的ProcessingDelayMin和ProcessingDelayMax参数(8.6.11.3.2、12.31.8.6、12.31.8.7)给出流的任何帧的第k跳(>1)的**上游网桥中的处理延迟的界限**。关联的ProcessingDelayMin和ProcessingDelayMax参数随后分别表示为$d_{PR,min}(k)$和$d_{PR,max}(k)$。
**网桥内部处理延迟的变化会增加缓冲延迟中的突发大小(V.3)**。根据指定的分配合格时间的计算(8.6.11.3.2)，这些变化存在于相关的时钟偏差变化(v.7)内。
**注意**--最大到达时间识别延迟和最大处理延迟的总和不同于桥延迟属性(12.32.1.1)中相关的最大独立延迟。这个总数可能更大。

### 组合延迟界
对于从说话者站到具有至少一个网桥(n>1)的收听站的路径，**感兴趣的流的组合端到端延迟界**$d_{min}(f)$可以用等式(V-6)来概括
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310231035701.png)
方程式(V-7)、方程式(V-8)和方程式(V-9)1<k<n.
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310231036343.png)
在从说话者站到收听站的路径上没有桥的情况下(即，n=1)，端到端的延迟界可以用公式(V-10)来概括。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310231038560.png)






---
## 时分多路复用

![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202310191437773.png)
时分多路复用允许在一个周期内预留时隙，以便能够及时传输周期性实时数据

---

## TAS/QBV
作为TSN的核心组件之一，时间感知调度器(TAS)首次引入了基于传输时间对传统以太网帧的数据传输进行优先排序的可能性，从而保证了它们在定义的时间点上的转发和交付。
这允许提供专用时隙，用于在周期内传输具有实时要求的数据分组。在时间感知调度器的帮助下，传统的尽力而为以太网业务的传输可以被临时中断，以便在为高优先级业务预留的时隙内转发时间敏感的数据业务。因此，时间感知调度器允许相对于传统的尽力而为数据业务对周期性实时数据(参见图2中的时隙1)进行优先排序。
与严格的优先级方案类似，时间感知型调度器使用存在于以太网头的VLAN标记中的CoS优先级(PCP-优先级代码点)。
### 传统AVB
传统上，AVB 以太网使用基于类的服务模型。多个流（每个流具有保留的数据速率）被收集在最多两个 FIFO 队列（A 类和 B 类）中。在数据包传输之前，队列由基于信用的整形器 (CBS) 整形 [8]。 CBS 随着时间的推移将数据包分散在队列中，以便不超过保留速率的总和。

---

## CQF/QCH
循环排队和转发 (CQF) 是在 IEEE 802.1 TSN 任务组 [13] 中提出的，目前正在标准化为 802.1Qch [14]。CQF 是一种基于同步帧的调度方法，类似于走走停停的排队[15]。传输由网络范围内的可配置时间框架强制执行。与 CBS 不同，CQF 依赖于全局同步时间概念的可用性。<span style="color:black;background:#d59e83 !important;">即如果时间同步失败，则CQF失败。</span>

---

## RCSD
Rate-Controlled Service Disciplines（RCSD）是一种网络服务管理策略，旨在实现网络流量的速率控制和流量管理。这种服务策略主要用于计算机网络和通信系统，以确保在网络中传输的数据流不会超过分配给它们的带宽限制，从而维护网络的性能和可靠性。

RCSD的主要特点包括：

1. 速率控制：RCSD旨在控制流量的传输速率，确保不超过事先定义的速率上限。这有助于防止某些流量占用过多的带宽，从而确保其他流量也有足够的带宽可用。

2. 服务质量（QoS）管理：RCSD可用于实施服务质量策略，以确保关键应用程序的带宽要求得到满足。这对于需要低延迟、高可用性或其他特定要求的应用程序非常重要。

3. 流量控制：RCSD还可以用于流量控制和调度，以确保网络中的流量按照特定的规则和策略进行传输。这有助于优化网络性能，并减少网络拥塞的可能性。

4. 端到端控制：RCSD通常在端到端的基础上实施，这意味着它可以在网络的源和目的地之间控制流量，以确保整个路径上的速率控制和服务质量。

RCSD是网络管理中的一种关键工具，它有助于确保网络资源的有效分配和利用，并提高了网络的可管理性和可预测性。这对于支持多种应用程序和服务的复杂网络非常重要，尤其是在需要满足不同流量类型和性能要求的情况下。