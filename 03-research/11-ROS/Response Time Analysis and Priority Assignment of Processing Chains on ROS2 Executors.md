---
created: 2024-05-15T18:55:00
updated: 2024-05-28T22:42
tags:
  - 笔记
  - 笔记/文献笔记
status:
  - done
---
# Response Time Analysis and Priority Assignment of Processing Chains on ROS2 Executors
 



**TitleTranslation:**  ROS2执行器处理链的响应时间分析和优先级分配
**Journal or Conference:**   2020 IEEE Real-Time Systems Symposium (RTSS)  
**Authors:**  YueTang, ZhiweiFeng, NanGuan, XuJiang, MingsongLv, QingxuDeng, WangYi
**Pub.date:**  2020-12
**DOI:**  10.1109/RTSS49844.2020.00030
**tags:** #/ing, schedule
**zoterolink:**  [zotero](zotero://select/library/items/LNS5SD3S)

# 摘要

ROS（机器人操作系统）是目前最流行的机器人软件开发框架。安全关键领域的机器人软件通常受到硬实时约束，因此设计人员必须对其时序行为进行正式建模和分析，以确保在运行时始终遵守实时约束。本文研究了ROS2中处理链的实时调度和分析，ROS2是第二代ROS，主要考虑实时性。首先，我们研究 ROS2 执行器上处理链的响应时间分析。我们证明这个问题唯一存在的结果是乐观和悲观的，并开发新技术来解决这些问题并显着提高分析精度。其次，我们揭示了执行器上处理链的响应时间仅取决于其最后的调度实体（回调），这为设计人员提供了有用的指导，不仅可以改善响应时间界限，还可以改善实际的最坏情况/平均值以很少的设计成本实现系统的响应时间。我们使用随机生成的工作负载进行实验，并在现实的 ROS2 平台上进行案例研究，以评估和演示我们的结果。

# 一、简介
ROS（机器人操作系统）[1]是目前最流行的机器人软件开发框架和事实上的标准。自 2010 年发布 1.0 版本以来，ROS 已被工业界和学术界数十万开发人员和研究人员使用，为大量不同类型的机器人系统提供支持 [2]、[3]。 ROS 的一个主要理念是通过促进软件模块化和可组合性来提高机器人软件开发的生产力，但这也导致了一些根本性的缺点。一个主要缺点是缺乏实时能力，这限制了 ROS 的更广泛传播，因为机器人中的计算通常受到时间限制 [4]。

ROS2 [5]是自2017年以来发布的第二代ROS，继承了ROS的成功理念，并将其置于改进的基础上[6]。 ROS2的一个主要考虑因素是支持强大的实时能力。例如，ROS2采用DDS（数据分发服务）[7]作为进程间通信中间件进行实时数据交换，可以部署在实时操作系统之上（而不是仅运行在Linux上）并支持实时操作系统。面向控制的代码路径上的时间安全资源预分配。

ROS2的新架构提供了良好的基础，但其本身不足以支持硬实时机器人软件。对于硬实时系统，设计人员必须验证系统时序属性并保证在运行时的任何情况下都遵守时序约束。最近，卡西尼等人[6] 在 ROS2 中处理器调度的形式化建模和分析方面进行了开创性工作。特别是，[6]对 ROS2 执行器（ROS2 多路复用计算任务的核心组件）中的工作负载结构和调度策略进行了建模，并开发了限制 ROS2 执行器上处理链响应时间上限的技术。事实证明，ROS2执行器的调度行为与过去实时调度研究中研究的行为有很大不同，需要新的分析技术。 [6]的高层愿景和具体成果对ROS社区[8]、[9]产生了直接影响，并有可能引发实时调度和ROS社区之间更密切的互动，以支持分析硬实时保证ROS2。

尽管其意义重大，<span style="background:#fff88f">[6]中的工作也存在一些问题：ROS2执行器上的处理链（在[6]中称为子链）的响应时间界限既是乐观的（界限可能小于实际最坏情况）又是悲观的（该界限通常不必要地大于实际最坏情况）。我们将在第四节详细讨论这些问题。</span>

本文的第一个贡献是通过开发用于 ROS2 执行器上的处理链的新响应时间分析技术来解决[6]中的上述问题。我们的新分析技术通过探索对 ROS2 执行器调度行为的深入了解，显着提高了分析精度。对随机生成的工作负载进行的实证评估表明，我们的<span style="background:#ff4d4f">新响应时间界限始终优于[6]</span>，在不同的参数设置下具有显着的优势。

应用程序开发人员提高系统响应能力，不仅是硬实时系统的响应时间上限，而且是软实时和通用系统的实际最坏情况和平均响应时间，几乎不需要甚至不需要额外的设计成本。我们使用随机生成工作负载的模拟实验和基于 ROS2 的真实机器人软件系统的案例研究来演示我们的发现的用途。

我们的第二个贡献是<span style="background:#ff4d4f">研究回调优先级分配如何影响 ROS2 执行器上处理链的响应时间</span>，据我们所知，在之前的工作中尚未解决这个问题。我们发现<span style="background:#ff4d4f">处理链的响应时间仅取决于该处理链中最后一个回调的优先级：分配给最后一个回调的优先级越高，处理链的响应时间可能越短。</span>这个属性可以帮助ROS2应用程序开发人员提高系统响应能力，不仅是硬实时系统的响应时间上限，而且是软实时和一般系统的实际最坏情况和平均响应时间，几乎没有或甚至没有额外的设计成本。我们使用随机生成工作负载的模拟实验和基于 ROS2 的真实机器人软件系统的案例研究来演示我们的发现的用途。

# 二.相关工作
学术研究界意识到ROS缺乏实时能力，并致力于这方面的改进。 [10]将优先级机制引入ROS的调度和数据交换，[11]在实时操作系统上运行ROS的实时节点以获得更好的实时性能。 [12]提出了一种实时调度框架，[13]提出了基于透明CPU/GPU协调机制的实时ROS扩展。然而，这些研究仅提高了系统的实时能力，并没有提供任何分析实时性保证。对于ROS2，[14]、[15]通过实验评估了不同底层实时操作系统和不同DDS实现的ROS2的性能，这些都是基于测量的，但没有考虑形式化建模和分析。

据我们所知，现有的唯一关于 ROS2 执行器时序行为的形式化建模和分析的工作是 [6]。然而，如上所述，[6]中处理链的响应时间分析既乐观又悲观。我们的工作通过探索对 ROS2 执行器调度行为的更深入了解并开发新的分析技术来解决这些问题。此外，我们研究了回调优先级分配对处理链响应时间的影响，这在[6]中没有考虑。

基于链的任务模型的时序分析的实时调度研究已经做了很多工作，根据任务的激活方法可以将其分为两类[16]：触发链[17]-[21]，其中前置任务触发后继任务的释放，以及数据链[16]、[22]-[25]，其中任务被单独触发，因此可能发生过采样或欠采样。从广义上讲，本文考虑的ROS2执行器上的处理链属于触发链范畴。然而，ROS2 执行器的调度行为与之前工作中研究的调度行为显着不同，并且没有现有的分析技术适用于我们的问题。

# 三．系统模型
本节介绍系统模型。我们首先提供一些关于 ROS2 的简要背景和我们的系统模型的背景（ROS2 的更详细介绍可以在 [6] 中找到）。图1-(a)显示了ROS2的架构。 <span style="background:#40a9ff">ROS2 应用程序通常由单个节点组成，这些节点使用发布订阅范例相互通信：节点发布有关主题的消息，主题将消息广播到订阅该主题的节点。节点通过激活回调来处理每条消息来对传入消息做出反应。为了部署 ROS 应用程序，各个节点被分发到主机，然后映射到操作系统进程。 ROS2客户端库中的执行器协调操作系统进程中节点回调的执行。 </span><span style="background:#40a9ff">ROS2 提供了两种内置执行器：一种是在单个线程中执行回调的顺序执行器，另一种是在多个线程之间分配待处理回调的处理。</span>与[6]相同，本文考虑了作为在单线程执行器上执行的处理链（如图1-（b）所示）实现的应用程序，其中工作负载必须顺序执行。链中的每个顶点代表一个回调1。处理链通常以系统计时器激活的计时器回调开始，然后是可能跨越多个执行器的几个常规回调。在本文中，我们将注意力限制在计算<span style="background:#d3f8b6">单个执行器上的链的响应时间</span>上。然而，与[6]中相同，我们可以通过组合性能分析（CPA）方法轻松地将我们的结果扩展到跨多个执行器的链的端到端响应时间分析[26]-[29]。


![image.png|525](https://raw.githubusercontent.com/wsm6636/pic/main/202405161128817.png)


## A. 工作负载模型

我们考虑 ROS2 执行器上的系统 Γ，它由一组独立的处理链（或简称链）组成 Γ = {C, C′, C′′...}。每个链 C ∈ Γ 由回调 C = {Ctm, C1, ..., C||C||} 的有序序列组成。 Ctm 是一个计时器回调，后面跟着常规回调 C1, ..., C||C||，其中 ||C||表示C中常规回调的数量。最后一个常规回调C||C||称为链的接收器回调。除非明确指定，本文约定使用 C = {Ctm, C1, ..., C||C||} 表示当前正在分析的链，称为分析链，并使用 C′ = { Ct′m, C′1, ..., C′ ||C′||} 表示任意其他链，称为干扰链，它与 C 竞争处理资源。我们使用 e(C) 表示总和链 C 的 WCET（最坏情况执行时间）：
![image.png|275](https://raw.githubusercontent.com/wsm6636/pic/main/202405161605699.png)
其中 e(Ctm) 是计时器回调 Ctm 的 WCET，e(Cz) 是第 z 个常规回调的 WCET (1 ≤ z ≤ ||C||)。

> 下，第几条回调链
> 上，回调链中的第几个回调

每次链的计时器回调接收到外部事件时，链都会重复释放链实例。我们用 Ci 表示 C 的第 i 个实例，它由相应的回调实例 $C^i = {C^i_{tm}, C^i_1 , ..., C^i_{||C||}}$ 组成。 $C^i_{tm}$ 执行完成后，$C^i_{tm}$ 会产生一条消息来调用$C^i_{1}$ ，然后$C^i_{1}$完成后会产生一条消息来调用 $C^i_{2}$ ，依此类推 。链 C 的释放模式（即外部事件对其定时器回调的到达模式）由到达曲线 αC(Δ) 表征，<span style="background:#40a9ff">该曲线限制了在长度为 Δ 的任何时间间隔内释放的 C 链实例数量的上限。</span>我们用
![image.png|350](https://raw.githubusercontent.com/wsm6636/pic/main/202405161613857.png)
表示 αC(Δ) [30] 的伪逆函数，即释放链 C 的 x 个连续实例的任何时间间隔的长度，其下界为 $\overline{αC(x)}$。

请注意，我们的模型允许 e($C_{tm}$) = 0，这意味着链 C 没有计时器回调。这是为了模拟应用程序的端到端处理链的一部分被分配给所考虑的执行器的情况（例如，图 1-(b) 中执行器 B 中的较低链）。

链实例 $C^i = {C^i_{tm}, C^i_1 , ..., C^i_{||C||}}$ 的响应时间是其释放时间与其接收器回调实例 $C^i_{||C||}$ 完成时间之间的时间距离。链 C 的最坏情况响应时间是其所有实例中的最大响应时间。本文的目标是计算每个链 C ∈ Γ 的最坏情况响应时间的安全上限。

## B. 资源模型
与[6]相同，我们假设 Γ 在<span style="background:#d3f8b6"> ROS2 中的单线程执行器上执行</span>，并具有以供应绑定函数<span style="background:#d3f8b6"> sbf (Δ) 为特征的资源预留，这限制了执行器在任何环境中可用的处理时间量</span>。长度为 Δ 的时间间隔。我们用
![|475](https://raw.githubusercontent.com/wsm6636/pic/main/202405161628460.png)
表示 sbf (Δ) [30] 的伪反函数，即 $\overline{sbf (x)}$ 是提供 x 个处理时间单位的任何时间间隔长度的上限。


## C. 调度模型
执行器维护一个就绪集Ω，它记录了准备执行的回调实例。当回调实例完成时，它将从 Ω 中删除。定时器回调实例一旦被外部事件触发就准备就绪并立即放入Ω中。 Ω 中可以同时存在同一计时器回调的多个实例。当且仅当同时满足以下两个条件时，常规回调实例 $C^i_z$ 才准备就绪：
  - $C^i_{z}$ 的输入消息可用，即前面的回调实例 $C^i_{z-1}$（或 $C^i_{tm}$，如果 z = 1）已完成。 
  - 同一回调的所有早期实例（$C^{i−1}_z$、$C^{i−2}_z$ 等）均已完成。因此，同一回调一次最多可以有一个实例准备就绪。
<span style="background:#40a9ff">常规回调实例在准备就绪时不会立即放入 Ω 中。相反，所有当前准备好的常规回调实例都会在 Ω 为空的时间点（称为轮询点）添加到 Ω 中。</span>

两个轮询点之间的时间间隔称为处理窗口。执行器在当前处理窗口中非抢占式地选择Ω中的回调实例（包括定时器和常规回调实例）来一一执行。<span style="background:#d3f8b6">在处理窗口中执行就绪回调实例的顺序取决于它们的优先级。每个回调都有一个固定且唯一的优先级，并且其所有实例都继承此优先级。</span>计时器回调的优先级高于常规回调。我们使用 hp(Cz) 来表示比回调 Cz 优先级更高的回调集合。


![image.png|725](https://raw.githubusercontent.com/wsm6636/pic/main/202405161613621.png)
每次链的计时器回调接收到外部事件时，链都会重复释放链实例。我们用 Ci 表示 C 的第 i 个实例，它由相应的回调实例 Ci = {Ctim, C1i , ..., Ci ||C||} 组成。 Ctim 执行完成后，Ctim 会产生一条消息来调用 C1i ，然后 C1i 完成后会产生一条消息来调用 C2i ，依此类推 2。链 C 的释放模式（即外部事件对其定时器回调的到达模式）由到达曲线 αC(Δ) 表征，该曲线限制了在长度为 Δ 的任何时间间隔内释放的 C 链实例数量的上限。我们用

## D. 一个说明性的例子
图2-(a)中的两条链C和C'在执行器上执行。每个顶点上方的数字代表该回调的优先级：数字越小优先级越高。两条链的到达曲线αC(Δ)和αC′(Δ)以及执行器的sbf(Δ)如图2-(b)所示。假设 C 和 C' 的第一个链实例分别在时刻 0 和 7 被释放。回调 WCET 为：e(Ctm) = 2、e(C1) = 2、e(C2) = 2、e(C3) = 4、e(Ct′m) = 2、e(C′2) = 4 ，e(C′3) = 2。图2-(d)显示了执行序列，其中时间区间[8, 10]、[18, 20]和[28, 30]中的灰色块表示处理资源不可用。图2-(c)显示了Ω在一些关键时间点的内容（其中添加了一些准备好的回调实例）。

# 四．对[6]中分析的讨论
在[6]中，链C的响应时间界限是通过找到满足（[6]中的引理8）的R的最小值来计算的：
![image.png|500](https://raw.githubusercontent.com/wsm6636/pic/main/202405171503612.png)
请注意，在上面的等式中，e(C||C||) 是所分析的链 C 的最后一个常规回调的 WCET。

我们首先使用图3中的例子来表明上述计算响应时间界限的方法可能过于乐观（即使系统只包含一条链）。设 sbf (Δ) = Δ, e(Ctm) = 2, e(C1) = 2, e(C2) = 8。C 的到达曲线如图 3 所示。我们可以将 (1) 实例化为本例参数：
sbf (R) = αC(R − 7) · 12。其中R=12为最小解。然而，我们可以在图3中看到，C的第二个和第三个实例的响应时间分别为22和24，这比获得的界限12大。

![image.png|650](https://raw.githubusercontent.com/wsm6636/pic/main/202405171504101.png)

现在我们简要讨论为什么[6]中的界限过于乐观。直观上，(1)的RHS计算的是链实例的释放时间和其接收器回调开始执行的时间点之间释放的总工作负载（由于回调是非抢占式执行的，因此在该时间点之后释放的工作负载不会干扰该链实例）。由于 sbf (R) 表示提供足够资源来处理此类工作负载的时间长度，因此求解 (1) 似乎可以安全地限制响应时间。但式（1）中的 RHS 所代表的工作负载仅包括链发布时间之后释放的工作负载，而链实例实际上可能会受到其发布时间之前释放的工作负载的影响（即所谓的“带入”） 。在我们的示例中，第二个链实例受到同一链的第一个实例的“进位”干扰，而第三个链实例受到第二个实例的“进位”干扰（一般来说，链实例也可能受到进位干扰） -受到其他链的干扰）。因此，(1) 的 RHS 低估了所分析的链实例所遭受的总干扰，因为它没有计算“进位”。
![image.png|650](https://raw.githubusercontent.com/wsm6636/pic/main/202405171540409.png)

在证明 (1) 的 RHS 可能低估干扰之后，接下来我们证明它也可能导致高估。图4示例的参数除了链的到达曲线外与图3相同。求解(1)得到的界限是36，而实际最坏情况的响应时间是28。现在我们讨论悲观的原因。直观上，(1)的RHS统计了所分析的链实例的sink回调实例开始时间之前释放的每个链实例的所有工作负载。然而，实际上一些回调实例可能在分析的链实例的接收器回调实例之后执行，因此不会造成干扰。在图4中，第二个链实例的响应时间最差，我们可以看到第三个链实例的接收器回调实例实际上不会干扰第二个链实例。虽然在这个例子中，过度计数并不是很大，但一般来说，这可能会导致严重的悲观情绪，如第七节中的实验所示。

# 五、响应时间分析
## 一、概述
如果至少有一个就绪回调实例尚未完成（正在执行，或在就绪集 Ω 中等待，或已就绪但尚未放入 Ω），我们就说执行器正忙。<span style="background:#d3f8b6">如果执行器在a之前和b之后不忙，并且执行器在[a，b]中的任何时间点都忙，则时间间隔[a，b]是繁忙时段。</span>

我们重点分析任意繁忙时段的C链。我们特别关注 Ci 的分析，它是在这段繁忙时期发布的第 i 个 C 实例（i 是任意的）。我们将 C 称为已分析链，将 Ci 称为已分析链实例。除 C 之外的所有其他链都是干扰链，它们的实例也是干扰链实例。不失一般性，我们让时间点0作为该繁忙时段的开始时间。我们定义了三个重要的时间点：
- t1：Ci 的释放时间，
- t2：$C_1^i$ 开始执行时，
- t3：$C^i_{||C||}$ 时开始执行。

我们的目标是找到 t3 − t1 的上限，通过该上限，我们可以通过考虑执行 Ci ||C|| 的时间来获得 Ci 的响应时间界限。 （因为回调是非抢占式执行的）。下面，我们重点介绍 t3 − t1 上限计算中的一些关键点。

首先，我们可以得出繁忙期长度的上限，从而找到未知索引 i 的上限（回想一下，Ci 是所考虑的繁忙期中 C 的任意实例）。因此，我们的分析就像每一步中 i 都是已知值一样，枚举低于其上限的所有 i 值，最后获得 i 的所有值中的最大值。

对于上限 t3 -t1，我们将设置下限 t1 和上限 t3。下限 t1 很容易，因为 $\overline{αC(i)}$ 下限了 C 释放 i 个实例的时间间隔的长度。

对于上限 t3，我们将在 [0, t3] 中执行的总工作负载设定上限。这个总工作量由被分析的链 C 本身和干扰链共同贡献，它们将分别有上限。

使我们的分析比[6]更精确的关键观察如下。<span style="background:#40a9ff">在 ROS2 执行器上，链以“管道”方式执行。</span>因此，对于被分析的链实例 Ci“之后”的链实例（被分析的链 C 或干扰链 C'），只有其部分工作负载可以在 Ci ||C|| 之前执行。其余部分在计算Ci受到的干扰时被排除（而在[6]中他们的工作量全部算作对Ci的干扰）。

接下来，我们首先介绍链的“管道”式执行模式的属性（第 V-B 节），然后将分析链本身（第 V-C 节）和干扰链的总工作负载上限设置为 Ci（第 V-D 节） ），最后将它们放在一起并呈现整个响应分析过程（第 V-E 节）。

## B. 性质
我们使用 $pw_n$ 来表示所考虑的繁忙时段中的第 n 个处理窗口。
**引理 1**  处理窗口中最多执行一个常规回调实例。
证明：一次最多有一个常规回调实例准备就绪。因此，Ω 在处理窗口开始时最多包含一个常规回调实例。此外，由于仅在处理窗口边界处将新元素添加到Ω，因此证明了引理。

**引理2** 设C 为任意链（被分析链或干扰链）。假设$C_1^k$（$C^k$的第一个常规回调）在处理窗口$pw_n$中执行，则$C^l_1$（l > k）最早执行的处理窗口是$pw_{n+l−k}$。
证明：引理直接遵循引理 1。

**引理3** 链实例的至多一个常规回调实例在处理窗口中执行。
证明：当常规回调实例完成时，其后继者最早可以在当前处理窗口结束时（因此不能在当前处理窗口中执行）添加到Ω中。

**引理4** 链实例的常规回调实例在连续的处理窗口中一一执行。
证明：通过反证法证明，假设回调实例 $C^i_x$ 第一次违反引理，即 $C^i_x$ 不在 $C^i_{x−1}$ 执行窗口之后的处理窗口中执行（用 $pw_n$ 表示）。在 $pw_n$ 结束时，$C^i_x$ 的输入消息已准备就绪，因此 $C^i_x$ 不在$pw_{n+l}$中执行的唯一原因是同一回调的较早实例 $C^j_x$ 在 $pw_{n+l−k}$ 中执行。由于 $C^i_x$ 是第一个违反引理的回调实例，因此 $C^aj_{x-1}$ 必须在 $pw_n$ 中执行。因此，我们可以得出结论，同一回调的两个实例 $C^i_{x−1}$ 和 $C^j_{x−1}$ 都在 $pw_n$ 中执行，这与引理 1 相矛盾。

通过引理 4，我们知道所分析的链实例 $C^i$ 的常规回调实例一旦启动，必须​​恰好在 ||C|| 内结束。连续的处理窗口。因此，在计算 [t1, t3] 中其他链实例的工作负载时，我们可以使用此属性来排除其工作负载中必须在那些 ||C|| 之后执行的部分。连续的处理窗口。这是使我们的分析比[6]更精确的关键。

## C. 被分析链的工作负载界限 下
面的引理给出了在 [0, t3] 中执行的被分析链 C 的总工作负载的上限： 
**引理5**  在 [0, t3] 中执行的被分析链 C 的工作负载是上限以W(t3)为界：
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172231167.png)
证明：C在[0,t3]中的工作负载有两部分：
(i)Ci本身和Ci之前释放的C实例的工作负载，
(ii)Ci之后释放的C实例的工作负载。
首先，我们设定上限 (i)。 Ci 本身在 t3 之前执行的工作量最多为 e(C) − e(C||C||)。 Ci之前释放的C实例数量为i−1，因此它们的工作量最多为e(C)·(i−1)。将它们放在一起，(i) 的上限为 e(C) · i − e(C||C||)。在余下的证明中，我们设定上限 (ii)。

令Cj 为Ci (j > i) 之后释放的C 实例。 Cj 的计时器回调实例的工作负载的上限只是 e(Ctm)。接下来我们重点关注限制其常规回调实例的工作负载。令 pwm 为 Cj 1 执行的处理窗口。我们的目标是分析pwm，····，pwn+||C||−1中执行的Cj的工作量（注意t3是在pwn+||C||−1中，），它由两部分组成：

1）pwn+||C||−1之前执行的工作负载：当m ≥ n + ||C||− 1时，pwn+||C||−1之前执行的工作负载为0。当m < n + ||C||− 1时，根据引理 3，在一个处理窗口中最多执行一个 Cj 的常规回调实例。因此，在 pwm、····、pwn+||C||−1 中执行的 Cj 定期回调实例的总工作量至多为 Σn+||C||−1−m,z=1 e(Cz)。

2)pwn+||C||−1 和 t3 之前执行的工作负载：当 m > n + ||C|| − 1时，pwn+||C||−1 中执行的工作负载为 0。当 m ≤ n+||C||−1 时，由于 Cj 的常规回调实例在从 pwm 开始的连续处理窗口中执行，因此pwn+||C||−1 中执行的 Cj 是 Cj n+||C||−m，当且仅当 Cj n+||C||−m 的优先级高于 Ci ||C|| 时，它在 t3 之前执行。因此，我们通过 e(Cn+||C||−m) · ε 来计算 t3 之前的工作负载，其中，如果 Cn+||C||−m ∈ hp(C||C||)，则 ε = 1，且 ε =否则为 0。

综上所述，在 [0, t3] 中执行的 Cj 常规回调实例的总工作负载上限为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172251943.png)
我们可以观察到 (3) 相对于 m 是不增加的。 （直观上，如果m增加，一些回调将被排除在（3）的第二项之外。虽然其中一个被计入（3）的第一项，但（3）的整体值不能变大，无论是否ε 等于 1 或 0。）因此，当 m = n + j − i 时（3）最大化（根据引理 2，我们知道 m ≥ n + j − i），并且我们可以将 (3) 重写为 m = n + j − i.
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172253729.png)
到目前为止，我们已经证明了 [0, t3] 中 Cj 的总工作量上限为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172254763.png)
请注意，当 μ ≤ 1 时，Σμ−1,z=1 e(Cz) = 0；当 μ < 1 时，e(Cμ) · ε = 0，对应于 m ≥ n + ||C||− 1 的情况。 和 m > n+||C||−1 时，分别分析 pwn+||C||−1 之前和 pwn+||C||−1 中执行的工作负载。由于 [0, t3] 期间释放的 C 实例数量至多为 αC(t3)，因此对每个具有 j ∈ [i + 1, αC(t3)] 的 Cj 求和 (4) 中的上限证明第(ii)部分的工作量上限为M(t3)。

## D. 干扰链的工作负载界限 
我们使用 γ′ 来表示在 [0, t2] 中释放的干扰链 C′ 的实例数量（即，在分析的链实例 Ci 的第一个常规回调实例开始执行之前释放） ）。以下引理给出了 [0, t3] 中干扰链 C' 的工作负载的上限 W'(γ', t3)。注意，W′(γ′，t3)不仅取决于t3，还取决于γ′。在下面的引理中，我们可以将 γ′ 视为已知值。稍后我们将通过引理 7 和引理 8 来修正 γ′ 的值。
**引理 6**   在 [0, t3] 中执行的干扰链 C′ 的工作负载上限为 W′(γ′, t3)：
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172300204.png)
引理 6 的证明在附录中给出。证明思路与引理 5 类似。它们的差异是由于 (i) 干扰链的常规回调次数可能与分析链不同（而在引理 5 中，分析链实例和造成干扰的实例都不同）来自同一个链，因此具有相同数量的常规回调）； (ii) 干扰链中的实例和分析的链实例之间的释放顺序可能与其常规回调实例开始执行的顺序不同（而在引理 5 中，两个考虑的链实例来自同一链，并且它们的释放顺序和开始执行它们的常规回调实例的顺序是一致的）。

下面我们将固定γ′的值。引理 7 将表明 W'(γ', t3) 相对于 γ' 不减少，引理 8 将导出 γ' 值的上限。因此，通过将 γ′ 设置为 M′(γ′，t3) 的上界，我们可以得到 M′(γ′，t3) 的上界。

**引理7** W'(γ',t3)相对于γ'不减。
证明：我们首先用 x = j − γ′ 重写 M′(γ′, t3)：
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172304654.png)
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172305399.png)

根据 Ψ(x) 的定义，我们可以观察到 Ψ(x) ≤ e(C′)（直观上， Ψ(x) 表示在 t3 之前执行的 C′γ′+x 的回调实例的工作量，这不能被大于整条链的 WCET 总量）。给定任意 γ′1 ≤ γ′2，我们有
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172313195.png)
**引理 8** t2 的上限为满足以下方程的 δ 的最小正值：
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172314094.png)
证明：我们通过反证法证明引理，假设 t* 是 (6) 的最小解并且 t* < t2。 [0, t*] 中执行的工作负载由三部分组成： 
- [0, t*] 中释放的分析链C 的定时器回调实例的工作负载。 [0, t*] 中释放的 C 的定时器回调实例的数量最多为 αC(t*)，因此它们的工作量上限为 αC(t*)e(Ctm)。 
- 在[0, t*] 中准备就绪的分析链C 的常规回调实例的工作负载。由于 Ci 的第一个正则回调在 t2 开始执行，并且 t* < t2，因此 [0, t*] 中准备好的正则回调实例都属于 Ci 之前的链实例。此类链实例的数量最多为 i − 1，因此相应的工作负载上限为 (i−1) Σ||C|| z=1e(Cz)。 
-  [0, t*] 中释放的干扰链实例的工作负载。对于每个干扰链C′，[0,t*]中释放的实例数量最多为αC′(t*)。因此，在 [0, t*] 中释放的所有干扰链实例的总工作负载的上限为 Σ C′∈Г\{C} αC′ (t*)e(C′)。

总之，可以在 [0, t*] 中执行的工作负载的上限为 X (t*)。另一方面，[0, t*] 中可用的资源至少为 sbf (t*)。由于 X (t*) = sbf (t*)，[0, t*] 中可以执行的工作负载最多为 sbf(t*)，因此 t* 准备好的所有工作负载都已由 t* 完成，这与事实上 t* 是繁忙时段中间的一个时间点（回想一下，我们正在分析繁忙时段中 C 的第 i 个实例，并且执行器在 [0, t3] 期间必须繁忙）。
我们可以将（6）重写为 δ = $\overline{sbf (X (δ))}$ 并应用众所周知的定点迭代技术 [31] 来找到最小正解。结合引理 6、引理 7 和引理 8，我们有：
**引理 9** 在 [0, t3] 中执行的干扰链 C' 的工作负载上限为 W'(αC' ($\overline{t2}$), t3)，其中 $\overline{t2}$ 是 (6) 中 δ 的最小解。

## E. 计算响应时间界限
到目前为止，我们已经获得了分析链和每个干扰链的工作负载上限，从而获得了系统的总工作负载，在 [0, t3] 中。另一方面，sbf (t3) 给出了 [0, t3] 中可用资源的下限。因此，我们可以通过以下引理对 t3 进行上限： 

**引理 10** t3 的上限是满足以下等式的 δ 的最小正值
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172319484.png)
其中 $\overline{t2}$ 是引理 8 中 (6) 的最小解。
由于篇幅限制，引理 10 的形式证明被省略。直观上，式（7）的 LHS 和 RHS 都是关于 δ 的非减函数，它们的第一个交点给出了一个时间点的上限，在该时间点上，在分析的链实例之前要执行的就绪工作负载不大于可用资源，因此分析的链实例的接收器回调实例可以开始执行。与(6)类似，我们可以用sbf重写(7)，并应用定点迭代技术来找到其最小正解。
最后，所分析的链实例 Ci 的响应时间界限通过以下引理计算：

**引理 11** Ci 的响应时间的上限为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172320543.png)
证明：设tf表示Ci ||C||的结束时间，因此Ci的响应时间为tf − t1（回想一下t1是Ci的释放时间）。 [0, t3] 中的总工作负载上限为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172321496.png)
并且由于 t3 ≤ $\overline{t3}$，其上限为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172321663.png)
且上界为 sbf ($\overline{t3}$)，因为$\overline{t3}$ 是 (7) 的解。因此，[0, tf ] 中的总工作负载的上限为 sbf ($\overline{t3}$) + e(C||C||)。由于 $\overline{sbf (x)}$ 是完成工作负载 x 的时间上限，我们知道
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172323458.png)
另一方面，αC(i) 限制了释放 i 个 C 实例的时间间隔长度，因此 t1 ≥ $\overline{αC(i)}$。结合式(9)，引理得证。下一个引理限制了繁忙时段长度的上限，从而限制了繁忙时段中可以释放的实例数量的上限。

**引理 12** 令 $\overline{Δ}$ 为满足以下方程的最小正值：
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172325770.png)
则所分析的链 C 在任何繁忙时段释放的实例数量上限为 αC($\overline{Δ}$)。

由于篇幅限制，省略了引理的正式证明。直观上，(10)的LHS是一个时间间隔内整个系统释放的总工作负载的上限，RHS是该时间间隔内总可用资源的下限。如果总工作负载不超过该时间间隔的总可用资源，则繁忙期必须结束，因此（10）的最小解限制了繁忙期长度的上限，因此αC（$\overline{Δ}$）限制了实例数量的上限。 C在繁忙时期发布。与(6)和(7)类似，我们可以用$\overline{sbf}$重写(10)并应用定点迭代技术来找到其最小正解。

最后，通过对 \[1, αC($\overline{Δ}$)] 中的每个 i 应用引理 11 并获取最大值，我们得到 C 的最坏情况响应时间的上限。

**定理 1** 任意链 C ∈ Γ 的最坏情况响应时间的上限为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405172328499.png)
# 六．优先级分配
在本节中，我们研究优先级分配如何影响链的响应时间。我们观察到，在分析链（引理 5）和干扰链（引理 6）的工作负载上限中，依赖于回调优先级的唯一因素是检查回调实例是否在与主链相同的处理窗口中执行。接收器回调实例 $C^i_{||C||}$所分析的链实例的优先级高于 $C^i_{||C||}$或不（由（2）中的ε和（5）中的ε′决定）。因此，<span style="background:#d3f8b6">定理 1 中的响应时间限制仅受分析链的接收器回调的优先级影响：优先级越高，响应时间限制可能越低，但与其他回调的相对优先级顺序无关。接下来，我们将证明上述属性不仅适用于我们的响应时间限制，而且适用于实际的系统行为。</span>

**引理13** 在每个处理窗口中，在不同优先级分配下执行的回调实例集是相同的。
证明：我们考虑系统的任意释放顺序，其中每个链实例的释放时间和每个回调实例的实际执行时间是固定的。每个繁忙时段的长度在不同优先级分配下不会改变，因此我们将注意力限制在任意繁忙时段。首先看这个繁忙期的第一个处理窗口pw1：pw1中只执行了pw1中释放的定时器回调实例，并且它们都在pw1结束时完成，因此在不同优先级分配下，pw1中执行的回调实例是相同的（同样，在pw1末尾的轮询点添加到就绪集Ω的就绪回调实例在不同优先级分配下是相同的）。接下来我们证明该引理也适用于这个繁忙时期的其他处理窗口。

我们通过反证法证明，假设在某些处理窗口中执行的回调实例在两个优先级分配 Φ 和 Φ′ 下是不同的。我们使用 pwn 和 pw′n 分别表示优先级分配 Φ 和 Φ′ 下所考虑的繁忙时段中的第 n 个处理窗口。

令 pwm 为第一个与其对应的 pw'm 有如此差异的处理窗口。我们假设 Czi 是最早（就释放时间而言）引起差异的回调实例，并且不失一般性，我们假设 Czi 在 pwm 中执行，而不是在 pw′m 中执行（相反的情况可以相同地证明）。我们首先证明 Czi 不是一个常规的回调实例。当且仅当满足以下条件时，常规回调实例 Czi 才会在 pwm 中执行：
- 其前身 $C^i_{z−1}$ 已在 pwm−1 结束时完成。 
- 同一回调 Cz 的所有先前实例均已在 pwm−1 结束时完成。

由于 pwm 是第一个处理窗口，其中执行的回调实例集与其对应的 pw′m 不同，因此 Czi−1 和 Cz 的所有先前实例在 pw′m−1 结束时已完成，因此 Czi 也在 pw 中执行'米。因此，Czi 不可能是常规回调实例，所以它必须是定时器回调实例（下面我们将 Czi 称为 Ctim）。我们将证明这也会导致矛盾。

我们使用 E* 和 E′* 分别表示在 pw1、···、pwm−1 和 pw′1、····、pw′m−1 中执行的累积工作负载。我们使用 z(t) 来表示从所考虑的繁忙时段的开始时间到时间 t 所累积的处理资源。由于 pwm 是第一个处理窗口，其中 Φ 下执行的回调实例集与 Φ′ 下的对应回调实例不同，因此我们知道 E* = E′*。

我们用ts表示pwm的启动时间，用tr表示Ctim的释放时间。我们用 E1 和 E′1 分别表示 pwm 和 pw′m 中执行的所有常规回调实例的总执行时间，用 E2 表示 \[ts, tr 中释放的所有定时器回调实例的总执行时间）。

我们声称 ζ(tr) < E* + E1 + E2。这是因为，否则，在优先级分配 Φ 下，所有就绪回调实例应该在 tr 之前完成，因此 pwm 应该在 tr 之前结束，因此 Ctim 无法在 pwm 中执行，这与我们的假设相矛盾。

现在我们将注意力转移到优先级分配Φ′下的执行。由于 Ctim 是 pwm 中最早执行的（就释放时间而言）定时器回调实例，而不是 pw′m 中执行的定时器回调实例，因此我们知道 \[ts, tr) 中释放的所有定时器回调实例的总工作量 E2 均在 结束前执行。 pw′m。正如我们上面讨论的，在 pwm 中执行的常规回调实例也必须在 pw′m 中执行，因此 E1 = E′1。因此，pw′m 中执行的总工作量至少为 E′1 + E2 = E1 + E2。并且由于 E* = E′ * ，从所考虑的繁忙周期开始到 pw′m 结束执行的总工作负载至少为 E* + E1 + E2。通过 ζ(tr) < E* + E1 + E2，我们知道应该在 pw′m 结束之前完成的总工作量 E* + E1 + E2 在 tr 时尚未完成。因此，tr 必须在 pw′m 结束之前。由于定时器回调实例是在其被释放的处理窗口中执行的，因此Ctim必须以pw′m执行，这与我们假设Ctim以pwm执行而不是pw′m执行相矛盾。

**定理 2** 链实例的响应时间仅受其接收器回调的优先级影响（优先级越高，响应时间可能越短），但不依赖于系统中其他回调的相对优先级顺序。

证明：我们考虑任意链实例 Ci 并令 pwu 为其接收器回调实例执行的处理窗口。链实例的响应时间由三部分组成：(i) 其释放时间与 pwu 启动时间之间的时间距离，(ii) pwu 启动时间与接收器回调实例启动时间之间的时间距离，以及 (iii) 接收器回调实例的执行时间。第 (iii) 部分显然与优先级分配无关。通过引理 13，我们知道第 (i) 部分与 pwu 之前执行的回调实例的优先级无关。 pwu 中回调实例的执行顺序取决于它们的优先级和 Ci ||C||是在 pwu 中执行的 Ci 的唯一回调实例。因此，第 (ii) 部分仅取决于 Ci 的优先级：优先级越高，它可能越早执行。系统中其他回调的相对优先级顺序不影响Ci ||C|| 的启动时间在pwu。

定理 2 表明，不仅从响应时间上限（对于硬实时系统）的角度来看，而且从实际最坏情况和平均响应时间（对于软实时系统）的角度来看，提高接收器回调的优先级总是有益的。 -时间和一般系统）。在ROS2中，回调的优先级由两个级别决定： (1)回调类型：不同的回调类型有不同的优先级。正如我们模型中所定义的，计时器回调比任何常规回调具有更高的优先级。实际上，常规回调又分为三种类型：订阅者、服务和客户端。总体来说，四种回调类型的优先级顺序为
定时器>订户>服务>客户端，
其中的意思是“具有比以下更高的优先级”。 (2) 注册顺序：同一类型的回调的优先级顺序取决于它们注册到执行器的顺序：越早注册，优先级越高。

由于上述优先级层次结构，并不总是可以将接收器回调的优先级提升到最高。尽管如此，开发人员可以通过尽早在同一类型的回调中注册接收器回调，从而在同一回调类型中授予它们尽可能高的优先级，这在实践中基本上是一种无成本的优化选项。还可以通过修改应用程序设计来执行更积极的优化。例如，由于三种常规回调类型主要在触发执行的方式上有所不同，因此在某些应用程序中，可以更改回调的类型（将接收器回调提升为更高优先级的类型，或将其他回调降级）。定期回调低优先级类型）。对需要修改应用程序的优化机会的获得和损失进行彻底调查超出了本文的范围，将在我们未来的工作中考虑。





***

# 笔记

## 1 论文创新在于

## 2 解决了什么问题

## 3 方法

## 4 不足&可继续研究

## 5 可参考

## 6 思考
