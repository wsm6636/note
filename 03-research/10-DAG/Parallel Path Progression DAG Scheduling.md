---
created: 2024-03-27T18:55
updated: 2024-05-15T10:56
tags:
  - 笔记
  - 笔记/文献笔记
status:
  - ing
---

**TitleTranslation:**  并行路径进展DAG调度
**Journal or Conference:**  IEEE Trans. Comput.  IEEE Transactions on Computers 
**Authors:**  NiklasUeter, MarioGünzel, Georg Von DerBrüggen, Jian-JiaChen
**Pub.date:**  2023-10
**DOI:**  10.1109/TC.2023.3280137     
**zoterolink:**  [zotero](zotero://select/library/items/X4I3VCIH)

# 摘要

现代网络物理系统不断增长的性能需求导致多处理器架构得到越来越多的利用。为了有效地利用硬实时系统中潜在的并行性，需要适当的任务模型和调度算法来提供时序保证。由于基于最坏情况假设的悲观分析，此类调度算法和相应的最坏情况响应时间分析通常会遭受资源过度配置的困扰。因此，需要具有高资源效率的调度算法和分析。一个著名的细粒度并行任务模型是有向无环图 (DAG) 任务模型，它由优先级约束的子作业组成。本文研究零星任意期限DAG任务的分层实时调度问题。我们提出了一种并行路径进展调度属性，该属性仅使用两个不同的子任务优先级来实现，这允许在响应时间分析中量化用户选择的完整路径集合的并行执行。这种新颖的方法显着改进了高度并行 DAG 结构的并行 DAG 任务的最先进的响应时间分析，并且可以证明耗尽大量核心。基于此特性设计了两种分层调度算法，扩展了并行路径进展特性并改进了零星任意期限 DAG 任务集的响应时间分析。


# 一、引言和动机

现代网络物理系统已经从单处理器系统转向多处理器系统，以应对热量和能量限制，以及日益复杂的应用程序和紧迫的期限限制的计算需求。值得注意的是，用于实时领域的多核架构中的可用核心数量已大大增加。具有 256 个内核的 Kalray MPPA 架构就是一个例子，这加剧了对能够利用可用内核潜力的方法的需求。这种架构转变对实时感知并行软件的设计方法、细粒度并行任务模型的规范和实现以及允许正式响应时间分析的适当调度算法的设计提出了多重挑战。

并行计算 OpenMP 和实时扩展 OmpSs [14] 的事实上的标准编程和调度模型正在使用分层调度。也就是说，在较高级别上，工作线程由操作系统调度，而在较低级别上，并行任务的子作业由负责将就绪子作业分派给可用工作线程的相应运行时环境管理。分层调度的具体实现尚未标准化，例如，OpenMP 和 OmpS 的方法不同之处在于，OpenMP 通过主线程实现 fork-join 并行性，主线程在遇到并行区域时创建所谓的并行线程组。相比之下，OmpSs 使用工作线程池在子作业准备好后立即为其提供服务，这类似于列表调度。在这两个框架中，应用程序源代码都是用高级编程语言编写的，该语言使用一组指令进行检测，与库例程和提供的运行时环境一起用于描述和执行并行应用程序。

我们认为，一方面并行应用程序设计和调度的解耦，另一方面实时操作系统调度和服务契约的解耦，由于时间隔离和简单集成，是实现实时并行软件的最有前途的方法使用所使用的实时操作系统的任何常用的调度算法，例如固定优先级的分区或全局调度变体或最早截止时间优先（EDF）调度算法。

<span style="color:black;background:#40a9ff !important;">分层调度方法的响应时间分析被分解为验证每个工作线程是否能够提供实时操作系统必须承诺的定义数量的服务的问题以及随后验证的问题每个 DAG 作业都可以在其期限限制内使用承诺的服务完成其工作负载。</span>

在DAG任务集的实时调度理论中，目标是有效地利用多处理器为具有任务间和任务内并行性的任务集提供的并行性，同时保证每个任务满足其截止日期。并行性可以分为任务间并行性和任务内并行性，任务间并行性是指不同任务的并行执行，每个任务顺序执行；任务内并行性是指单个任务的并行执行。任务内并行性需要具有可以并行调度的子任务级粒度的任务模型，例如Fork-join模型[25]、同步并行任务模型或基于DAG（有向无环图）的任务模型。已经提出了大量的实时调度算法及其响应时间分析，例如，针对广义并行任务模型 [33] 和基于 DAG（有向无环图）的任务模型 [3]、[5]、[13] ]、[16]、[17]、[19]、[28]、[42]。对于基于 DAG 的任务模型，响应时间分析的改进可以分为改善任务间干扰的分析，例如[13]、[16]，或任务内干扰的分析，例如[19]、[ 20]、[26]、[42]。一般来说，任务内干扰分析建立在包络执行过程中的干扰分析（也称为关键路径或关键路径）的基础上。直观上，包络路径是依赖于调度的子作业序列，其特性是所有包络路径子作业的到达和完成时间间隔是DAG作业的到达时间和完成时间间隔的划分。由于这些子作业包含 DAG 作业的执行，因此用于执行信封路径子作业的累积时间量以及信封路径子作业受到干扰的累积时间量限制了响应时间。

与最先进的技术相比，我们分析了沿着包络路径的多个用户选择的路径的同时进行，最多有多个处理器的数量。因此，我们只需考虑不属于任何用户选择的响应时间限制路径的子作业的干扰，从而能够将格雷厄姆的完工时间限制从一条路径推广到多条路径。这种改进是通过任务内优先级排序来实现的，即通过为用户选择的路径的所有子任务分配较低的优先级。由此，包络路径子作业的进展和来自用户选择的路径的子作业的进展可以在分析上彼此相关。据我们所知，这是第一篇提出并行路径进展概念1和相应的响应时间分析以及这些概念对分层调度的扩展的论文。

贡献：我们提供以下贡献：

- 基于第 III-A 节中提出的并行路径进展概念，我们在第 III-B 节中提出了一种<span style="color:black;background:#ff4d4f !important;">抢占式固定优先级调度算法，以及针对最多处理器数量的任意路径集合的可持续响应时间分析</span>。在第四节中，我们提供了<span style="color:black;background:#ff4d4f !important;">一种多项式时间算法，该算法要么找到完全覆盖 DAG 的路径集合（如果存在可用数量的处理器），要么找到具有可证明有界的最坏情况响应时间的近似值。</span>
- 我们将我们的研究结果扩展到第五节中的两种分层调度算法。即<span style="color:black;background:#ff4d4f !important;">第 V-A 节中的偶发任意截止日期团体预订系统和 V-B 节中的偶发任意截止日期普通预订系统</span>，它们利用了并行路径进展概念。分层调度算法可以应用于零星的任意期限 DAG 任务，这些任务可以与不同任务模型描述的任务（例如顺序任务）同时执行。
- 对于这两个预订系统，我们提供响应时间分析和算法来生成“可行”的预订系统，分别如第 V-A 和 V-B 节中所述。
- 在第六节中，我们使用综合生成的 DAG 任务集评估我们的方法，并证明我们的方法在高并行性场景中推进了最先进的技术，并表明我们的方法的性能介于起始-在更连续的场景中进行最先进的联合调度。

# 二.任务模型和问题描述
我们考虑一个集合 T := {τ1, . 。 。 , τn} 是在 M 个同构处理器上调度和执行的零星任意截止时间有向无环图 (DAG) 任务。每个任务 τi := (Gi, Di, Ti) ∈ T 由描述子任务和优先约束、最小到达时间 Ti 和相对截止时间 Di 的 DAG Gi 定义。每个任务都会释放无限序列的任务实例，称为作业。我们用 Ji 表示任务 τi 的第-个作业，用 ai 、 fi 和 di = ai + Di 表示作业 Ji 的到达时间、完成时间和（绝对）截止日期。

![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405091128296.png)


**DAG**：任务的 DAG Gi 由元组 (Vi, Ei) 定义，其中 Vi 表示子任务的有限集，关系 Ei ⊆ Vi × Vi 表示它们之间的优先级约束，因此不存在循环优先级约束。为了在数学上精确，每个作业 Jil 都与 DAG Gil 的一个实例相关联，该实例具有相应的第l个子作业 vjl，其中 vj 是 Vi 中的子任务。任务τi的第l个作业的子作业，即vjl (vj ∈ Vi)，在(vk, vj) ​​∈ Vi的所有第l个子作业vkl 执行完毕后被释放。为了减少这种表示法，我们在分析一项特定作业时删除任务和作业的索引。也就是说，我们用 G = (V, E) 和 vj ∈ V 来表示特定 DAG 作业的子作业。示例性 DAG 如图 1 所示。

**Volume**： <span style="color:#00b050 !important;">voli : Vi → R≥0 指定每个子任务 vj ∈ Vi 的最坏情况执行时间，</span>这意味着没有子作业（实例）vjl 在执行平台上执行的时间超过 voli(vj) 个时间单位，但是可能会更早完成。此外，子任务 W ⊆ Vi 的任意子集的体积为 vol(W ) := Σ vj∈W   voli(vj)。特别是，任务的总体积 τi 由 Ci := voli(Vi) 给出。

**发布和截止日期**：在实时系统中，任务必须满足时间要求，即每个作业 Jil 必须在作业到达 ail 和该作业在 ail + Di 的绝对截止日期之间完成其总量。如果每个作业都满足其截止日期，即，fil ≤ ail + Di 对于所有 l∈ N，则称任务 τi 满足其截止日期。我们考虑任意截止日期，这意味着我们不对截止日期和 inter 的关系做出任何假设-到达时间。例如，相对期限可能小于最小到达间隔时间 (Di ≤ Ti)，在这种情况下，只有前一个作业完成后才会释放新作业。或者，截止时间可以大于最小到达间隔时间（Di > Ti），在这种情况下，尽管先前的作业尚未完成，但仍可以发布新的作业。 τi 的任何两个后续作业的释放时间至少相隔 Ti 个时间单位，即，对于所有 ε N，a l+1,i ≥ ail + Ti。表 1 中提供了所用符号的摘要。


![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405091131463.png)

# 三．并行性和路径感知调度

DAG 任务的并行性本质上受到其组成的路径的限制，因为路径强制执行关联子作业的顺序执行顺序。在本文中，我们的目标是通过强制执行跟踪和保证 DAG 内路径集合并行进度的属性来减少任务内干扰，从而显着改善高并行用例的最坏情况响应时间。为此，我们回答以下问题：（Q1）跟踪和保证一组专用处理器上的并行路径进展所需的最小理论属性是什么？ （Q2）任何路径集合都可以用于并行进程吗？如果可以，什么是可证明的良好选择？ （Q3）如何扩展（Q1）和（Q2）的结果以考虑分层调度？

## A. 并行路径进展概念
在本小节中，我们将研究在专用于执行 DAG 任务的单个作业的 M 个处理器上实现并行路径进展所需的属性。这样，我们就避免了任何任务间干扰，只关注任务内干扰。

**定义 1（路径）**：对于 DAG G = (V, E) 的每个子任务 vj ∈ V，vj 的前驱集由 pred(vj) := {vi ∈ V | (vi, vj) ​​∈ E}。 vj 的后继集合分别由下式给出 和 succ(vj) := {vi ∈ V | (vj, vi) ∈ E}。路径是一组有序的子任务 π := 〈v1,...。 。 。 , vn> 使得 pred(v1) = ∅, succ(vn) = ∅ 且 vk ∈ pred(vk+1) 对于所有 k ∈ {1, . 。 。 ，n−1}。如果 pred(v1) = ∅ 或 succ(vn) = ∅ 则 π 在本文中不被视为路径。

**定义2（n路径集合）**：设一个DAG G = (V, E)，则所有可能路径的枚举表示为 Ψ(G) := {π | π 是 G 中的根据定义 1 的路径}。来自 ψ(G) 幂集的路径 ψ ∈ P(ψ(G)) 的任何子集称为路径集合。此外，如果 |ψ| = n，则路径集合 ψ ∈ P(ψ(G)) 被称为 n 路径集合。即 ψ 是 n 条路径的集合。
> 幂集，所有可能的合集，包括空集和本身
> ψ(G) 只包含所有可能的路径（路径1，路径2）
> P(ψ(G))包括空路径，路径1，路径2，路径1+路径2

在本文的其余部分中，我们将使用 π* 来表示 G 中的最长路径，即，对于所有 π ∈ Ψ(G)，vol(π*) ≥ vol(π)。事实上，<span style="color:black;background:#d3f8b6 !important;">可以并行执行的最大路径数量受到处理器数量 M 的限制。因此，我们将解决方案空间限制为 n 路径集合，其中 n ∈ {1, . 。 。 ，M}</span>。基于具体的 n 路径集合 ψ，对于每个 πψ1 。 。 。 , πψn ∈ ψ, 属于 ψ 中至少一条路径的子任务集由 Vs(ψ) := πψ1 ∪ · · · ∪ πψn 定义。请注意，我们使用下标来索引属于路径集合的路径。相反，不属于任何选定路径的子任务的补集由 Vsc(ψ) := {v ∈ V | v ∉ Vs(ψ)}。

我们提出了一种并行进度优先级，根据上述集合的成员资格为每个子任务赋予优先级，这在以下定义中得到了形式化。在本节后面，我们将解释如何通过在响应时间分析中明确考虑 ψ 中路径的并行执行，使用这种优先级来更好地分析自干扰。

**定义 3（并行路径进展优先级）**：令 Vs(ψ) 表示 DAG G = (V, E) 的 n 路径集合 ψ 中的子任务集。所有子任务 v ∈ V 的固定优先级策略是并行路径进展优先级当且仅当对于任意两个 vi ∈ Vs(ψ) 和 vk ∈ Vsc(ψ) ，Π(vi) < Π(vk)，其中 Π( vi) 表示子任务 vi 的优先级。
> 补集的优先级更高

请注意，在我们的<span style="color:black;background:#d3f8b6 !important;">优先级符号中，较高的值意味着较高的优先级，即 Π(vi) > Π(vk) 意味着 vi 比 vk 具有更高的优先级。</span>满足并行路径进展优先级属性的充分策略是仅使用两个不同的优先级级别。

我们在下面的例子中集中阐明引入的符号和定义。图 1 所示 DAG 的路径枚举 Ψ(G) 由 6 条路径 {π1, π2,…. 。 。 , π6}，即； π1 := 〈v1, v2, v3〉, π2 := 〈v1, v4, v5, v9〉, π3 := 〈v1, v4, v5, v6〉, π4 := 〈v1, v7, v5, v9〉, π5 := 〈v1, v7, v5, v6〉 和 π6 := 〈v1, v7, v8〉。来自幂集 P(Ψ(G)) 的 2 路径集合 ψ 例如由 ψ := {π2, π3} 给出。随后，Vs(ψ) = π2 ∪ π3 = {v1, v4, v5, v6, v9} 和 Vsc(ψ) := {v2, v3, v7, v8}。例如，如果所有子作业 vi ∈ Vs(ψ) 被分配优先级 Π(vi) = 1，相反，所有子作业 vi ∈ Vsc(ψ) 被分配优先级 Π(vi) = 2，则此优先级是有效的并行路径进度优先顺序。
> 看不懂

## B. 并行路径进展调度
在本小节中，我们将研究通过工作保存抢占列表调度算法结合并行路径进展优先级在 M 个专用处理器上调度的单个 DAG 作业。我们详细阐述了这种优先级如何帮助分析路径集合的并行进程，从而帮助分析 DAG 作业的响应时间。

**定义 4（List-FP）**：在 M 个专用处理器上的抢占式 list-FP 调度中，DAG 任务 G = (V, E) 的任务实例（作业），每个子作业 v ∈ V 的固定优先级分配为按照以下规则安排：
- 如果所有前面的子作业都已执行直至完成，则子作业到达就绪列表，即每个子作业 vi 的子作业到达时间 ai 由 max{fj | vj ∈ pred(vi)} 给出。 已到达但尚未完成的子作业被视为待处理。
- 在任何时间 t，M 个最高优先级的挂起子作业将在 M 个处理器上执行，并且如果需要，较低优先级的子作业将被抢占。
首先，我们引入并形式化调度包络的概念，它是一系列子作业，其属性是所有包络路径子作业的到达和完成时间间隔，是 DAG 的到达时间和完成时间间隔的划分工作。

**定义 5（包络）**：令 S 为某个 DAG 任务 G = (V, E) 的给定 DAG 作业的子作业 V = {v1, . 。 。, vl }的任何具体调度。令每个子作业 vk ∈ V 在 S 中具有到达时间 ak 和结束时间 fk。我们将 G 在 S 中的包络定义为到达和结束时间间隔的集合 \[ak1 , fk1 ), \[ak2 , fk2 ) , . 。 。 , \[akp , fkp ) 对于某些 p ∈ {1, . 。 。 ,l } 向后迭代如下： 
1) ki = kj ∈ {1, . 。 。 , l} 对于所有 i = j。 
2) vkp 是V 中完成时间最长的子作业。 
3) vki−1 是 vki 之前具有最大完成时间的子作业，对于所有 i ∈ {p, p − 1,...。 。 。 , 2}。 
4) vk1 是源节点，即没有前驱节点。

我们称 πe := {vk1 , vk2 , . 。 。 , vkp } 包络路径。我们注意到，如果存在具有相同完成时间的子作业，则 DAG 作业的包络定义可能不唯一。在这种情况下，关系可以任意断开。

在本小节的剩余部分中，我们使用之前介绍的所有属性来分析单个 DAG 作业的响应时间。为单个作业 J 生成 M 个专用处理器上的固定优先级列表调度 S，其中所有子作业都根据定义 3 中描述的规则确定优先级。对于响应时间分析，我们分析之间的时间间隔 \[aJ , fJ )将J的到达时间和结束时间按区间划分为繁忙时间和非繁忙时间。如果在时间 t 在 S 中执行包络子作业，则任何时间点 t ∈ \[aJ , fJ ) 都称为忙。相反，如果包络子作业未执行，则任何时间点 t ∈\[aJ , fJ ) 称为非忙。通过根据定义 5 构建包络，必须在任何时间点 t ∈ \[aJ , fJ ) 信封子作业处于待处理状态，即已到达但尚未完成。结合 t 可以完全忙或不忙这一简单事实，我们知道 DAG 作业 J 的响应时间由在这两种状态中的任何一个状态下花费的累积时间量给出。

与之前的工作相比，我们将非繁忙时间进一步划分为并行路径（如果包络子作业 vki ∈ Vs(ψ)）和非并行路径时间（如果 vki ∈ Vsc(ψ)），假设包络路径 πe := 〈vk1 , vk2 , . 。 。 , vkp 〉 在S。这种方法的直觉是将包络子作业的执行与路径集合 ψ 的子作业的执行联系起来，这将在接下来的分析中使用和解释。

**定理 6（抢先响应时间限制）**：具有任意 n 路径集合的 DAG 作业 J 的响应时间 ψ = {πψ1 , . 。 。 , πψn } ∈P(Ψ(G)) （n  最多为M ）使用抢占式 List-FP 调度在 M 个专用同构处理器上调度，其边界为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405091452597.png)

证明：根据包络的定义（参见定义 5），我们知道在具体的抢占式列表-FP 调度 S 中，DAG 作业到达到完成时间的间隔 \[aJ , fJ ) 可以被划分成连续的区间 \[ak1 , fk1 = ak2 ), . 。 。 , \[fkn−1 = akn , fkn ) 其中 \[aki , fki )​​ 表示所有 i ∈ {1, .  。 。 , p}的子作业 vki 的到达和完成时间, 在包络线 πe := {vk1 , vk2 , . 。 。 ，vkp}。

**繁忙时间**：单独考虑每个包络子作业间隔 \[aki , fki )​​ 对于 i ∈ {1, . 。 。 , p}，繁忙时间量由 vki 的执行时间给出，根据定义，该执行时间不超过 vol(vki )。 \[aJ , fJ ) 中的累积繁忙时间量可以通过将间隔的各个繁忙时间相加而获得，即 vol(πe)，其不超过最长路径 vol(π*)。

**非繁忙时间**：由于我们的调度策略是节省工作的，因此每当包络子作业 vki 在 \[aki , fki )​​ 期间不执行时，所有 M 个处理器都必须忙于执行非包络子作业。由于 vki 可以排他地存在于 Vs(ψ) 或 Vsc(ψ) 中，因此我们分析集合 {t ∈ \[aJ , fJ ) |包络子作业未执行} ∩ \[aki , fki )​​ 对于两种情况分别：
- **并行路径**：令 vki ∈ Vs(ψ) 并假设在时间 t 不执行，则最多 n − 1 个处理器执行 Vs(ψ) 中的子作业。这是因为 Vs(ψ) 中的所有子作业都源自 n 个不同的路径，这意味着一般情况下，Vs(ψ) 中同时待处理的子作业永远不会超过 n 个。此外，由于假设 vki ∈ Vs(ψ) 并且在 t 时不执行，因此 Vs(ψ) 中的最多 n − 1 个子作业处于待处理状态。相反，我们知道至少有 M − (n − 1) 个处理器执行 Vsc(ψ) 中的子作业，否则 vki 的执行将会与案例假设相矛盾。
- **非并行路径**：在另一种情况下，令 vki ∈ Vsc(ψ) 并假设在时间 t 未执行，则必定没有处理器正在执行 Vs(ψ) 中的任何子作业。这是因为，如果 Vs(ψ) 中的任何较低优先级子作业将被执行，则较高优先级的包络子作业 vki ∈ Vsc(ψ) 也将被执行，这与案例假设相矛盾。相反，我们知道所有 M 个处理器都专门用于执行 Vsc(ψ) 的子作业。
总之，我们知道在所有非繁忙时间 t ∈ \[aJ , fJ ) 中，至少有 M − (n − 1) 个处理器执行 Vsc(ψ) 的子作业。 \[aJ , fJ ) 期间来自 Vsc(ψ) 的子作业总量最多为 vol(Vsc(ψ))。非繁忙时间的最大累积量是通过平均分配工作量来实现的，因此不超过vol(Vsc(ψ))/(M − (n − 1))。

我们的响应时间分析的可持续性：<span style="color:black;background:#fff88f !important;">文献中提出的许多多处理器硬实时调度算法和可调度性分析都是不可持续的，这意味着它们会出现时序异常。</span>这些异常描述了一种反直觉的现象，即被验证始终满足其截止日期的作业可能会通过增加资源而错过其截止日期，例如，在更多处理器上执行作业或减少执行时间（提前完成）。在推论 7 中，我们表明我们的响应时间限制在处理器数量和子作业执行时间方面是可持续的。在可用处理器和执行时间各不相同的动态环境中，这是一个有益的特性，并最终简化了实际系统中的实现工作。

**推论 7（可持续性）**：定理 6 中的响应时间界限对于 G = (V, E) 的 DAG 作业成立，即使任何子作业 v ∈ V 在其最坏情况执行时间之前完成或者处理器数量增加。

证明：这直接来自于包络路径 vol(πe) 的体积以及并行路径非繁忙和非并行路径非繁忙间隔的长度只有在最坏情况执行时间为任何子作业减少或处理器数量增加。由于响应时间的上限是执行包络作业的次数和不执行包络作业的次数之和，因此证明了推论。
## A. DAG 顶点覆盖
寻找最少数量的顶点不相交路径（使得图 G 的所有顶点都被覆盖）的一般问题是一个 NP 完全问题，可以通过简化为 HAMILTONIANCYCLE 问题来证明。然而，对于有向图 G，Gallai 和 Milgram 在 1960 年表明，覆盖有向图 G 的所有顶点的顶点不相交路径的最小数量不超过 G 的最大独立集的大小，概括了结果来自 Dilworth [11] 和 König-Egevary [10]。

在有向图也是非循环的情况下，即 DAG，则可以通过已知的二分图中最大匹配问题的简化，在多项式时间内计算 G 的最大独立集，例如，Hopcroft-Karp算法。

例如，覆盖图 1 所示 DAG 的顶点不相交路径集由下式给出： U = {<v1, v2, v3>, <v4, v5, v6>, <v7, v8>, \<v9> }，其计算方法如上所述。在我们提出的路径收集算法中，我们需要完全覆盖 G 的从源顶点到汇顶点的路径集合，这些路径不一定是顶点不相交的。因此，我们在这里解释了我们提出的算法 1 第 1 行所要求的显式算法构造，以获得覆盖 G 的 w ∈ N 多条路径。请注意，对于我们的算法，知道数值 w 就足够了，而无需知道显式的路径。然而，为了证明存在性，我们显式地构造了 w 条路径。

对于每个 i∈ {1, . . . , |U |}，我们用顶点不相交路径 ui = 〈ui1 , . . . , uin 〉 ∈ U ,初始化第 i 条路径 πi，并连续应用以下步骤，直到所有 πi 都是根据定义 1 的路径：
- 如果 πi 中最左边的顶点不是 G 的源顶点，则针对某个 z∈ {1, . . . , m} 选择任意 uh = 〈uh1 , . . . , uhm 〉 ∈ U 使得 E 中的 <vuhz , vui1 > 并将路径延伸到πi = 〈uh1 , . . . , uhz 〉 ◦ πi 。
- 如果 πi 中最右边的顶点不是 G 的汇顶点，则选择任何元组 uh = 〈uh1 , . . . , uhm 〉 使得 E 中对于某个 z∈ {1, . . . , m}  存在 <vuin , vuhz > 并将路径更新为 πi = 〈uh1 , . . . , uhz 〉 ◦ πi 

例如，参考所提供的示例，我们从 u4 = (9) 开始，其中 π4 = 〈v9〉（它是 G 中的一个汇点）并识别元组 u2 = (4, 5, 6)，因为 (v5, v9) ∈E 并且路径更新为 π4 = 〈v4, v5, v9〉。由于 v4 不是 G 中的源顶点，我们继续并由于 (v1, v4) ∈ E 识别 u1 = (1, 2, 3) 并更新 π4 = 〈v1, v4, v5, v9〉。由于 v1 是源顶点，因此过程终止。重复该过程产生四个简单路径 π1 = 〈v1, v2, v3〉, π2 = 〈v1, v7, v8〉, π3 = 〈v1, v4, v5, v6〉, π4 = 〈v1, v4, v5, v9>，共同覆盖所有顶点 v ∈ V 。请注意，虽然在此示例中，w = 4 是覆盖 G 的最小路径数，但该算法通常仅提供安全上限。

# B. 加权最大覆盖范围
另一个相关算法是加权最大覆盖率[31]问题。下面，我们将寻找 DAG G 最大化 vol(Vs(ψ))（最小化 vol(Vsc(ψ))）的 n 路径集合 ψ 的问题映射到该问题，如下所示：
- 输入：加权最大覆盖问题的问题实例 I 由集合 S := {S1, . 。 。 , Sm}、权重函数 ω 和自然数 k。每个集合 Si ⊆ U 都是某个总体 U 的子集，其中每个 i ∈ {1, . 。 。 , m} 并且每个元素 s ∈ Si 都与函数 ω(s) 给出的权重相关联。
- 目标：对于给定的问题实例 I，目标是找到一个子集 S′ ⊆ S 使得 |S′| ≤ k 且 Σ s∈{∪{Si∈S′}} w(s) 最大化。
Nemhauser 等人证明了这一点。 [31] 加权最大覆盖问题的任何多项式时间逼近算法相对于下界为 1 − 1/e 的最优解具有渐近逼近比，除非 P = N P ，其中 e 是欧拉数。这种近似比率可以通过贪婪策略来实现，该策略总是选择包含尚未选择的元素的最大权重的集合。尽管加权最大覆盖率和我们的问题并不等价，但我们对算法 1 中的 n 路径集合近似使用相同的近似策略。

## C. 近似算法
基于大小为w的路径集合的存在性，可以分析算法1的逼近质量。我们首先提出我们提出的算法，然后证明逼近因子。
n 路径集合近似算法：从算法 1 中的第 1 行到第 3 行，计算完全覆盖 的最小路径数的上限 w。如果处理器的数量 M 足以允许所有 w 条路径的并行执行，即 w ≤ M，则选择这些路径作为路径集合。

在另一种情况下，从第 4 行到第 17 行，在每次迭代中 n ∈ {1,... 。 。 , M }，选择相对于当前迭代的体积函数 vol' 的最长路径 π\*n。选择路径后，该路径的子作业的所有体积都设置为0，表示子作业已被覆盖。通过这种策略，我们总是选择每次迭代中包含最大数量的尚未选择的子作业的路径。此外，在每次第 n 次迭代中，在第 14 行中探测解 ψn 是否严格改进先验解 ψn−1 少一条路径。在第 M 次迭代结束时，发现一个 n* 路径集合 ψ*，它产生如定理 8 中所述的形式保证。使用 Hopcroft-Karp 算法可以在 O(|V |) 中获得最大二分匹配。 nPCA 的时间复杂度主要由 for 循环和第 9 行中每次迭代中调用的深度优先搜索 (DFS) 决定，导致时间复杂度为 O(M · |V ||E|)

![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405091620847.png)
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405091648684.png)
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405091648305.png)


**定理 8 (nPCA)**：使用并行路径级数调度且根据算法 1 计算 n* 多路径的 DAG 作业 J (makespan) 在 M 个专用处理器上的<span style="color:black;background:#d3f8b6 !important;">最坏情况响应时间最多为</span>
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101015404.png)
其中 w 指的是 PATHCOVERAGE 的解。
> 能覆盖所有节点的最小路径数
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101507847.png)

证明：我们分别针对 M ≥ w 和 M < w 的情况证明该定理。
情况 1：在第一种情况下，即从第 1 行到第 3 行，令 M ≥ w。从第 IV-A 节的讨论中，我们知道 DAG G = (V, E) 的每个顶点 v ∈ V 至少被 PATHCOVERAGE 算法计算出的 w 条路径中的一条覆盖，这些路径在 PATHCOVERAGE 算法中返回第 3 行。因此，响应时间界限由下式给出
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101029489.png)
它的上限是最佳响应时间，因为 G 中的最长路径是任何 DAG 作业响应时间的下限。

情况 2：请注意，从 PATHCOVERAGE 获得的 w 不是最小解，而是它的上限。也就是说，在w>M≥n≥1的约束下，可能存在n条路径，使得可以覆盖DAG总体积C。然而，尚不知道这样的最小解是否可以在多项式时间内计算。然而，我们可以证明最佳响应时间相对于该上限的近似比率。

步骤 1：我们通过反证法证明，对于每次迭代 n ∈ {1, . 。 。 , M } 以下不等式成立
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101036780.png)
其中 ψ0 := ∅ 且 vol(Vs(ψ0)) = 0。为了使证明更加清晰，我们在第 n 次迭代中使用 vol(n) 来指代 vol′。假设矛盾存在迭代 n ∈ {1, . 。 。 , M } 这样
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101039712.png)
成立。那么它必须特别指出
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101039271.png)
其中 - - 通过算法策略选择- π\*n，使得对于所有路径 π ∈ Ψ(G)，满足不等式 vol(n)(π\*n) ≥ vol(n)(π)。因此，对于任意 w 条路径的集合，w·vol(n)(π\*n) ≥ vol(n)(∪w,i=1  πi)。因此，如果 (6) 成立，那么
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101042990.png)
也成立。根据算法不难看出
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101043960.png)
成立，因为如果第 n 次迭代中顶点的体积与初始体积不同，则该顶点必须被先前迭代期间收集的任何路径覆盖，即 Vs(ψn−1)。然后，在 (7) 中使用 (8) 的恒等式，得出 (5) 对于任意 w 条路径的任意集合，得出条件 vol(∪w,i=1  πi) < C，这与 w 条解的存在性相矛盾路径。

步骤 2：在第二步中，我们现在通过归纳法断言并证明
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101044348.png)
对于 n = 1，(9) 简化为 w · vol(Vs(ψ1)) ≥ C，这成立，因为我们知道存在有限 w，使得 vol(πψ1 ∪ · · · ∪ πψw ) = C ≤ Σ w i=1 vol(πψi ) ≤ w · vol(Vs(ψ1)) = w · vol(π*)，因为 ψ1 只包含 G 中的最长路径。在归纳步骤 n → n + 1 中，我们有
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101057969.png)
使用（4），我们得出结论：
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101057412.png)
结论：使用（9）得出，在nPCA第n次迭代之后，使用计算的n路径集合ψn的最大响应时间至多为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101057157.png)
由于 Ropt ≥ max{vol(π*), C/M } 以及 nPCA 在第 17 行使用 (14) 返回的最小响应时间解 (ψ*, n*)，我们有：
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101058964.png)
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101058912.png)
请注意，(15) 是由于在约束 (M ≥ n ≥ 1) 下，函数 M/(M − n + 1) 在 n ≥ 1 时相对于 M 严格递减。约束下，最小可行 M 由 n 向下限制，因此不超过 n/(n − n + 1) = n。
此外，我们还有基于算法生成的结果 w 和 n* 的参数界限，即
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101108564.png)
最后，我们有 RJ ≤ Eq.(17) ≤ Eq.(16) 得出证明。

# 五、分级调度
我们使用分层调度方法将并行路径进展的属性扩展到具有任务间干扰的系统。即，将调度问题分为不同的调度级别。在最低级别，预订系统（或线程）通过符合预订系统模型的某种调度策略在物理处理器上进行调度。在更高的层面上，工作负载（即 DAG 作业的子作业）是通过在时间和空间上隔离的环境中的预留来执行的。隔离属性允许分析每个 DAG 作业的响应时间，而不会出现任务间干扰。最重要的是，预订系统可以使用现有的响应时间分析与同一组物理处理器上的其他任务共同调度。

我们提出并讨论了两种预订方案，即第V-A节中的群组预订系统和第V-B节中的普通预订系统，并提供了资源供应规则和响应时间分析。分层调度问题由两个相互关联的问题组成：
- <span style="color:black;background:#ff4d4f !important;">各个组预留或普通预留系统的服务供应，以便 DAG 作业可以在所提供的服务内完成。</span>
- <span style="color:black;background:#ff4d4f !important;">通过支持各自任务模型的任何现有分析来验证所提供的预订系统的可调度性，</span>例如，零星的任意截止日期的组任务或零星的任意截止日期的普通顺序任务。
对于本节的其余部分，我们假设所研究的预订系统模型在 M 个相同的多处理器上存在可行的调度，并重点关注服务提供问题。我们<span style="color:black;background:#d3f8b6 !important;">假设预订系统满足以下四个属性，无论具体的预订模型如何。</span>

**属性1（并行服务）**：预订系统释放m个并行预订，使得在预订系统承诺服务期间的每次，最多m个预订可以同时提供服务。
**属性 2（服务关联）**：预订系统的一个实例恰好服务于 DAG 任务的一个 DAG 作业。这意味着为 DAG 任务 τi 的第一个作业 Ji 提供服务的 m 个并行预留实例均在时间 ai 同步到达，并且截止时间由 di 给出。请注意，如果下一个 DAG 作业在前一个 DAG 作业完成之前到达，则会释放新的预留实例（作业）。这允许直接处理任意期限而无需进一步考虑。
**属性3（持续服务）**：只要预约系统安排好时间，就提供预约服务，无论当时待服务的待处理子作业数量是否不足。
**属性 4（内部调度）**：预订系统对 DAG 作业 G = (V, E) 的每个子作业 v ∈ V 的内部调度，对 m 个预留进行并行路径进展优先级遵循定义 4 中的 List-FP，其中只有一个区别：在任何时间 t，令 m(t) 表示同时调度的预留，然后在预留上执行 m(t) 个最高优先级的挂起子作业，并在必要时抢占较低优先级的子作业。

**回收**：在正式的响应时间分析中需要上述属性，这是悲观的，因为每当计划保留但无法分派子作业时，处理器有时可能会旋转而不执行任何工作负载。可以通过将任何软实时 DAG 作业或正常顺序作业附加到优先级低于要服务的 DAG 作业的预留来使用回收机制。唯一必需的属性是，只要子作业待处理且提供了服务，所提供的 DAG 作业就可以声明该服务。

## A. 组预约系统
在组调度中，一组线程被分组为所谓的组，并具有附加约束，即组中的所有线程必须同时在可用处理器上共同调度。事实证明，基于组的并行计算通常可以提高性能[15]、[21]、[41]。由于其性能优势，组 模型受到许多并行计算标准的支持，例如 MPI、OpenMP、Open ACC 或 GPU 计算。受我们的方法和组执行模型中并行路径进展的实际好处和概念契合的启发，我们提出了如下的移动组预订系统。

**定义 9（m-Gang 预订系统）**：服务于零星任意期限 DAG 任务 τi := (Gi, Di, Ti) 的零星任意期限 mi-gang 预订系统 G 由元组 Gi := (mi ，Ei，Di，Ti），使得在到达和截止时间间隔内提供mi · Ei 服务，并具有所有预订必须同时共同调度的组调度约束。

因此，DAG 任务 τi 的 Gi 的供应问题是找到 mi 和 Ei，使得给定属性 1-4 和组调度约束，每个 DAG 作业可以在其绝对截止日期之前在 mi 预留之一内完成。

**定理 10（组预留供应）**：零星任意截止日期 DAG 任务 τi := (Gi, Di, Ti) 的每个作业 Ji 可以在大小为 Ei 的 mi 个并行预留的相应群预留实例内完成其总容量 Ci其绝对期限如果
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101215458.png)
对于至多mi的任何n路径集合ψ成立，并且<span style="color:black;background:#d3f8b6 !important;">组预订系统Gi被验证是可调度的</span>，即能够在绝对期限之前提供所有服务。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101504064.png)

证明：由于在一个 mi-gang 中，所有预订同时提供服务，因此任务 τi 的任何 DAG 作业 J 的到达和完成时间窗口 [aJ , fJ ] 可以分为繁忙、非繁忙和非服务区间，其中mi-gang 预订均未安排，因此不提供任何服务。与之前的证明类似，响应时间不超过这些集合的累积长度，其中假设mi-gang 是可调度的，非服务时间的累积长度的上限为 Di − Ei。因此，如果 (18) 成立，则
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101218208.png)
这就得出了证明。

![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101218536.png)

**组预订配置**：为特定群组预订系统找到最佳配置取决于当前的具体可调度性问题以及要共同调度的其他任务。因此，在某些具体情况下，用减少的预算来换取增加的组规模可能是有益的。然而，确定此类具体规定超出了本工作的范围。相反，在更通用的优化尝试中，我们寻求找到一种配置，<span style="color:black;background:#d3f8b6 !important;">最大限度地减少未使用的组服务（浪费），这被描述为 mi · Ei − Ci。</span>由于组限制，将保留数量 mi 增加到超过将要在其上执行保留的处理器数量 M 是不可能的。此外，将 组 大小增加到超过为 DAG 确定的 w 值只会增加浪费，因为 w 描述了最大固有并行性。由于 mi ∈ {1, . 。 。 。 , min{w, M }} 的搜索空间受到限制，可以应用穷举搜索来查找 mi, Ei 的值，其中 Ei ≤ Di 和 ψ, n 近似最小化目标
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101235130.png)
如算法2所示。为了说明该算法，计算了图1中具有最长路径体积10、总体积18、相对期限16和M=3的DAG的示例性结果。由于 DAG 的边界 w 为 4，因此只有 mi ∈ {1, 2, 3} 的团伙大小才是可行的候选者。该算法返回 2-gang，其 2 -路径集合 Vs(ψ) = {v1, v7, v5, v6, v2, v3} 产生的预留预算为 10 + (18 − 14)/(2 − 2 + 1) = 14 ≤ 16，浪费 2 · 14 − 18 = 10。图 2 显示了此配置的 2 组系统的示例性调度以及使用组预留的内部 DAG 作业调度。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101237052.png)

## B. 普通预订系统
<span style="color:black;background:#fff88f !important;">尽管组调度有实际好处，但与没有此类约束的等效普通预订系统相比，由于协同调度约束而导致的分析可调度性降低了。</span>

**定义 11（m-普通预订系统）**：服务于偶发任意截止日期 DAG 任务 τi := (Gi, Di, Ti) 的偶发任意截止日期 mi-普通预订系统 O 由元组 Oi := (mi , Ei1, ., Eimi , Di, Ti) 使得在到达和截止时间间隔内提供 Σmi ,p=1  Ep i 服务。

**定理 12（普通预留供应）**：零星任意截止日期 DAG 任务 τi := (Gi, Di, Ti) 的每个作业 Ji 可以在其绝对截止日期之前在其各自的普通预留实例 Oi 内完成其总数量 Ci，如果首先
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101250383.png)
对于任何 n 路径集合 ψ 都成立，其中 n 至多为 mi 和 all；其次，<span style="color:black;background:#d3f8b6 !important;">验证普通预订系统Oi是可调度的</span>，即每个单独的预订都能够在绝对期限之前提供所有服务。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101513664.png)

证明：令 S 为 mi 个可行调度的普通预订的时间表。也就是说，每个单独的预留都保证在区间 \[aJ , aJ + Di) 内为 DAG 作业 J := Ji 提供 Ep i 服务，其中 p ∈ {1,...。 。 。 ，mi}。设 ψ 表示 n 路径集合，Vs(ψ) 表示相应的子作业集。令 mi(t) ∈ {0, 1, . 。 。 , mi} 在时间 t 提供服务的预订数量，令 h(t) ∈ {0, . 。 。 , mi(t)} 在时间 t 为 Vsc(ψ) 中的子作业提供服务的预订数量。我们通过反证法证明这个定理，即我们假设 DAG 作业 J 错过了截止日期，并证明这导致违反（21）。令 J 在 S 中的时间 dJ := aJ + Di 处错过其截止日期，并令 vkp 表示在时间 dJ 正在执行且尚未完成的子作业。请注意，必须至少存在一个这样的子作业，否则总体积就完成了，这与错过最后期限的假设相矛盾。

使用定义 5 中的包络构造规则，不完整的包络路径 πe := {vk1 , vk2 , ... 。 。 。 , vkp } 是从子作业 vkp 开始派生的。我们将区间 \[aJ , dJ ) 划分为连续的子区间 Iki ，即 \[ak1 , fk1 ), \[ak2 , fk2 ), 。 。 。 , \[akp , dJ ) 对于每个不完整的包络子作业。此外，我们将每个子作业间隔划分为繁忙时间，定义为 αki := {t ∈ Iki | vki 被执行}，非繁忙时间定义为 βki := {t ∈ Iki |vki 不被执行}  对于每个 i ∈ {1,...，p}。请注意，在我们的划分中，无服务的情况，即mi(t) = 0被认为是非繁忙时间。

为了测量在任一状态下花费的累积时间，我们定义
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101427739.png)
其中 [pred] 表示艾弗森括号，如果谓词为真，则计算结果为 1，否则计算结果为 0。每个时间点 t ∈ [aJ , dJ ] 要么是繁忙时间，要么是非繁忙时间，并且由于假设 J 错过了最后期限，我们有
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101429332.png)
我们分别分析繁忙时间和非繁忙时间的数量如下。
繁忙时间：每个间隔 Iki 内的累计繁忙时间量由 |αki | ≤ vol(vki ) 给出。 对于 i ∈ {1, . 。 。 , p − 1} 和 |αkp | < vol(vkp ) 因为子作业 vkp 根据定义尚未完成执行。综上所述，Iki期间的累计繁忙时间由下式给出：
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101434342.png)

非繁忙时间：如果不完全包络子作业 vki ∈ Vs(ψ)，我们进一步将非繁忙间隔划分为并行路径情况，如果 vki ∈ Vsc(ψ)，则将划分为非并行路径情况。由于我们的调度策略是工作节约型的，因此每当包络子作业 vki 在时间 t ∈ Iki 未得到服务时，所有 mi(t) 预留都必须为非包络作业提供服务（或者根本没有可用的服务）。

非并行路径：假设 vki ∈ Vsc(ψ)，则对于任何时间 t ∈ βki，每个 mi(t) 预留要么专门为 Vsc(ψ) \\vki 的子作业提供服务（要么不提供任何服务）。这是因为 Vs(ψ) 子作业的优先级低于 Vsc(ψ) 子作业，因此对 Vs(ψ) 子作业的服务意味着对所有待处理的 Vsc(ψ) 子作业的服务，这与假设未处理的 vki ∈ Vsc(ψ) 未被服务。根据这个含义，我们有 βki ⊆ {t ∈ Iki | h(t) = mi(t)} 因而 |βki |可以被过度近似为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101444206.png)
我们引入辅助函数 m'i(t) = mi − mi(t) 来形式化时间 t 的非服务，从而产生
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101444278.png)
每个满足谓词的 t ∈ Iki 也满足 (h(t) + m'i(t))/mi = 1。此外，根据定义h(t) + m' i(t) ≥ 0，对于任何 t ∈ Iki (无论谓词是否满足），我们进一步将 βki 的长度近似为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101447132.png)
并行路径：通过假设，让不完整的包络子作业 vki ∈ Vs(ψ) 在时间 t ∈ Iki 不被任何 mi(t) 服务。我们使用 n(t) ∈ {1, . 。 。 , n} 表示 t 时刻 Vs(ψ) 中待处理的子作业数量。通过案例假设，我们知道对于每个 t ∈ βki 至多 n(t) − 1 个来自 Vs(ψ) 的子作业在时间 t 由 mi(t) 预留服务。此外，我们知道待处理的 Vsc(ψ) 子作业优先于 Vs(ψ) 子作业，即
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101448052.png)
根据这个含义，我们有 βki ⊆ {t ∈ Iki | h(t) ≥ mi(t) − (n − 1)} 因此
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101448091.png)
使用 m'i(t) = mi − mi(t) 得出不等式 h(t) + m'i(t) ≥ mi − (n − 1)。与前一种情况相同的推理，长度可以近似为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101449306.png)
总之我们有
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101451049.png)
并且由于 (31) ≥  (27)，我们得出的结论是
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101451818.png)
根据定义，∫dJ,aJ  h(t) dt ≤ vol(Vsc(ψ)) 成立，因此
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101456412.png)

DAG 任务 τi 的作业预订系统的合约承诺在 DAG 作业 J 的到达时间及其截止时间  \[aJ , dJ )期间提供 (Ei1, 。 。 。 Eimi) 服务。因此，每个 mi 个单独预订在 p ∈ {1,... mi}时间内最多不为 Di − Epi 提供服务，这意味着
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101457971.png)
综上所述，参考 (24)，我们发现 J 的最后期限错过意味着：
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101457564.png)
这就证明了定理。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101518838.png)
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101542792.png)

**普通预留供应算法**：与组预留供应问题类似，用单个预留大小交换预留数量可能有利于具体任务集的可调度性。同样，为了提供一个可以针对具体应用场景进一步细化的基准解决方案，我们寻找在相等预算 Ep,i = Ep+1, i对于 p ∈ {1,…mi − 1} 且 Ei1 ≤ Di的约束下最小化累积分配服务的预订系统，如算法 3 中所述。关键直觉是：首先，并行预留的数量 mi 受到可用处理器数量 M 的最小值和所服务的 DAG w 的限制，其次，累积分配的服务只能随着 mi 的增加而增加。因此，在第一阶段，我们将 mi 设置为可达到的最小值，即在 mi ≥ n 约束下的 n，从而导致不等式
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101523090.png)
作为优化的对象。在算法 3 中，我们计算路径覆盖和边界 w 并应用于每个 n ∈ {1,…。 。 。 , min{w, M }} 迭代 nPCA 原理，通过分析第 n 次迭代中是否存在以下改进条件来搜索最小化服务的配置
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101531748.png)
成立，简化为 vol(Vs(ψn)) − vol(Vs(ψn−1)) > Di。如果计算出的 n* < w 导致违反最后期限约束，即 Ei* > Di，我们迭代 mi ∈ {n*, 。 。 。 , M } 直到截止日期之前并返回相应的解决方案。如果 n* = w，则只有当 vol(π*) > Di 成立时，即 DAG 默认情况下不可调度时，才会违反截止日期约束。

讨论：与 gang 预订系统相比，由于附加的 (n − 1) · Di 项，增加普通预订系统中路径集合的大小可能没有好处。为了能够改进单个路径集合，必须满足以下条件
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101533371.png)
这简化为
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101533002.png)
虽然左侧的增量始终为 Di − vol(π*)，但右侧的增量正在递减（在 nPCA 下）。因此，如果 n = 2 没有产生改进，那么任何 w > n > 2 也不会产生改进。一般来说，为了使 n 路径集合比单路径集合和相应的预留系统有所改进，必须满足以下条件
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101534335.png)
其中 vol' 指的是 nPCA 中基于迭代的体积函数。可以观察到，非常紧迫的期限，即 D ≈ vol(π*) 和具有很少重叠路径的 DAG 结构从这种方法中受益最多。在这方面，以下示例中使用的 DAG 并未受益于并行路径概念，而仅用于说明预留原则。请注意，由于算法 3 中计算出的累积分配服务不超过单路径预留系统的累积分配服务，因此任意期限普通分区和全局 EDF 调度下的加速因子为 3 + 2√2 。Ueter 等人展示了关于任何最佳调度程序的预订系统。 [38]仍然适用。

![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101538096.png)

示例：图 3 中示出了使用图 1 中所示的 DAG 的 3 路径集合（截止时间为 16）的示例性 4-普通预留系统。在该示例中，每个预留的大小相等，这导致 Ep i = 13.5对于 p ∈ {1, . 。 。 , 4} 根据（21），Di = 16，n = 3，mi = 4，vol(Vsc(ψ)) = 4。请注意，只要在到达和截止时间间隔内提供承诺的服务，服务可以根据具体时间表任意提供。
> 没看懂

# 六．评估
在即将到来的评估中，我们使用综合生成的 DAG 任务集来评估我们提出的并行路径进展概念的性能，以便进行系统和详尽的探索。首先，我们评估我们的方法（OUR）的完工时间与 He 等人代表的最先进的方法相比。 [20]（他）。我们使用联合调度[26]（FED）来评估 OUR 是否可以利用并行路径并行执行的潜力，因为 OUR 和 FED 的相似性能表明，要么大部分工作负载位于最长的路径上，要么处理器不足，即我们的界限降级为格雷厄姆界限。

其次，我们根据算法 2 (GA) 和算法 3 (ORD) 评估我们提出的组和普通预留系统配置策略，以针对半联邦调度 [24] (SEM) 和基于预留的联邦调度的资源分配进行相对资源过度配置[38] (UE) 相对于 DAG 的总体积，即下界。

第三，我们评估我们的路径覆盖算法在近似算法中以及在什么参数场景中是否可以优于迭代路径集合选择。

## A. 实验数据生成
为了系统地评估所提出的算法并评估不同类别 DAG 结构的性能，我们针对每种生成参数配置使用逐层和 Erd ̋os–Rényi 生成方法生成 300 个 DAG。

逐层生成：正在评估的 DAG 的内部结构强烈影响评估分析的性能。逐层方法提供了参数化生成过程来随机生成 DAG，其结构可归因于生成参数最小并行度、最大并行度、最小层数、最大层数和连接概率。在每个 DAG 的生成中，层数从 5 – 10 和 10 – 15 范围内统一选择，代表最小层到最大层。在每一层中，被称为并行度的子任务的数量从 5 - 10、10 - 15、10 - 25 和 10 - 30 的范围内统一抽取，代表最小并行度到最大并行度的范围。请注意，完全覆盖 DAG 的最小路径数永远不会超过任何生成层中的最大并行度。一层中的子任务仅允许来自层 - 1 的子任务连接。层中每个新生成的子任务都以概率连接概率与前一层的子任务连接，连接概率是从 5% - 10 %、10% - 20%、20% - 30%、40% - 50%、50% - 60% 和 40% - 80%范围内随机抽取的，从而产生 48 种不同的配置，每种配置我们生成一组 300 个 DAG。每个子任务都被分配一个从 10 到 100 范围内统一抽取的整数最坏情况执行时间。

Erd ̋os–Rényi 生成：此外，我们使用 Erd ̋os–Rényi 方法生成 DAG 任务集，该方法用最小顶点到最大顶点和连接概率进行参数化。在生成过程中，首先在10-100和100-150的范围内均匀地绘制多个顶点。对于每类连接概率为5%-10%、15%-20%、25%-30% 、35% − 40% 和 45% − 50%，统一绘制连接概率，用于生成属于该类的单个 DAG。其次，生成上三角邻接矩阵，其中矩阵中的每个条目 aij，即有向边 (vi, vj)，均以概率连接概率绘制。我们为每个配置组合生成 300 个 DAG。

截止日期和周期生成：对于前面描述的每个生成的 DAG 集，我们生成了简单、中等和困难的截止日期。也就是说，截止时间的开区间 D := (vol(π*), C) 定义了截止时间，使得 <span style="color:black;background:#FFDBBB !important;">DAG 在默认情况下不是不可行的，也不是简单可调度的</span>。然后将该区间划分为三个等大小的区间 D1、D2 和 D3，分别代表该区间的第一、第二和第三部分。如果从区间 D1 中随机抽取，则截止时间被认为是困难的；如果从 D2 中随机抽取的，则为中等截止日期；如果从 D3 中随机抽取的截止时间，则为简单截止日期。由于“比较”方法仅支持约束截止日期，但基于预订的联合调度除外，这是我们普通预订系统的特例，因此我们仅评估约束截止日期。我们在 {[1, 1.2], [1.2, 1.5], [1, 2], [2, 3], [1, 1.8], [1, 3]} 并设置周期 T = α·D。

## B. 路径覆盖实验
在路径覆盖实验中，我们将第 IV-A 节中描述的路径覆盖算法计算出的边界与第 IV-C 节中描述的贪婪方法所需的最小路径数进行比较，以完全覆盖 DAG。这个实验的动机是为了表明，在评估的 DAG 中，实际上存在这样的情况，其中这个界限比迭代解决方案更好，因此，资源分配可以得到显着改善。两种算法均在第 VI-A 节中描述的 DAG 集上进行评估，其结果汇总并分别显示在表 II 和表 III 中。改进的列显示评估集中路径覆盖确定的路径少于迭代解决方案的 DAG 的百分比。 max列显示了所需路径的最大绝对差，即有多少条路径，路径覆盖算法需要较少。
可以看出，对于 Erd ̋os–Rényi 集，所有 DAG 集都可以得到显着改进，并且连接概率在 5 – 40% 范围内的集至少有 56% 的改进。对于逐层 DAG 集，改进仍然存在，但只有大约四分之一的 DAG 可以受益，并且较高的连接概率会减少改进。
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101554543.png)
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101554907.png)

## C. 完工时间实验
我们评估了完工时间，即 4、8、16、32 个处理器上单个 DAG 作业的最坏情况响应时间（仅适用于第 VI-A 节中描述的所有配置），并提出标准化为理论下限的完工时间max{C/M, vol(π*)}，即 100% 意味着严格的结果。由于评估结果相似，因此图 4和 5中的箱线图中只显示了一些代表性的数字。

观察结果：从所有记录的结果可以看出，我们的方法并不严格主导 HE 方法，但可以在高并行性（即大量处理器）的情况下提高完工时间。直观上，如果 DAG 任务的大部分工作负载分布在最多 M 个路径上，我们的方法的完工时间会更好，这可能会随着可用处理器数量的增加而增加。因此，改进取决于 DAG 参数和处理器数量。否则，HE 方法可以更好地更准确地分析子任务干扰，从而能够提供更好的完工时间。值得注意的是，我们的方法能够为许多评估案例提供严格的结果。图 4 显示了一个代表性案例，其中评估了具有 100-150 个顶点和 45-50% 连接概率的 DAG 集。可以看出，当提供的处理器数量为 8 时，OUR 提供了严格的结果，而 HE 提供了稍大（非最佳）的完工时间值。另一个代表性情况如图5所示，是通过逐层方法生成的DAG集，层数为10~15，并行度为10~30，连接概率为50~60%。请注意，如果仅考虑一条路径，联合调度 (FED) 与我们的分析一致。可以看出，OUR 并没有显着提高 FED 至 16 个处理器，这表明 DAG 任务的大部分工作负载分布在更多路径上。然而，当为并行度最多为 30 的任务提供 32 个处理器时，OUR 的完工时间在大多数情况下都很紧张。

## D. 预留超额供应实验
系统。我们只对预订系统的资源分配的评估感兴趣，因为可调度性取决于用于调度预订系统的调度算法的可调度性分析的性能。我们比较了我们的普通预留（ORD）、我们的组（GA）、半联邦调度（SEM）和基于预留的联邦调度（UE）的每个作业激活（意味着在一段时间内T）的每种方法的资源分配）相对于 DAG 总体积。也就是说，超额拨备值为 100% 表明配置较紧。我们假设有足够数量的处理器可用，以便可以为每个生成的最后期限找到预订系统。一些有代表性的结果显示在图 6 和 7 的箱线图中。

观察：可以看出，ORD 和 GA 在所有场景下都改善了资源分配，对于难以调度的 DAG 任务显着改善。随着周期与截止时间比率的增加，基于预留的调度方法对半联邦调度的改进越大。有趣的是，ORD 和 GA 在所有场景中都表现出相似的资源分配，这表明 ORD 限制较少的预留方案不会产生更大的资源需求。

![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101553631.png)
![image.png](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101553756.png)
![](https://gcore.jsdelivr.net/gh/wsm6636/pic/202405101553294.png)

# 七．相关工作
并行任务系统的实时感知调度已经针对各种不同的提出的任务模型进行了广泛的研究。古森斯等人 [18]提供了具有实时约束的并行任务的分类。

并行任务模型的早期工作侧重于同步并行任务模型，例如[8]、[27]、[33]。同步并行任务模型扩展了 fork-join 模型 [9]，允许每个（同步）段中有不同数量的子任务，其中子任务的数量可以超过处理器的数量。

有向无环图 (DAG) 任务模型是一种著名的并行任务模型，最近受到许多调度和分析工作的影响。 DAG 通过一组子任务的非循环优先级约束来建模子任务级并行性。并行DAG任务模型已经针对<span style="color:black;background:#fbc2eb !important;">全局[5]、[7]、[30]和分区调度[4]</span>、[6]、[16]、[17]进行了研究。

文献中提出的调度算法和分析可以分为分解式和非分解式。<span style="color:black;background:#fbc2eb !important;">在前者中，并行任务模型被分解为一组顺序任务模型，并代替它们进行调度和分析，例如[23]。非分解方法考虑并行任务模型的特殊性，例如[2]、[5]、[13]、[26]、[30]、[38]。</span>

Li 等人提出的一种突出的基于分解的方法是联合调度 [26]避免并行任务的任务间干扰。它已在[2]、[3]、[12]、[22]、[24]、[38]等中进行了扩展。在原始的联合调度方法中，DAG 任务集被划分为可以在单个处理器上顺序执行的任务和需要并行执行以在各自的截止日期之前完成的任务。在联合调度[26]中，信封执行的任务内干扰的上限是非信封子作业的工作负载除以处理器数量。相应的响应时间分析不需要有关 DAG 内部结构的信息，除了总体积和最长路径之外。

He 等人改进了这一分析 [19]，他提出了一种用于列表调度的特定节点内优先级分配，即 <span style="color:black;background:#fbc2eb !important;">DAG 内节点的拓扑排序。</span>与联合调度相比，这种优先级分配和 DAG 结构的检查导致任务的包络路径自干扰上限不那么悲观。赵等人进一步完善和扩展了这些结果。 [42]，其中沿着包络路径的执行显式地考虑子作业依赖性，以更准确地限制自干扰。最近，He 等人 [20]通过取消节点内优先级分配中的拓扑顺序限制改进了他们之前的工作，这进一步改进了Zhao等人的结果。 [42]。

# 八．结论和未来的工作
我们提出了并行路径进展概念，允许分析并行路径集合的同时进展。我们提出了一种可持续的调度算法和分析，通过针对零星任意截止日期 DAG 任务的基于组和普通预订系统的分层调度进行了扩展。对于这些预订，我们提供的算法可以根据其所需的服务大致提供最佳的预订系统。我们使用综合生成的 DAG 任务集评估了我们的方法，并证明我们的方法可以提高高并行度场景中的最新技术，同时展示低并行度场景的合理性能。在未来的工作中，我们计划通过考虑预订系统的自我暂停行为来改善所提出的预订系统的主动空闲问题。



***

# 笔记

## 1 论文创新在于

## 2 解决了什么问题

## 3 方法

## 4 不足\&可继续研究

## 5 可参考

## 6 思考
